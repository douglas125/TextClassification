{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis\n",
    "\n",
    "Download the Foursquare annotated comments in Brazilian Portuguese: https://www.kaggle.com/thaisalmeida/tips-foursquare/version/1\n",
    "\n",
    "Place the files in subfolder 'docs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget files if using Google Colab\n",
    "!wget -q https://raw.githubusercontent.com/douglas125/TextClassification/master/preProcessing.py\n",
    "!wget -q https://raw.githubusercontent.com/douglas125/TextClassification/master/Embeddings.py\n",
    "!wget -q https://raw.githubusercontent.com/douglas125/TextClassification/master/requirements.txt\n",
    "!pip install -r requirements.txt\n",
    "\n",
    "\n",
    "#move CSVs to docs/ folder\n",
    "from google.colab import files\n",
    "files.upload()\n",
    "\n",
    "!mkdir docs\n",
    "!mv *.csv docs/\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import preProcessing\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "pd.set_option('max_colwidth',150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texto</th>\n",
       "      <th>rotulo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A comida é deliciosa, mas pedi limonada suiça e me disseram que hoje estavam todos muito ocupados e que ninguém conseguiria me atender....melhor i...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A partir desta sexta feira dia 11 começam a abrir para jantar mas corre pois é só até as 22 hrs e no domingo dia das mães, estarão aberto durante ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Joint burguer e brewdog</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Agora de segunda a sexta o Habanero vai abrir no almoço com pratos mexicanos e tradicionais!</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Experimente o drink \"Dona Diabla\". Muito bom!</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Nova senha do Wifi: 1129508219</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Wi-fi 1129508219</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Adoramos a pizza carbonara e a paulistana. Não surpreendeu tanto, mas vale a pena por resgatar o tradicionalismo. Dica @Gourmet_For</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>O diferencial desse Burger King é que você mesmo serve o refrigerante, e a vontade!</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Unico defeito estacionamento pago!</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>24h é 24h.</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Excelente Burger King: bom atendimento, ambiente agradável e refil para refrigerante. Evite o inconveniente estacionamento pago estacionando ao re...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>o atendimento aqui é simplesmente um lixo</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>O Drive-Truh mais lento da cidade!!</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Cheio de bêbados depois das 2 da manhã :D</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Recinto sujo, sem manutenção. Não há segurança pra conter a briga que ocorreu agora há pouco. O refrigerante está aguado, sem gosto, horrível. O l...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                    texto  \\\n",
       "0   A comida é deliciosa, mas pedi limonada suiça e me disseram que hoje estavam todos muito ocupados e que ninguém conseguiria me atender....melhor i...   \n",
       "1   A partir desta sexta feira dia 11 começam a abrir para jantar mas corre pois é só até as 22 hrs e no domingo dia das mães, estarão aberto durante ...   \n",
       "2                                                                                                                                 Joint burguer e brewdog   \n",
       "3                                                            Agora de segunda a sexta o Habanero vai abrir no almoço com pratos mexicanos e tradicionais!   \n",
       "4                                                                                                           Experimente o drink \"Dona Diabla\". Muito bom!   \n",
       "5                                                                                                                          Nova senha do Wifi: 1129508219   \n",
       "6                                                                                                                                        Wi-fi 1129508219   \n",
       "7                     Adoramos a pizza carbonara e a paulistana. Não surpreendeu tanto, mas vale a pena por resgatar o tradicionalismo. Dica @Gourmet_For   \n",
       "8                                                                     O diferencial desse Burger King é que você mesmo serve o refrigerante, e a vontade!   \n",
       "9                                                                                                                      Unico defeito estacionamento pago!   \n",
       "10                                                                                                                                             24h é 24h.   \n",
       "11  Excelente Burger King: bom atendimento, ambiente agradável e refil para refrigerante. Evite o inconveniente estacionamento pago estacionando ao re...   \n",
       "12                                                                                                              o atendimento aqui é simplesmente um lixo   \n",
       "13                                                                                                                    O Drive-Truh mais lento da cidade!!   \n",
       "14                                                                                                              Cheio de bêbados depois das 2 da manhã :D   \n",
       "15  Recinto sujo, sem manutenção. Não há segurança pra conter a briga que ocorreu agora há pouco. O refrigerante está aguado, sem gosto, horrível. O l...   \n",
       "\n",
       "    rotulo  \n",
       "0     -1.0  \n",
       "1      0.0  \n",
       "2      0.0  \n",
       "3      0.0  \n",
       "4      1.0  \n",
       "5      0.0  \n",
       "6      0.0  \n",
       "7      1.0  \n",
       "8      1.0  \n",
       "9     -1.0  \n",
       "10     0.0  \n",
       "11     1.0  \n",
       "12    -1.0  \n",
       "13    -1.0  \n",
       "14    -1.0  \n",
       "15    -1.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('docs/tips_scenario1_train.csv')\n",
    "df.head(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'este é um teste de 000 números ! mas que : interessante .'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preProcessing.clean_text('Este é um teste de 354 números! Mas que: \"interessante\".')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mas', 'que', ':', '\"', 'legal', '\"']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preProcessing.splitWithPunctuation('mas que: \"legal\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1714, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline: Bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df['texto'].astype(str).tolist()\n",
    "categs = df['rotulo'].tolist()\n",
    "texts = [preProcessing.clean_text(t) for t in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(texts, categs, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "countVec = CountVectorizer()\n",
    "vectTexts_train = countVec.fit_transform(X_train)\n",
    "vectTexts_test = countVec.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1542x4708 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 25330 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectTexts_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "mnb.fit(vectTexts_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9105058365758755"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb.score(vectTexts_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7790697674418605"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb.score(vectTexts_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=None, error_score='raise',\n",
       "          estimator=MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),\n",
       "          fit_params=None, iid=True, n_iter=10, n_jobs=1,\n",
       "          param_distributions={'alpha': [0.001, 0.1, 1, 10, 100], 'fit_prior': [True, False]},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score=True, scoring=None, verbose=1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnbParams = { #'verbose' : [1],\n",
    "             'alpha':[0.001, 0.1,1,10, 100],  \n",
    "             'fit_prior' :[True, False]}\n",
    "mnbRSCV = RandomizedSearchCV(mnb, mnbParams, verbose=1, return_train_score=True) #, n_jobs=-1)\n",
    "mnbRSCV.fit(vectTexts_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_fit_prior</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.005490</td>\n",
       "      <td>4.073427e-04</td>\n",
       "      <td>0.000832</td>\n",
       "      <td>2.350675e-04</td>\n",
       "      <td>True</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'fit_prior': True, 'alpha': 0.001}</td>\n",
       "      <td>0.751456</td>\n",
       "      <td>0.784466</td>\n",
       "      <td>0.753906</td>\n",
       "      <td>0.763294</td>\n",
       "      <td>0.015026</td>\n",
       "      <td>3</td>\n",
       "      <td>0.988315</td>\n",
       "      <td>0.986368</td>\n",
       "      <td>0.989320</td>\n",
       "      <td>0.988001</td>\n",
       "      <td>0.001226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.004658</td>\n",
       "      <td>2.352357e-04</td>\n",
       "      <td>0.000665</td>\n",
       "      <td>2.350670e-04</td>\n",
       "      <td>False</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'fit_prior': False, 'alpha': 0.001}</td>\n",
       "      <td>0.737864</td>\n",
       "      <td>0.772816</td>\n",
       "      <td>0.757812</td>\n",
       "      <td>0.756161</td>\n",
       "      <td>0.014330</td>\n",
       "      <td>4</td>\n",
       "      <td>0.991237</td>\n",
       "      <td>0.986368</td>\n",
       "      <td>0.988350</td>\n",
       "      <td>0.988651</td>\n",
       "      <td>0.001999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002994</td>\n",
       "      <td>5.947204e-07</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>3.893359e-07</td>\n",
       "      <td>True</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'fit_prior': True, 'alpha': 0.1}</td>\n",
       "      <td>0.735922</td>\n",
       "      <td>0.766990</td>\n",
       "      <td>0.693359</td>\n",
       "      <td>0.732166</td>\n",
       "      <td>0.030162</td>\n",
       "      <td>5</td>\n",
       "      <td>0.982473</td>\n",
       "      <td>0.979552</td>\n",
       "      <td>0.986408</td>\n",
       "      <td>0.982811</td>\n",
       "      <td>0.002809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.003493</td>\n",
       "      <td>7.061566e-04</td>\n",
       "      <td>0.000665</td>\n",
       "      <td>2.349547e-04</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'fit_prior': False, 'alpha': 0.1}</td>\n",
       "      <td>0.693204</td>\n",
       "      <td>0.722330</td>\n",
       "      <td>0.675781</td>\n",
       "      <td>0.697147</td>\n",
       "      <td>0.019198</td>\n",
       "      <td>7</td>\n",
       "      <td>0.977605</td>\n",
       "      <td>0.976631</td>\n",
       "      <td>0.980583</td>\n",
       "      <td>0.978273</td>\n",
       "      <td>0.001681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.003826</td>\n",
       "      <td>8.477645e-04</td>\n",
       "      <td>0.000665</td>\n",
       "      <td>2.347299e-04</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>{'fit_prior': True, 'alpha': 1}</td>\n",
       "      <td>0.786408</td>\n",
       "      <td>0.794175</td>\n",
       "      <td>0.787109</td>\n",
       "      <td>0.789235</td>\n",
       "      <td>0.003510</td>\n",
       "      <td>1</td>\n",
       "      <td>0.914314</td>\n",
       "      <td>0.906524</td>\n",
       "      <td>0.909709</td>\n",
       "      <td>0.910182</td>\n",
       "      <td>0.003198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.003826</td>\n",
       "      <td>6.225663e-04</td>\n",
       "      <td>0.000831</td>\n",
       "      <td>2.352356e-04</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>{'fit_prior': False, 'alpha': 1}</td>\n",
       "      <td>0.778641</td>\n",
       "      <td>0.801942</td>\n",
       "      <td>0.777344</td>\n",
       "      <td>0.785992</td>\n",
       "      <td>0.011307</td>\n",
       "      <td>2</td>\n",
       "      <td>0.927945</td>\n",
       "      <td>0.925998</td>\n",
       "      <td>0.928155</td>\n",
       "      <td>0.927366</td>\n",
       "      <td>0.000971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.003494</td>\n",
       "      <td>4.079274e-04</td>\n",
       "      <td>0.000665</td>\n",
       "      <td>2.347860e-04</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "      <td>{'fit_prior': True, 'alpha': 10}</td>\n",
       "      <td>0.689320</td>\n",
       "      <td>0.685437</td>\n",
       "      <td>0.693359</td>\n",
       "      <td>0.689364</td>\n",
       "      <td>0.003233</td>\n",
       "      <td>8</td>\n",
       "      <td>0.702045</td>\n",
       "      <td>0.696203</td>\n",
       "      <td>0.692233</td>\n",
       "      <td>0.696827</td>\n",
       "      <td>0.004030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.002994</td>\n",
       "      <td>1.946680e-07</td>\n",
       "      <td>0.000666</td>\n",
       "      <td>2.357976e-04</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>{'fit_prior': False, 'alpha': 10}</td>\n",
       "      <td>0.699029</td>\n",
       "      <td>0.700971</td>\n",
       "      <td>0.712891</td>\n",
       "      <td>0.704280</td>\n",
       "      <td>0.006122</td>\n",
       "      <td>6</td>\n",
       "      <td>0.740019</td>\n",
       "      <td>0.717624</td>\n",
       "      <td>0.720388</td>\n",
       "      <td>0.726011</td>\n",
       "      <td>0.009970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.002994</td>\n",
       "      <td>3.371748e-07</td>\n",
       "      <td>0.000665</td>\n",
       "      <td>2.355168e-04</td>\n",
       "      <td>True</td>\n",
       "      <td>100</td>\n",
       "      <td>{'fit_prior': True, 'alpha': 100}</td>\n",
       "      <td>0.681553</td>\n",
       "      <td>0.681553</td>\n",
       "      <td>0.683594</td>\n",
       "      <td>0.682231</td>\n",
       "      <td>0.000961</td>\n",
       "      <td>10</td>\n",
       "      <td>0.682571</td>\n",
       "      <td>0.682571</td>\n",
       "      <td>0.681553</td>\n",
       "      <td>0.682232</td>\n",
       "      <td>0.000480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.003327</td>\n",
       "      <td>2.362491e-04</td>\n",
       "      <td>0.000666</td>\n",
       "      <td>2.351794e-04</td>\n",
       "      <td>False</td>\n",
       "      <td>100</td>\n",
       "      <td>{'fit_prior': False, 'alpha': 100}</td>\n",
       "      <td>0.685437</td>\n",
       "      <td>0.683495</td>\n",
       "      <td>0.689453</td>\n",
       "      <td>0.686122</td>\n",
       "      <td>0.002479</td>\n",
       "      <td>9</td>\n",
       "      <td>0.694255</td>\n",
       "      <td>0.689387</td>\n",
       "      <td>0.689320</td>\n",
       "      <td>0.690987</td>\n",
       "      <td>0.002311</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.005490  4.073427e-04         0.000832    2.350675e-04   \n",
       "1       0.004658  2.352357e-04         0.000665    2.350670e-04   \n",
       "2       0.002994  5.947204e-07         0.000499    3.893359e-07   \n",
       "3       0.003493  7.061566e-04         0.000665    2.349547e-04   \n",
       "4       0.003826  8.477645e-04         0.000665    2.347299e-04   \n",
       "5       0.003826  6.225663e-04         0.000831    2.352356e-04   \n",
       "6       0.003494  4.079274e-04         0.000665    2.347860e-04   \n",
       "7       0.002994  1.946680e-07         0.000666    2.357976e-04   \n",
       "8       0.002994  3.371748e-07         0.000665    2.355168e-04   \n",
       "9       0.003327  2.362491e-04         0.000666    2.351794e-04   \n",
       "\n",
       "  param_fit_prior param_alpha                                params  \\\n",
       "0            True       0.001   {'fit_prior': True, 'alpha': 0.001}   \n",
       "1           False       0.001  {'fit_prior': False, 'alpha': 0.001}   \n",
       "2            True         0.1     {'fit_prior': True, 'alpha': 0.1}   \n",
       "3           False         0.1    {'fit_prior': False, 'alpha': 0.1}   \n",
       "4            True           1       {'fit_prior': True, 'alpha': 1}   \n",
       "5           False           1      {'fit_prior': False, 'alpha': 1}   \n",
       "6            True          10      {'fit_prior': True, 'alpha': 10}   \n",
       "7           False          10     {'fit_prior': False, 'alpha': 10}   \n",
       "8            True         100     {'fit_prior': True, 'alpha': 100}   \n",
       "9           False         100    {'fit_prior': False, 'alpha': 100}   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  mean_test_score  \\\n",
       "0           0.751456           0.784466           0.753906         0.763294   \n",
       "1           0.737864           0.772816           0.757812         0.756161   \n",
       "2           0.735922           0.766990           0.693359         0.732166   \n",
       "3           0.693204           0.722330           0.675781         0.697147   \n",
       "4           0.786408           0.794175           0.787109         0.789235   \n",
       "5           0.778641           0.801942           0.777344         0.785992   \n",
       "6           0.689320           0.685437           0.693359         0.689364   \n",
       "7           0.699029           0.700971           0.712891         0.704280   \n",
       "8           0.681553           0.681553           0.683594         0.682231   \n",
       "9           0.685437           0.683495           0.689453         0.686122   \n",
       "\n",
       "   std_test_score  rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0        0.015026                3            0.988315            0.986368   \n",
       "1        0.014330                4            0.991237            0.986368   \n",
       "2        0.030162                5            0.982473            0.979552   \n",
       "3        0.019198                7            0.977605            0.976631   \n",
       "4        0.003510                1            0.914314            0.906524   \n",
       "5        0.011307                2            0.927945            0.925998   \n",
       "6        0.003233                8            0.702045            0.696203   \n",
       "7        0.006122                6            0.740019            0.717624   \n",
       "8        0.000961               10            0.682571            0.682571   \n",
       "9        0.002479                9            0.694255            0.689387   \n",
       "\n",
       "   split2_train_score  mean_train_score  std_train_score  \n",
       "0            0.989320          0.988001         0.001226  \n",
       "1            0.988350          0.988651         0.001999  \n",
       "2            0.986408          0.982811         0.002809  \n",
       "3            0.980583          0.978273         0.001681  \n",
       "4            0.909709          0.910182         0.003198  \n",
       "5            0.928155          0.927366         0.000971  \n",
       "6            0.692233          0.696827         0.004030  \n",
       "7            0.720388          0.726011         0.009970  \n",
       "8            0.681553          0.682232         0.000480  \n",
       "9            0.689320          0.690987         0.002311  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(mnbRSCV.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7790697674418605"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnbRSCV.best_estimator_.score(vectTexts_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embedding Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Embeddings import WordEmbeddingBR, splitWithPunctuation\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cbow50_fasttext', 'cbow50_wang2vec', 'glove50']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WordEmbeddingBR.downloadNILCEmbeddings()\n",
    "WordEmbeddingBR.getAvailableEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading embedding file: cbow50_wang2vec.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "934967it [00:59, 15727.38it/s]\n"
     ]
    }
   ],
   "source": [
    "wee = WordEmbeddingBR('cbow50_wang2vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting Support Vector Machine...\n",
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "[LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  24 out of  24 | elapsed:    7.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]Fitting Gradient Boosted Tree...\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         658.5195            6.26s\n",
      "         2         495.4146            6.12s\n",
      "         3         380.5770            6.32s\n",
      "         4         297.1064            6.83s\n",
      "         5         243.7370            6.74s\n",
      "         6         212.2517            6.74s\n",
      "         7         179.5781            6.47s\n",
      "         8         152.4104            6.27s\n",
      "         9         132.1538            6.12s\n",
      "        10         115.4280            5.95s\n",
      "        20          37.9122            4.85s\n",
      "        30          13.3994            4.19s\n",
      "        40           5.1836            3.59s\n",
      "        50           1.8979            3.04s\n",
      "        60           0.8089            2.58s\n",
      "        70           0.3634            2.07s\n",
      "        80           0.2790            1.48s\n",
      "        90           0.2790            0.95s\n",
      "       100           0.2790            0.52s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         671.9916            4.55s\n",
      "         2         520.6709            5.02s\n",
      "         3         406.8037            5.31s\n",
      "         4         326.3749            5.82s\n",
      "         5         266.0991            6.30s\n",
      "         6         225.0647            6.47s\n",
      "         7         195.0785            6.46s\n",
      "         8         164.2433            6.45s\n",
      "         9         143.5765            6.25s\n",
      "        10         125.4225            6.08s\n",
      "        20          43.1297            4.77s\n",
      "        30          18.9884            3.98s\n",
      "        40           9.5922            3.37s\n",
      "        50           5.9567            2.91s\n",
      "        60           4.1062            2.54s\n",
      "        70           3.4722            2.07s\n",
      "        80           3.1418            1.61s\n",
      "        90           3.0220            1.10s\n",
      "       100           2.9930            0.62s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         660.5007            6.31s\n",
      "         2         507.4379            6.51s\n",
      "         3         399.0890            6.06s\n",
      "         4         315.9342            5.75s\n",
      "         5         253.6216            5.93s\n",
      "         6         212.1103            6.04s\n",
      "         7         178.4741            6.15s\n",
      "         8         156.5863            6.10s\n",
      "         9         135.0496            6.02s\n",
      "        10         120.4958            5.85s\n",
      "        20          41.9691            4.60s\n",
      "        30          16.6314            3.85s\n",
      "        40           7.9419            3.36s\n",
      "        50           5.0688            2.89s\n",
      "        60           3.7268            2.41s\n",
      "        70           3.2481            1.93s\n",
      "        80           3.0518            1.45s\n",
      "        90           3.0093            0.98s\n",
      "       100           2.9808            0.55s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         770.1586            7.27s\n",
      "         2         670.9554            9.79s\n",
      "         3         603.4396            9.38s\n",
      "         4         547.4962            9.00s\n",
      "         5         506.8908            9.22s\n",
      "         6         471.2818            9.03s\n",
      "         7         437.2783            8.91s\n",
      "         8         407.9026            8.83s\n",
      "         9         387.2833            8.77s\n",
      "        10         367.8681            8.61s\n",
      "        20         224.1091            7.48s\n",
      "        30         143.1032            7.14s\n",
      "        40          99.1938            6.88s\n",
      "        50          70.6351            6.51s\n",
      "        60          51.6205            6.21s\n",
      "        70          37.3589            5.96s\n",
      "        80          28.9748            5.65s\n",
      "        90          21.2176            5.35s\n",
      "       100          15.7538            5.06s\n",
      "       200           0.9375            2.44s\n",
      "       300           0.2616            0.20s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         781.8112            8.97s\n",
      "         2         683.8254            8.33s\n",
      "         3         609.8548            9.22s\n",
      "         4         562.0009            9.46s\n",
      "         5         521.6649            9.87s\n",
      "         6         488.4876           10.17s\n",
      "         7         452.1422           10.25s\n",
      "         8         427.2836           10.19s\n",
      "         9         403.6289           10.00s\n",
      "        10         382.1124           10.02s\n",
      "        20         241.6303            9.43s\n",
      "        30         161.6753            8.69s\n",
      "        40         116.7451            8.00s\n",
      "        50          82.0145            7.29s\n",
      "        60          61.7570            6.87s\n",
      "        70          47.2591            6.55s\n",
      "        80          35.1193            6.20s\n",
      "        90          27.5742            5.91s\n",
      "       100          21.1813            5.60s\n",
      "       200           4.3264            2.51s\n",
      "       300           3.0367            0.23s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         774.9551            7.12s\n",
      "         2         670.2225            7.63s\n",
      "         3         604.7745            8.15s\n",
      "         4         556.1663            8.27s\n",
      "         5         508.8844            8.74s\n",
      "         6         470.0089            8.73s\n",
      "         7         444.2526            8.91s\n",
      "         8         415.0768            8.71s\n",
      "         9         385.9428            8.61s\n",
      "        10         366.1157            8.47s\n",
      "        20         230.4047            7.15s\n",
      "        30         148.4890            6.56s\n",
      "        40         103.4973            6.16s\n",
      "        50          75.0101            5.82s\n",
      "        60          56.4689            5.51s\n",
      "        70          43.1838            5.23s\n",
      "        80          32.6514            4.99s\n",
      "        90          25.3975            4.74s\n",
      "       100          20.0868            4.61s\n",
      "       200           4.2903            2.26s\n",
      "       300           3.0045            0.21s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         892.2209            9.81s\n",
      "         2         832.6355           10.22s\n",
      "         3         780.8232            9.91s\n",
      "         4         735.7237            9.96s\n",
      "         5         694.6419            9.95s\n",
      "         6         658.9340           10.13s\n",
      "         7         626.5421            9.98s\n",
      "         8         596.1736            9.86s\n",
      "         9         570.4062            9.96s\n",
      "        10         546.9959           10.32s\n",
      "        20         362.2477            9.04s\n",
      "        30         260.8026            8.16s\n",
      "        40         195.7642            7.51s\n",
      "        50         154.8390            6.96s\n",
      "        60         121.5850            6.50s\n",
      "        70          97.5654            6.08s\n",
      "        80          79.3683            5.63s\n",
      "        90          65.1696            5.21s\n",
      "       100          54.3592            4.81s\n",
      "       200           8.7824            0.98s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         896.7241           10.60s\n",
      "         2         842.6213           10.16s\n",
      "         3         792.6049           10.55s\n",
      "         4         748.9750           11.30s\n",
      "         5         708.4118           11.23s\n",
      "         6         670.8958           11.18s\n",
      "         7         637.7008           11.04s\n",
      "         8         606.0905           10.82s\n",
      "         9         578.6467           10.98s\n",
      "        10         554.3936           10.74s\n",
      "        20         375.1972            9.68s\n",
      "        30         268.7083            9.15s\n",
      "        40         201.4377            9.53s\n",
      "        50         155.3608            8.97s\n",
      "        60         123.4038            8.20s\n",
      "        70          99.1230            7.92s\n",
      "        80          79.7592            7.36s\n",
      "        90          66.0932            6.76s\n",
      "       100          54.3352            6.13s\n",
      "       200          11.4773            1.16s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         898.1110            9.92s\n",
      "         2         838.4991           10.16s\n",
      "         3         787.0119            9.95s\n",
      "         4         742.1632           11.07s\n",
      "         5         701.6666           11.34s\n",
      "         6         664.3818           11.10s\n",
      "         7         627.0572           11.10s\n",
      "         8         597.5516           11.01s\n",
      "         9         566.8869           11.24s\n",
      "        10         540.0326           11.02s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        20         347.1043           10.30s\n",
      "        30         244.9993            9.07s\n",
      "        40         182.6824            8.28s\n",
      "        50         140.6383            7.60s\n",
      "        60         109.2661            7.08s\n",
      "        70          88.5923            6.55s\n",
      "        80          71.3518            6.05s\n",
      "        90          57.6216            5.58s\n",
      "       100          47.1368            5.15s\n",
      "       200           8.3875            1.06s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         663.8706           37.10s\n",
      "         2         475.0937           38.23s\n",
      "         3         346.4510           39.12s\n",
      "         4         251.0832           38.49s\n",
      "         5         185.3167           38.60s\n",
      "         6         141.1186           38.26s\n",
      "         7         106.7624           38.85s\n",
      "         8          79.6621           38.81s\n",
      "         9          58.7069           38.76s\n",
      "        10          43.7401           38.67s\n",
      "        20           3.4129           34.41s\n",
      "        30           0.4175           30.69s\n",
      "        40           0.2975           23.91s\n",
      "        50           0.2975           18.71s\n",
      "        60           0.2975           15.27s\n",
      "        70           0.2975           12.76s\n",
      "        80           0.2975           10.87s\n",
      "        90           0.2975            9.39s\n",
      "       100           0.2975            8.20s\n",
      "       200           0.2975            2.70s\n",
      "       300           0.2975            0.69s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         652.7229           37.81s\n",
      "         2         462.3991           37.70s\n",
      "         3         327.6977           38.70s\n",
      "         4         251.4068           38.76s\n",
      "         5         190.7176           38.53s\n",
      "         6         140.2635           40.29s\n",
      "         7         108.6628           40.17s\n",
      "         8          83.4745           40.67s\n",
      "         9          62.1611           41.36s\n",
      "        10          48.5491           41.29s\n",
      "        20           6.2769           38.09s\n",
      "        30           3.2326           34.02s\n",
      "        40           3.0318           27.61s\n",
      "        50           2.9634           23.12s\n",
      "        60           2.9333           19.92s\n",
      "        70           2.8976           17.50s\n",
      "        80           2.8726           15.80s\n",
      "        90           2.8528           14.43s\n",
      "       100           2.8386           13.11s\n",
      "       200           2.7803            5.90s\n",
      "       300           2.7736            1.84s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         635.9633           42.93s\n",
      "         2         450.8125           44.13s\n",
      "         3         321.9947           46.49s\n",
      "         4         232.8121           47.78s\n",
      "         5         169.8600           46.25s\n",
      "         6         122.2124           45.52s\n",
      "         7          90.3944           44.81s\n",
      "         8          66.9604           44.96s\n",
      "         9          49.1772           44.55s\n",
      "        10          36.8992           43.90s\n",
      "        20           5.6840           36.36s\n",
      "        30           3.2064           31.28s\n",
      "        40           3.0242           25.27s\n",
      "        50           2.9581           21.24s\n",
      "        60           2.9237           18.24s\n",
      "        70           2.8905           16.11s\n",
      "        80           2.8649           14.49s\n",
      "        90           2.8458           13.20s\n",
      "       100           2.8311           12.11s\n",
      "       200           2.7797            5.59s\n",
      "       300           2.7734            1.83s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed:  1.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1        1046.0737            7.97s\n",
      "         2         848.6318            7.89s\n",
      "         3         705.4500            7.73s\n",
      "         4         598.5587            7.87s\n",
      "         5         497.5283            7.63s\n",
      "         6         436.0509            7.43s\n",
      "         7         381.8273            7.55s\n",
      "         8         335.0726            7.40s\n",
      "         9         299.2200            7.25s\n",
      "        10         270.3118            7.29s\n",
      "        20         105.2294            6.11s\n",
      "        30          52.3799            5.49s\n",
      "        40          26.7224            4.86s\n",
      "        50          15.5067            4.24s\n",
      "        60          10.4264            3.51s\n",
      "        70           7.7755            2.80s\n",
      "        80           6.2265            2.13s\n",
      "        90           5.3279            1.50s\n",
      "       100           4.8589            0.89s\n"
     ]
    }
   ],
   "source": [
    "classifiers = wee.TrainBaselineClassifiers(X_train, y_train, n_iter=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SVM': 0.9980544747081712, 'GradientBoostingClassifier': 0.9980544747081712}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wee.TestBaselineClassifiers(X_train, y_train, classifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SVM': 0.7732558139534884, 'GradientBoostingClassifier': 0.7558139534883721}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wee.TestBaselineClassifiers(X_test, y_test, classifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8081395348837209"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svmRSCV.best_estimator_.score(vectTexts_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
