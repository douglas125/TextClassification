{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis\n",
    "\n",
    "Download the Foursquare annotated comments in Brazilian Portuguese: https://www.kaggle.com/thaisalmeida/tips-foursquare/version/1\n",
    "\n",
    "Place the files in subfolder 'docs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import preProcessing\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "pd.set_option('max_colwidth',150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texto</th>\n",
       "      <th>rotulo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A comida é deliciosa, mas pedi limonada suiça e me disseram que hoje estavam todos muito ocupados e que ninguém conseguiria me atender....melhor i...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A partir desta sexta feira dia 11 começam a abrir para jantar mas corre pois é só até as 22 hrs e no domingo dia das mães, estarão aberto durante ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Joint burguer e brewdog</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Agora de segunda a sexta o Habanero vai abrir no almoço com pratos mexicanos e tradicionais!</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Experimente o drink \"Dona Diabla\". Muito bom!</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Nova senha do Wifi: 1129508219</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Wi-fi 1129508219</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Adoramos a pizza carbonara e a paulistana. Não surpreendeu tanto, mas vale a pena por resgatar o tradicionalismo. Dica @Gourmet_For</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>O diferencial desse Burger King é que você mesmo serve o refrigerante, e a vontade!</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Unico defeito estacionamento pago!</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>24h é 24h.</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Excelente Burger King: bom atendimento, ambiente agradável e refil para refrigerante. Evite o inconveniente estacionamento pago estacionando ao re...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>o atendimento aqui é simplesmente um lixo</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>O Drive-Truh mais lento da cidade!!</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Cheio de bêbados depois das 2 da manhã :D</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Recinto sujo, sem manutenção. Não há segurança pra conter a briga que ocorreu agora há pouco. O refrigerante está aguado, sem gosto, horrível. O l...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                    texto  \\\n",
       "0   A comida é deliciosa, mas pedi limonada suiça e me disseram que hoje estavam todos muito ocupados e que ninguém conseguiria me atender....melhor i...   \n",
       "1   A partir desta sexta feira dia 11 começam a abrir para jantar mas corre pois é só até as 22 hrs e no domingo dia das mães, estarão aberto durante ...   \n",
       "2                                                                                                                                 Joint burguer e brewdog   \n",
       "3                                                            Agora de segunda a sexta o Habanero vai abrir no almoço com pratos mexicanos e tradicionais!   \n",
       "4                                                                                                           Experimente o drink \"Dona Diabla\". Muito bom!   \n",
       "5                                                                                                                          Nova senha do Wifi: 1129508219   \n",
       "6                                                                                                                                        Wi-fi 1129508219   \n",
       "7                     Adoramos a pizza carbonara e a paulistana. Não surpreendeu tanto, mas vale a pena por resgatar o tradicionalismo. Dica @Gourmet_For   \n",
       "8                                                                     O diferencial desse Burger King é que você mesmo serve o refrigerante, e a vontade!   \n",
       "9                                                                                                                      Unico defeito estacionamento pago!   \n",
       "10                                                                                                                                             24h é 24h.   \n",
       "11  Excelente Burger King: bom atendimento, ambiente agradável e refil para refrigerante. Evite o inconveniente estacionamento pago estacionando ao re...   \n",
       "12                                                                                                              o atendimento aqui é simplesmente um lixo   \n",
       "13                                                                                                                    O Drive-Truh mais lento da cidade!!   \n",
       "14                                                                                                              Cheio de bêbados depois das 2 da manhã :D   \n",
       "15  Recinto sujo, sem manutenção. Não há segurança pra conter a briga que ocorreu agora há pouco. O refrigerante está aguado, sem gosto, horrível. O l...   \n",
       "\n",
       "    rotulo  \n",
       "0     -1.0  \n",
       "1      0.0  \n",
       "2      0.0  \n",
       "3      0.0  \n",
       "4      1.0  \n",
       "5      0.0  \n",
       "6      0.0  \n",
       "7      1.0  \n",
       "8      1.0  \n",
       "9     -1.0  \n",
       "10     0.0  \n",
       "11     1.0  \n",
       "12    -1.0  \n",
       "13    -1.0  \n",
       "14    -1.0  \n",
       "15    -1.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('docs/tips_scenario1_train.csv')\n",
    "df.head(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'este é um teste de 000 números ! mas que : interessante .'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preProcessing.clean_text('Este é um teste de 354 números! Mas que: \"interessante\".')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mas', 'que', ':', '\"', 'legal', '\"']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preProcessing.splitWithPunctuation('mas que: \"legal\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1714, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline: Bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df['texto'].astype(str).tolist()\n",
    "categs = df['rotulo'].tolist()\n",
    "texts = [preProcessing.clean_text(t) for t in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(texts, categs, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "countVec = CountVectorizer()\n",
    "vectTexts_train = countVec.fit_transform(X_train)\n",
    "vectTexts_test = countVec.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1542x4708 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 25330 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectTexts_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "mnb.fit(vectTexts_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9105058365758755"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb.score(vectTexts_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7790697674418605"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb.score(vectTexts_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=None, error_score='raise',\n",
       "          estimator=MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),\n",
       "          fit_params=None, iid=True, n_iter=10, n_jobs=1,\n",
       "          param_distributions={'alpha': [0.001, 0.1, 1, 10, 100], 'fit_prior': [True, False]},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score=True, scoring=None, verbose=1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnbParams = { #'verbose' : [1],\n",
    "             'alpha':[0.001, 0.1,1,10, 100],  \n",
    "             'fit_prior' :[True, False]}\n",
    "mnbRSCV = RandomizedSearchCV(mnb, mnbParams, verbose=1, return_train_score=True) #, n_jobs=-1)\n",
    "mnbRSCV.fit(vectTexts_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_fit_prior</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.004159</td>\n",
       "      <td>2.354605e-04</td>\n",
       "      <td>0.000665</td>\n",
       "      <td>2.351794e-04</td>\n",
       "      <td>True</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'fit_prior': True, 'alpha': 0.001}</td>\n",
       "      <td>0.751456</td>\n",
       "      <td>0.784466</td>\n",
       "      <td>0.753906</td>\n",
       "      <td>0.763294</td>\n",
       "      <td>0.015026</td>\n",
       "      <td>3</td>\n",
       "      <td>0.988315</td>\n",
       "      <td>0.986368</td>\n",
       "      <td>0.989320</td>\n",
       "      <td>0.988001</td>\n",
       "      <td>0.001226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002994</td>\n",
       "      <td>1.123916e-07</td>\n",
       "      <td>0.000665</td>\n",
       "      <td>2.355729e-04</td>\n",
       "      <td>False</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'fit_prior': False, 'alpha': 0.001}</td>\n",
       "      <td>0.737864</td>\n",
       "      <td>0.772816</td>\n",
       "      <td>0.757812</td>\n",
       "      <td>0.756161</td>\n",
       "      <td>0.014330</td>\n",
       "      <td>4</td>\n",
       "      <td>0.991237</td>\n",
       "      <td>0.986368</td>\n",
       "      <td>0.988350</td>\n",
       "      <td>0.988651</td>\n",
       "      <td>0.001999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.003161</td>\n",
       "      <td>2.352357e-04</td>\n",
       "      <td>0.000665</td>\n",
       "      <td>2.350108e-04</td>\n",
       "      <td>True</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'fit_prior': True, 'alpha': 0.1}</td>\n",
       "      <td>0.735922</td>\n",
       "      <td>0.766990</td>\n",
       "      <td>0.693359</td>\n",
       "      <td>0.732166</td>\n",
       "      <td>0.030162</td>\n",
       "      <td>5</td>\n",
       "      <td>0.982473</td>\n",
       "      <td>0.979552</td>\n",
       "      <td>0.986408</td>\n",
       "      <td>0.982811</td>\n",
       "      <td>0.002809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.002994</td>\n",
       "      <td>2.973602e-07</td>\n",
       "      <td>0.000665</td>\n",
       "      <td>2.353481e-04</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'fit_prior': False, 'alpha': 0.1}</td>\n",
       "      <td>0.693204</td>\n",
       "      <td>0.722330</td>\n",
       "      <td>0.675781</td>\n",
       "      <td>0.697147</td>\n",
       "      <td>0.019198</td>\n",
       "      <td>7</td>\n",
       "      <td>0.977605</td>\n",
       "      <td>0.976631</td>\n",
       "      <td>0.980583</td>\n",
       "      <td>0.978273</td>\n",
       "      <td>0.001681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.003327</td>\n",
       "      <td>2.356855e-04</td>\n",
       "      <td>0.000832</td>\n",
       "      <td>2.350109e-04</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>{'fit_prior': True, 'alpha': 1}</td>\n",
       "      <td>0.786408</td>\n",
       "      <td>0.794175</td>\n",
       "      <td>0.787109</td>\n",
       "      <td>0.789235</td>\n",
       "      <td>0.003510</td>\n",
       "      <td>1</td>\n",
       "      <td>0.914314</td>\n",
       "      <td>0.906524</td>\n",
       "      <td>0.909709</td>\n",
       "      <td>0.910182</td>\n",
       "      <td>0.003198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.006155</td>\n",
       "      <td>6.223965e-04</td>\n",
       "      <td>0.001331</td>\n",
       "      <td>2.351799e-04</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>{'fit_prior': False, 'alpha': 1}</td>\n",
       "      <td>0.778641</td>\n",
       "      <td>0.801942</td>\n",
       "      <td>0.777344</td>\n",
       "      <td>0.785992</td>\n",
       "      <td>0.011307</td>\n",
       "      <td>2</td>\n",
       "      <td>0.927945</td>\n",
       "      <td>0.925998</td>\n",
       "      <td>0.928155</td>\n",
       "      <td>0.927366</td>\n",
       "      <td>0.000971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.005991</td>\n",
       "      <td>1.223391e-03</td>\n",
       "      <td>0.001163</td>\n",
       "      <td>4.677745e-04</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "      <td>{'fit_prior': True, 'alpha': 10}</td>\n",
       "      <td>0.689320</td>\n",
       "      <td>0.685437</td>\n",
       "      <td>0.693359</td>\n",
       "      <td>0.689364</td>\n",
       "      <td>0.003233</td>\n",
       "      <td>8</td>\n",
       "      <td>0.702045</td>\n",
       "      <td>0.696203</td>\n",
       "      <td>0.692233</td>\n",
       "      <td>0.696827</td>\n",
       "      <td>0.004030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.003992</td>\n",
       "      <td>1.077286e-03</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>1.946680e-07</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>{'fit_prior': False, 'alpha': 10}</td>\n",
       "      <td>0.699029</td>\n",
       "      <td>0.700971</td>\n",
       "      <td>0.712891</td>\n",
       "      <td>0.704280</td>\n",
       "      <td>0.006122</td>\n",
       "      <td>6</td>\n",
       "      <td>0.740019</td>\n",
       "      <td>0.717624</td>\n",
       "      <td>0.720388</td>\n",
       "      <td>0.726011</td>\n",
       "      <td>0.009970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.003992</td>\n",
       "      <td>8.150747e-04</td>\n",
       "      <td>0.000998</td>\n",
       "      <td>5.619580e-07</td>\n",
       "      <td>True</td>\n",
       "      <td>100</td>\n",
       "      <td>{'fit_prior': True, 'alpha': 100}</td>\n",
       "      <td>0.681553</td>\n",
       "      <td>0.681553</td>\n",
       "      <td>0.683594</td>\n",
       "      <td>0.682231</td>\n",
       "      <td>0.000961</td>\n",
       "      <td>10</td>\n",
       "      <td>0.682571</td>\n",
       "      <td>0.682571</td>\n",
       "      <td>0.681553</td>\n",
       "      <td>0.682232</td>\n",
       "      <td>0.000480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.004658</td>\n",
       "      <td>1.025704e-03</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>2.973602e-07</td>\n",
       "      <td>False</td>\n",
       "      <td>100</td>\n",
       "      <td>{'fit_prior': False, 'alpha': 100}</td>\n",
       "      <td>0.685437</td>\n",
       "      <td>0.683495</td>\n",
       "      <td>0.689453</td>\n",
       "      <td>0.686122</td>\n",
       "      <td>0.002479</td>\n",
       "      <td>9</td>\n",
       "      <td>0.694255</td>\n",
       "      <td>0.689387</td>\n",
       "      <td>0.689320</td>\n",
       "      <td>0.690987</td>\n",
       "      <td>0.002311</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.004159  2.354605e-04         0.000665    2.351794e-04   \n",
       "1       0.002994  1.123916e-07         0.000665    2.355729e-04   \n",
       "2       0.003161  2.352357e-04         0.000665    2.350108e-04   \n",
       "3       0.002994  2.973602e-07         0.000665    2.353481e-04   \n",
       "4       0.003327  2.356855e-04         0.000832    2.350109e-04   \n",
       "5       0.006155  6.223965e-04         0.001331    2.351799e-04   \n",
       "6       0.005991  1.223391e-03         0.001163    4.677745e-04   \n",
       "7       0.003992  1.077286e-03         0.000499    1.946680e-07   \n",
       "8       0.003992  8.150747e-04         0.000998    5.619580e-07   \n",
       "9       0.004658  1.025704e-03         0.000499    2.973602e-07   \n",
       "\n",
       "  param_fit_prior param_alpha                                params  \\\n",
       "0            True       0.001   {'fit_prior': True, 'alpha': 0.001}   \n",
       "1           False       0.001  {'fit_prior': False, 'alpha': 0.001}   \n",
       "2            True         0.1     {'fit_prior': True, 'alpha': 0.1}   \n",
       "3           False         0.1    {'fit_prior': False, 'alpha': 0.1}   \n",
       "4            True           1       {'fit_prior': True, 'alpha': 1}   \n",
       "5           False           1      {'fit_prior': False, 'alpha': 1}   \n",
       "6            True          10      {'fit_prior': True, 'alpha': 10}   \n",
       "7           False          10     {'fit_prior': False, 'alpha': 10}   \n",
       "8            True         100     {'fit_prior': True, 'alpha': 100}   \n",
       "9           False         100    {'fit_prior': False, 'alpha': 100}   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  mean_test_score  \\\n",
       "0           0.751456           0.784466           0.753906         0.763294   \n",
       "1           0.737864           0.772816           0.757812         0.756161   \n",
       "2           0.735922           0.766990           0.693359         0.732166   \n",
       "3           0.693204           0.722330           0.675781         0.697147   \n",
       "4           0.786408           0.794175           0.787109         0.789235   \n",
       "5           0.778641           0.801942           0.777344         0.785992   \n",
       "6           0.689320           0.685437           0.693359         0.689364   \n",
       "7           0.699029           0.700971           0.712891         0.704280   \n",
       "8           0.681553           0.681553           0.683594         0.682231   \n",
       "9           0.685437           0.683495           0.689453         0.686122   \n",
       "\n",
       "   std_test_score  rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0        0.015026                3            0.988315            0.986368   \n",
       "1        0.014330                4            0.991237            0.986368   \n",
       "2        0.030162                5            0.982473            0.979552   \n",
       "3        0.019198                7            0.977605            0.976631   \n",
       "4        0.003510                1            0.914314            0.906524   \n",
       "5        0.011307                2            0.927945            0.925998   \n",
       "6        0.003233                8            0.702045            0.696203   \n",
       "7        0.006122                6            0.740019            0.717624   \n",
       "8        0.000961               10            0.682571            0.682571   \n",
       "9        0.002479                9            0.694255            0.689387   \n",
       "\n",
       "   split2_train_score  mean_train_score  std_train_score  \n",
       "0            0.989320          0.988001         0.001226  \n",
       "1            0.988350          0.988651         0.001999  \n",
       "2            0.986408          0.982811         0.002809  \n",
       "3            0.980583          0.978273         0.001681  \n",
       "4            0.909709          0.910182         0.003198  \n",
       "5            0.928155          0.927366         0.000971  \n",
       "6            0.692233          0.696827         0.004030  \n",
       "7            0.720388          0.726011         0.009970  \n",
       "8            0.681553          0.682232         0.000480  \n",
       "9            0.689320          0.690987         0.002311  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(mnbRSCV.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7790697674418605"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnbRSCV.best_estimator_.score(vectTexts_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embedding Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Embeddings import WordEmbeddingBR, splitWithPunctuation\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cbow50_wang2vec', 'glove50']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WordEmbeddingBR.downloadNILCEmbeddings()\n",
    "WordEmbeddingBR.getAvailableEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading embedding file: cbow50_wang2vec.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "934967it [00:56, 16562.14it/s]\n"
     ]
    }
   ],
   "source": [
    "wee = WordEmbeddingBR('skip_s300_word2vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = max([len(x) for x in X_train])\n",
    "def getSentenceVector(x, emb):\n",
    "    wordArray = splitWithPunctuation(x)\n",
    "    ans = np.zeros( (maxlen, emb.embDim) )\n",
    "    for i,w in enumerate(wordArray):\n",
    "        if len(w) > 2:\n",
    "            ans[i] = emb.encodeWord(w.lower())\n",
    "            ans[i] /= (np.linalg.norm(ans[i])+1e-4)\n",
    "        \n",
    "    return np.sum(ans,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'muito caro pelo tamanho e sabor . fomos em dois e gastamos r$00,00 . para fast food de tamanho normal , foi muito .'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getSentenceVector(X_train[2], wee).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'achei a comida bem medíocre . prato com muitas coisas , mas nada com sabor . não vale o que custa .'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.54267877, -2.4083582 ,  0.05858124, -0.50801632,  0.2093675 ,\n",
       "       -2.41057827, -0.99857627, -0.35532332, -0.81334581, -0.72056427,\n",
       "        1.39481846, -0.28752871, -0.28190608, -2.01494058,  0.91679327,\n",
       "        0.15896422,  2.66689752, -1.15763982,  2.09417567,  0.91922997,\n",
       "       -1.35736812,  1.84102141,  1.33348798, -1.53619593,  0.12388522,\n",
       "        0.10981601, -0.39186563,  2.3167655 ,  1.03957657, -0.83999203,\n",
       "       -0.75009092,  0.14593409, -0.88529186,  0.09057839,  1.9714189 ,\n",
       "        0.65833036,  0.70094116,  0.80373321,  0.99129762, -1.38716639,\n",
       "       -0.70253531,  0.66281073, -0.45017885,  1.34422549,  2.04371999,\n",
       "       -0.03738796, -1.20501453, -0.53624573, -0.52358649, -0.71016648])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectTexts_train = [getSentenceVector(x, wee).reshape((-1,)) for x in X_train]\n",
    "vectTexts_test = [getSentenceVector(x, wee).reshape((-1,)) for x in X_test]\n",
    "getSentenceVector(X_train[0], wee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1        1320.3346           28.02s\n",
      "         2        1209.6517           26.19s\n",
      "         3        1115.1603           27.26s\n",
      "         4        1037.1981           27.16s\n",
      "         5         962.9793           27.60s\n",
      "         6         903.4017           27.00s\n",
      "         7         844.5276           27.13s\n",
      "         8         795.1224           27.15s\n",
      "         9         749.2693           27.33s\n",
      "        10         704.9255           27.48s\n",
      "        20         412.8127           25.80s\n",
      "        30         273.1831           23.58s\n",
      "        40         186.6105           22.10s\n",
      "        50         131.8634           21.31s\n",
      "        60          95.7391           20.37s\n",
      "        70          71.1971           19.79s\n",
      "        80          54.2056           18.85s\n",
      "        90          41.3895           17.91s\n",
      "       100          32.0871           17.25s\n",
      "       200           6.3685            8.95s\n",
      "       300           4.5454            1.36s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=6,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=320,\n",
       "              presort='auto', random_state=None, subsample=1.0, verbose=1,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#try some of scikit learn classifiers\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "\n",
    "gbc = GradientBoostingClassifier(verbose=1, learning_rate=0.1, n_estimators=320, max_depth=6)\n",
    "gbc.fit(vectTexts_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.9980544747081712 Test score: 0.7616279069767442\n"
     ]
    }
   ],
   "source": [
    "print('Train score: {} Test score: {}'.format(gbc.score(vectTexts_train, y_train),gbc.score(vectTexts_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         911.7711           12.91s\n",
      "         2         866.9821           13.04s\n",
      "         3         825.9867           12.22s\n",
      "         4         787.9908           11.81s\n",
      "         5         753.7134           11.81s\n",
      "         6         722.1049           11.62s\n",
      "         7         692.0052           11.85s\n",
      "         8         664.0919           11.81s\n",
      "         9         636.7105           11.72s\n",
      "        10         611.2379           11.90s\n",
      "        20         431.1345           10.53s\n",
      "        30         309.5752            9.80s\n",
      "        40         230.8327            8.93s\n",
      "        50         178.7208            8.21s\n",
      "        60         138.3163            7.57s\n",
      "        70         110.2369            6.95s\n",
      "        80          90.4521            6.35s\n",
      "        90          74.8349            5.77s\n",
      "       100          61.5676            5.22s\n",
      "       200          10.6359            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         914.0989           10.23s\n",
      "         2         871.2788           11.41s\n",
      "         3         831.5367           11.50s\n",
      "         4         795.8509           11.42s\n",
      "         5         764.1499           11.15s\n",
      "         6         733.9768           11.10s\n",
      "         7         703.2020           11.38s\n",
      "         8         674.4794           11.46s\n",
      "         9         648.2764           11.37s\n",
      "        10         622.0982           11.41s\n",
      "        20         432.2237           11.00s\n",
      "        30         318.5682           10.02s\n",
      "        40         238.5330            9.73s\n",
      "        50         182.7816            9.17s\n",
      "        60         141.8378            8.52s\n",
      "        70         112.8114            7.95s\n",
      "        80          91.9210            7.17s\n",
      "        90          74.7774            6.49s\n",
      "       100          61.6244            5.85s\n",
      "       200          11.9005            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         916.2887           10.92s\n",
      "         2         872.5826           11.46s\n",
      "         3         829.7757           12.09s\n",
      "         4         791.5760           12.01s\n",
      "         5         755.6902           11.91s\n",
      "         6         720.5972           11.88s\n",
      "         7         689.6089           12.01s\n",
      "         8         660.3965           12.05s\n",
      "         9         633.5660           12.04s\n",
      "        10         608.4546           11.84s\n",
      "        20         407.9346           10.51s\n",
      "        30         283.4772            9.86s\n",
      "        40         205.0365            9.00s\n",
      "        50         153.7603            8.24s\n",
      "        60         119.5509            7.60s\n",
      "        70          95.2727            6.98s\n",
      "        80          76.5425            6.38s\n",
      "        90          62.1296            5.80s\n",
      "       100          51.1822            5.26s\n",
      "       200           9.1191            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         771.7817            2.91s\n",
      "         2         646.6494            2.89s\n",
      "         3         562.6466            3.22s\n",
      "         4         489.7716            3.09s\n",
      "         5         426.6509            2.92s\n",
      "         6         373.6745            2.73s\n",
      "         7         335.2537            2.57s\n",
      "         8         303.7827            2.42s\n",
      "         9         272.2381            2.32s\n",
      "        10         251.4051            2.23s\n",
      "        20         118.6926            1.44s\n",
      "        30          56.7339            0.90s\n",
      "        40          31.9943            0.43s\n",
      "        50          18.8350            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         784.8848            2.45s\n",
      "         2         660.0814            3.17s\n",
      "         3         568.7393            2.89s\n",
      "         4         503.3738            2.77s\n",
      "         5         446.8839            2.64s\n",
      "         6         395.1867            2.56s\n",
      "         7         358.6356            2.50s\n",
      "         8         321.8522            2.41s\n",
      "         9         292.4553            2.34s\n",
      "        10         269.7046            2.30s\n",
      "        20         115.9607            1.47s\n",
      "        30          67.3390            0.91s\n",
      "        40          37.4041            0.44s\n",
      "        50          23.7088            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         768.9377            2.25s\n",
      "         2         638.4007            2.23s\n",
      "         3         549.0273            2.22s\n",
      "         4         476.3840            2.20s\n",
      "         5         425.7983            2.16s\n",
      "         6         382.5653            2.12s\n",
      "         7         348.6072            2.08s\n",
      "         8         307.5864            2.01s\n",
      "         9         280.9057            1.99s\n",
      "        10         255.2380            1.97s\n",
      "        20         113.5457            1.37s\n",
      "        30          56.0135            0.86s\n",
      "        40          33.1494            0.42s\n",
      "        50          20.9034            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         822.0385           12.51s\n",
      "         2         715.3814           11.96s\n",
      "         3         629.3323           12.16s\n",
      "         4         556.6520           12.35s\n",
      "         5         501.6827           12.40s\n",
      "         6         452.6233           12.33s\n",
      "         7         405.5171           12.40s\n",
      "         8         365.9942           12.43s\n",
      "         9         329.1382           12.45s\n",
      "        10         299.5150           12.50s\n",
      "        20         136.5623           11.04s\n",
      "        30          74.9230           10.46s\n",
      "        40          42.4078            9.39s\n",
      "        50          24.6338            8.48s\n",
      "        60          14.5993            7.67s\n",
      "        70           9.0301            6.95s\n",
      "        80           5.4786            6.37s\n",
      "        90           3.4187            5.76s\n",
      "       100           2.1518            5.17s\n",
      "       200           0.2903            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         828.6937           11.12s\n",
      "         2         728.4833           11.31s\n",
      "         3         642.4965           11.80s\n",
      "         4         567.5019           11.84s\n",
      "         5         506.3040           12.22s\n",
      "         6         455.7435           12.17s\n",
      "         7         409.4464           12.22s\n",
      "         8         370.0925           12.16s\n",
      "         9         337.8715           12.15s\n",
      "        10         313.6507           12.06s\n",
      "        20         142.7678           10.52s\n",
      "        30          73.3711            9.43s\n",
      "        40          43.2196            8.53s\n",
      "        50          26.1383            7.78s\n",
      "        60          16.5040            7.20s\n",
      "        70          10.3646            6.60s\n",
      "        80           7.5815            6.03s\n",
      "        90           5.7402            5.57s\n",
      "       100           4.6386            5.02s\n",
      "       200           2.9492            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         824.3973           11.42s\n",
      "         2         715.5848           11.07s\n",
      "         3         629.4745           11.21s\n",
      "         4         552.6802           11.74s\n",
      "         5         491.9764           12.24s\n",
      "         6         435.7023           12.31s\n",
      "         7         386.9113           12.41s\n",
      "         8         347.9123           12.44s\n",
      "         9         316.5921           12.40s\n",
      "        10         283.1994           12.51s\n",
      "        20         123.9978           11.16s\n",
      "        30          60.6661            9.93s\n",
      "        40          34.4439            9.10s\n",
      "        50          20.0023            8.41s\n",
      "        60          12.6879            7.74s\n",
      "        70           8.5308            7.07s\n",
      "        80           6.0769            6.46s\n",
      "        90           4.7589            5.93s\n",
      "       100           3.9905            5.30s\n",
      "       200           2.9221            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         822.0385           23.30s\n",
      "         2         715.3814           25.62s\n",
      "         3         629.3323           26.55s\n",
      "         4         556.6520           26.68s\n",
      "         5         501.6827           26.57s\n",
      "         6         452.6233           26.25s\n",
      "         7         405.5171           26.08s\n",
      "         8         365.9942           25.80s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         9         329.1382           25.50s\n",
      "        10         299.5150           25.75s\n",
      "        20         136.5623           23.74s\n",
      "        30          74.9230           21.62s\n",
      "        40          42.4078           21.07s\n",
      "        50          24.6338           20.01s\n",
      "        60          14.5993           18.99s\n",
      "        70           9.0301           18.40s\n",
      "        80           5.4786           17.74s\n",
      "        90           3.4187           16.87s\n",
      "       100           2.1518           16.17s\n",
      "       200           0.2903            7.45s\n",
      "       300           0.2903            2.57s\n",
      "       400           0.2903            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         828.7039           22.90s\n",
      "         2         728.5044           24.93s\n",
      "         3         642.4997           24.04s\n",
      "         4         572.1883           26.58s\n",
      "         5         508.2911           27.32s\n",
      "         6         457.6240           27.07s\n",
      "         7         411.9886           26.95s\n",
      "         8         373.9135           26.43s\n",
      "         9         341.6137           26.41s\n",
      "        10         312.6823           26.08s\n",
      "        20         144.4539           22.50s\n",
      "        30          77.9374           20.74s\n",
      "        40          43.6157           19.54s\n",
      "        50          25.6919           18.57s\n",
      "        60          16.2634           17.72s\n",
      "        70          10.8923           16.93s\n",
      "        80           7.5062           16.26s\n",
      "        90           5.5993           15.66s\n",
      "       100           4.6049           14.99s\n",
      "       200           2.9449            7.92s\n",
      "       300           2.8451            3.33s\n",
      "       400           2.8007            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         824.3973           20.51s\n",
      "         2         715.5848           25.32s\n",
      "         3         629.4745           26.02s\n",
      "         4         552.6802           27.03s\n",
      "         5         491.9764           26.22s\n",
      "         6         435.7023           26.28s\n",
      "         7         386.9113           26.03s\n",
      "         8         347.9123           25.80s\n",
      "         9         316.5921           25.65s\n",
      "        10         283.1994           25.94s\n",
      "        20         123.9978           23.00s\n",
      "        30          60.6661           21.75s\n",
      "        40          34.4439           20.19s\n",
      "        50          20.0023           19.19s\n",
      "        60          12.6879           18.26s\n",
      "        70           8.5308           17.41s\n",
      "        80           6.0769           16.70s\n",
      "        90           4.7589           16.03s\n",
      "       100           3.9905           15.29s\n",
      "       200           2.9221            7.75s\n",
      "       300           2.8329            3.36s\n",
      "       400           2.7973            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         799.0378           15.93s\n",
      "         2         690.0262           14.70s\n",
      "         3         615.4663           15.39s\n",
      "         4         555.8214           14.97s\n",
      "         5         510.5720           14.47s\n",
      "         6         465.4621           15.14s\n",
      "         7         434.6881           15.61s\n",
      "         8         400.2899           15.53s\n",
      "         9         371.0277           15.48s\n",
      "        10         351.7249           15.30s\n",
      "        20         198.7863           14.26s\n",
      "        30         124.6328           12.72s\n",
      "        40          85.3038           11.80s\n",
      "        50          57.9442           11.12s\n",
      "        60          40.4578           10.85s\n",
      "        70          28.6929           10.42s\n",
      "        80          19.1433           10.29s\n",
      "        90          13.8180            9.87s\n",
      "       100          10.0695            9.46s\n",
      "       200           0.3952            5.72s\n",
      "       300           0.2786            2.08s\n",
      "       400           0.2786            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         813.0001           12.35s\n",
      "         2         710.9569           13.90s\n",
      "         3         639.7983           13.54s\n",
      "         4         577.2828           15.27s\n",
      "         5         526.7618           15.53s\n",
      "         6         493.0485           15.34s\n",
      "         7         457.2273           15.24s\n",
      "         8         426.5096           15.80s\n",
      "         9         398.4491           15.52s\n",
      "        10         376.9240           15.26s\n",
      "        20         213.6312           13.10s\n",
      "        30         139.4203           12.00s\n",
      "        40          99.6407           11.45s\n",
      "        50          69.4904           11.14s\n",
      "        60          50.0102           11.01s\n",
      "        70          35.0985           10.66s\n",
      "        80          26.4938           10.31s\n",
      "        90          19.5750            9.85s\n",
      "       100          14.8396            9.49s\n",
      "       200           3.4392            5.71s\n",
      "       300           2.9436            2.50s\n",
      "       400           2.8572            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         812.6075           12.54s\n",
      "         2         708.6557           12.81s\n",
      "         3         630.3361           13.01s\n",
      "         4         561.6873           13.88s\n",
      "         5         511.4222           13.68s\n",
      "         6         471.1676           13.57s\n",
      "         7         440.9050           13.59s\n",
      "         8         406.7583           14.04s\n",
      "         9         373.4832           14.22s\n",
      "        10         351.7721           14.36s\n",
      "        20         200.2459           14.00s\n",
      "        30         126.6968           13.21s\n",
      "        40          90.2839           12.12s\n",
      "        50          62.8079           11.57s\n",
      "        60          44.8366           11.27s\n",
      "        70          31.5358           10.75s\n",
      "        80          23.4710           10.25s\n",
      "        90          18.3341            9.89s\n",
      "       100          14.2694            9.54s\n",
      "       200           3.3952            5.78s\n",
      "       300           2.9341            2.55s\n",
      "       400           2.8509            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         853.0999           30.07s\n",
      "         2         764.6109           29.20s\n",
      "         3         687.6349           29.39s\n",
      "         4         622.3924           30.38s\n",
      "         5         563.7971           31.34s\n",
      "         6         512.3920           31.95s\n",
      "         7         465.2922           31.63s\n",
      "         8         427.5498           31.35s\n",
      "         9         395.2378           31.11s\n",
      "        10         361.2415           31.63s\n",
      "        20         163.7684           27.82s\n",
      "        30          82.4143           25.62s\n",
      "        40          44.6711           24.87s\n",
      "        50          26.2400           23.65s\n",
      "        60          16.1871           22.97s\n",
      "        70           9.9769           21.84s\n",
      "        80           6.2867           20.78s\n",
      "        90           3.9547           19.89s\n",
      "       100           2.5233           19.75s\n",
      "       200           0.2970            9.92s\n",
      "       300           0.2970            3.39s\n",
      "       400           0.2970            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         859.4994           24.49s\n",
      "         2         772.7477           25.82s\n",
      "         3         697.6370           25.95s\n",
      "         4         637.2031           26.93s\n",
      "         5         579.0092           28.90s\n",
      "         6         526.3446           29.53s\n",
      "         7         479.1969           29.87s\n",
      "         8         439.3006           30.08s\n",
      "         9         401.4791           30.03s\n",
      "        10         368.1401           29.97s\n",
      "        20         165.7234           27.05s\n",
      "        30          84.2542           25.22s\n",
      "        40          45.8675           23.85s\n",
      "        50          27.3830           22.84s\n",
      "        60          16.6193           21.94s\n",
      "        70          10.8471           21.07s\n",
      "        80           7.7497           20.30s\n",
      "        90           5.8054           19.47s\n",
      "       100           4.5748           18.77s\n",
      "       200           2.9486            9.75s\n",
      "       300           2.8498            4.04s\n",
      "       400           2.8070            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         855.8250           24.09s\n",
      "         2         764.5254           25.92s\n",
      "         3         685.8235           26.42s\n",
      "         4         618.5435           27.17s\n",
      "         5         556.7600           29.10s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         6         504.9476           29.76s\n",
      "         7         455.7425           30.26s\n",
      "         8         413.7717           30.32s\n",
      "         9         375.9766           30.33s\n",
      "        10         341.7176           30.36s\n",
      "        20         148.6020           28.10s\n",
      "        30          71.5428           26.31s\n",
      "        40          38.5137           24.69s\n",
      "        50          22.0967           23.73s\n",
      "        60          13.6319           22.73s\n",
      "        70           9.2042           21.84s\n",
      "        80           6.5475           21.16s\n",
      "        90           5.0127           20.31s\n",
      "       100           4.0479           19.83s\n",
      "       200           2.9359           10.28s\n",
      "       300           2.8461            4.26s\n",
      "       400           2.8057            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         708.4170           15.10s\n",
      "         2         523.6427           16.35s\n",
      "         3         403.7190           17.40s\n",
      "         4         311.1610           17.63s\n",
      "         5         246.7533           18.04s\n",
      "         6         198.3845           18.14s\n",
      "         7         153.9167           18.47s\n",
      "         8         123.6779           18.90s\n",
      "         9         100.6714           18.89s\n",
      "        10          79.6656           18.71s\n",
      "        20          12.0738           16.98s\n",
      "        30           2.6934           15.01s\n",
      "        40           0.5978           13.86s\n",
      "        50           0.2979           11.68s\n",
      "        60           0.2900            9.22s\n",
      "        70           0.2900            7.40s\n",
      "        80           0.2900            6.02s\n",
      "        90           0.2900            4.94s\n",
      "       100           0.2900            4.09s\n",
      "       200           0.2900            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         697.8029           15.79s\n",
      "         2         523.0126           16.25s\n",
      "         3         398.2364           16.19s\n",
      "         4         304.1033           16.41s\n",
      "         5         243.1831           16.76s\n",
      "         6         191.2910           16.99s\n",
      "         7         155.6923           16.99s\n",
      "         8         122.8714           17.77s\n",
      "         9         100.7893           17.79s\n",
      "        10          80.6184           17.83s\n",
      "        20          15.2841           16.41s\n",
      "        30           5.2539           15.02s\n",
      "        40           3.3941           13.45s\n",
      "        50           3.0597           11.62s\n",
      "        60           2.9905            9.75s\n",
      "        70           2.9562            8.21s\n",
      "        80           2.9243            7.06s\n",
      "        90           2.8944            6.08s\n",
      "       100           2.8779            5.22s\n",
      "       200           2.7920            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         673.6112           15.29s\n",
      "         2         504.1490           16.50s\n",
      "         3         370.1978           17.76s\n",
      "         4         282.6421           18.24s\n",
      "         5         219.9422           18.41s\n",
      "         6         172.9498           18.44s\n",
      "         7         136.8851           18.44s\n",
      "         8         107.1456           18.67s\n",
      "         9          83.8470           18.79s\n",
      "        10          67.1108           18.63s\n",
      "        20          11.2022           16.69s\n",
      "        30           4.3576           14.91s\n",
      "        40           3.1517           13.23s\n",
      "        50           3.0240           11.23s\n",
      "        60           2.9775            9.43s\n",
      "        70           2.9443            8.04s\n",
      "        80           2.9071            6.93s\n",
      "        90           2.8815            5.99s\n",
      "       100           2.8614            5.17s\n",
      "       200           2.7893            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         890.1737            9.53s\n",
      "         2         832.0430            8.99s\n",
      "         3         781.7623            8.42s\n",
      "         4         737.9172            8.24s\n",
      "         5         701.0223            8.00s\n",
      "         6         667.6131            7.75s\n",
      "         7         639.0464            7.76s\n",
      "         8         611.7206            7.92s\n",
      "         9         584.5223            7.81s\n",
      "        10         563.2669            7.89s\n",
      "        20         409.6223            6.71s\n",
      "        30         319.0232            6.00s\n",
      "        40         256.7186            5.48s\n",
      "        50         210.9805            5.17s\n",
      "        60         176.2429            4.70s\n",
      "        70         146.0250            4.30s\n",
      "        80         124.7423            3.93s\n",
      "        90         107.2370            3.62s\n",
      "       100          90.3323            3.27s\n",
      "       200          22.0815            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         896.1755            8.24s\n",
      "         2         841.3665            7.56s\n",
      "         3         794.2774            7.14s\n",
      "         4         754.5961            7.41s\n",
      "         5         716.6821            7.42s\n",
      "         6         683.2131            7.21s\n",
      "         7         652.6319            7.17s\n",
      "         8         625.6243            7.11s\n",
      "         9         601.8899            7.25s\n",
      "        10         579.2199            7.23s\n",
      "        20         423.1347            7.28s\n",
      "        30         329.3275            6.73s\n",
      "        40         263.4202            6.24s\n",
      "        50         218.4464            5.54s\n",
      "        60         182.5120            5.05s\n",
      "        70         153.3468            4.57s\n",
      "        80         130.8419            4.14s\n",
      "        90         113.1481            3.73s\n",
      "       100          96.5491            3.36s\n",
      "       200          26.4469            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         898.9785            6.16s\n",
      "         2         840.9816            6.67s\n",
      "         3         792.6112            6.85s\n",
      "         4         750.3097            6.85s\n",
      "         5         710.9905            6.77s\n",
      "         6         671.6879            6.73s\n",
      "         7         641.6022            6.81s\n",
      "         8         614.3042            7.01s\n",
      "         9         590.0703            6.98s\n",
      "        10         564.0860            6.86s\n",
      "        20         399.8106            6.14s\n",
      "        30         307.9026            5.57s\n",
      "        40         246.6112            5.08s\n",
      "        50         200.2455            4.67s\n",
      "        60         170.1706            4.28s\n",
      "        70         143.3018            3.97s\n",
      "        80         121.2743            3.63s\n",
      "        90         104.7780            3.32s\n",
      "       100          89.7540            3.00s\n",
      "       200          23.2855            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         865.5324            2.62s\n",
      "         2         787.8253            2.77s\n",
      "         3         720.4137            2.70s\n",
      "         4         660.6764            2.62s\n",
      "         5         609.0685            2.65s\n",
      "         6         562.5646            2.66s\n",
      "         7         524.5905            2.60s\n",
      "         8         489.9452            2.55s\n",
      "         9         453.7401            2.55s\n",
      "        10         423.6242            2.48s\n",
      "        20         230.7615            1.72s\n",
      "        30         136.1880            1.09s\n",
      "        40          87.6508            0.54s\n",
      "        50          58.7530            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         869.5143            2.62s\n",
      "         2         794.2058            2.72s\n",
      "         3         732.7504            2.74s\n",
      "         4         672.5214            2.83s\n",
      "         5         623.6009            2.78s\n",
      "         6         574.9443            2.69s\n",
      "         7         534.4609            2.64s\n",
      "         8         496.4090            2.55s\n",
      "         9         458.1969            2.49s\n",
      "        10         430.9337            2.46s\n",
      "        20         239.6316            1.71s\n",
      "        30         140.9487            1.10s\n",
      "        40          91.5458            0.53s\n",
      "        50          63.0340            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         870.1014            3.11s\n",
      "         2         788.3053            2.86s\n",
      "         3         717.9021            2.76s\n",
      "         4         655.9954            2.65s\n",
      "         5         603.0493            2.70s\n",
      "         6         557.4933            2.65s\n",
      "         7         515.1476            2.61s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         8         475.3743            2.56s\n",
      "         9         444.8124            2.50s\n",
      "        10         412.0239            2.44s\n",
      "        20         207.7108            1.73s\n",
      "        30         121.6741            1.11s\n",
      "        40          75.9779            0.54s\n",
      "        50          49.9147            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         918.4076           10.13s\n",
      "         2         879.1327           10.18s\n",
      "         3         843.4398            9.70s\n",
      "         4         810.8774            9.66s\n",
      "         5         780.9824            9.50s\n",
      "         6         752.8327            9.39s\n",
      "         7         726.7030            9.37s\n",
      "         8         701.5674            9.32s\n",
      "         9         678.9798            9.26s\n",
      "        10         657.8733            9.19s\n",
      "        20         487.7309            7.95s\n",
      "        30         381.7082            7.19s\n",
      "        40         310.8836            6.72s\n",
      "        50         256.4365            6.30s\n",
      "        60         214.7730            5.77s\n",
      "        70         184.4263            5.32s\n",
      "        80         158.8348            4.87s\n",
      "        90         136.8556            4.46s\n",
      "       100         118.2721            4.02s\n",
      "       200          32.3618            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         921.4714            7.94s\n",
      "         2         885.5005            9.39s\n",
      "         3         852.0774            9.21s\n",
      "         4         821.0690            9.19s\n",
      "         5         792.3766            8.97s\n",
      "         6         766.4434            9.20s\n",
      "         7         740.5509            9.45s\n",
      "         8         716.3901            9.34s\n",
      "         9         692.7279            9.36s\n",
      "        10         670.8124            9.26s\n",
      "        20         509.0452            8.13s\n",
      "        30         402.3008            7.37s\n",
      "        40         327.3014            6.75s\n",
      "        50         268.1908            6.21s\n",
      "        60         221.8232            5.73s\n",
      "        70         187.2019            5.26s\n",
      "        80         160.6106            4.85s\n",
      "        90         138.1897            4.42s\n",
      "       100         120.9290            4.01s\n",
      "       200          36.6895            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         923.7892            8.24s\n",
      "         2         885.2023            8.40s\n",
      "         3         850.4077            8.65s\n",
      "         4         817.4821            8.90s\n",
      "         5         787.6066            9.17s\n",
      "         6         759.6390            9.55s\n",
      "         7         733.3437            9.43s\n",
      "         8         709.0379            9.31s\n",
      "         9         684.1679            9.24s\n",
      "        10         662.1202            9.24s\n",
      "        20         484.6796            8.19s\n",
      "        30         375.6206            7.43s\n",
      "        40         300.3277            6.88s\n",
      "        50         244.7794            6.31s\n",
      "        60         200.7061            5.82s\n",
      "        70         172.2549            5.31s\n",
      "        80         146.4746            4.91s\n",
      "        90         127.2920            4.48s\n",
      "       100         110.1672            4.14s\n",
      "       200          30.7985            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         830.2329            2.27s\n",
      "         2         745.2216            2.37s\n",
      "         3         683.0169            2.37s\n",
      "         4         636.3738            2.46s\n",
      "         5         597.3052            2.53s\n",
      "         6         566.7896            2.47s\n",
      "         7         534.1445            2.45s\n",
      "         8         508.3332            2.45s\n",
      "         9         482.7871            2.43s\n",
      "        10         459.0742            2.50s\n",
      "        20         336.7695            2.19s\n",
      "        30         252.0328            1.86s\n",
      "        40         190.6954            1.58s\n",
      "        50         149.3146            1.28s\n",
      "        60         117.1640            1.02s\n",
      "        70          95.1727            0.76s\n",
      "        80          77.1291            0.50s\n",
      "        90          61.7356            0.25s\n",
      "       100          50.6965            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         838.4050            2.67s\n",
      "         2         751.3515            2.86s\n",
      "         3         693.5356            2.69s\n",
      "         4         643.3247            2.63s\n",
      "         5         604.8577            2.74s\n",
      "         6         577.4080            2.69s\n",
      "         7         545.2869            2.61s\n",
      "         8         517.4271            2.63s\n",
      "         9         498.2051            2.59s\n",
      "        10         478.1146            2.63s\n",
      "        20         328.8117            2.10s\n",
      "        30         249.4077            1.78s\n",
      "        40         193.0539            1.51s\n",
      "        50         150.3747            1.26s\n",
      "        60         124.2827            1.00s\n",
      "        70         103.2003            0.75s\n",
      "        80          84.2754            0.51s\n",
      "        90          69.6280            0.25s\n",
      "       100          58.1960            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         838.5282            2.82s\n",
      "         2         751.0901            2.69s\n",
      "         3         686.7835            2.71s\n",
      "         4         639.1714            2.89s\n",
      "         5         598.2801            2.78s\n",
      "         6         563.0051            2.84s\n",
      "         7         533.1257            2.82s\n",
      "         8         505.7751            2.81s\n",
      "         9         481.4549            2.84s\n",
      "        10         461.7804            2.75s\n",
      "        20         323.1508            2.15s\n",
      "        30         244.1836            1.86s\n",
      "        40         190.9428            1.55s\n",
      "        50         149.3276            1.26s\n",
      "        60         118.9443            0.99s\n",
      "        70          97.6773            0.73s\n",
      "        80          81.3555            0.48s\n",
      "        90          67.4391            0.24s\n",
      "       100          55.9162            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         830.2329           11.55s\n",
      "         2         745.2216           11.02s\n",
      "         3         683.0169           10.63s\n",
      "         4         636.3736           10.42s\n",
      "         5         597.3049           10.49s\n",
      "         6         566.7893           10.39s\n",
      "         7         534.1443           10.59s\n",
      "         8         508.3327           10.59s\n",
      "         9         482.7869           10.60s\n",
      "        10         459.0740           10.53s\n",
      "        20         336.7690            9.50s\n",
      "        30         252.0326            8.84s\n",
      "        40         190.6951            8.54s\n",
      "        50         149.3142            8.32s\n",
      "        60         117.1637            8.23s\n",
      "        70          95.1724            7.96s\n",
      "        80          77.1290            7.61s\n",
      "        90          61.7355            7.28s\n",
      "       100          50.6964            6.99s\n",
      "       200           7.8222            4.42s\n",
      "       300           1.3228            2.20s\n",
      "       400           0.2847            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         838.4050           11.95s\n",
      "         2         751.3515           11.02s\n",
      "         3         693.5356           11.76s\n",
      "         4         643.3247           11.96s\n",
      "         5         604.8577           12.14s\n",
      "         6         577.4080           12.35s\n",
      "         7         545.2869           12.38s\n",
      "         8         517.4271           12.13s\n",
      "         9         498.2051           12.27s\n",
      "        10         478.1146           12.22s\n",
      "        20         328.8117           10.95s\n",
      "        30         249.4077            9.74s\n",
      "        40         193.0539            9.41s\n",
      "        50         150.3747            8.96s\n",
      "        60         124.2827            8.63s\n",
      "        70         103.2003            8.23s\n",
      "        80          84.2754            7.97s\n",
      "        90          69.6280            7.71s\n",
      "       100          58.1960            7.42s\n",
      "       200          12.8406            4.37s\n",
      "       300           4.8243            2.07s\n",
      "       400           3.2983            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         838.5282           13.94s\n",
      "         2         751.0901           14.40s\n",
      "         3         686.7835           13.87s\n",
      "         4         639.1714           13.64s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         5         598.2801           14.47s\n",
      "         6         563.0051           13.89s\n",
      "         7         533.1257           13.34s\n",
      "         8         505.7751           12.91s\n",
      "         9         481.4549           12.68s\n",
      "        10         461.7804           12.57s\n",
      "        20         323.1508           10.74s\n",
      "        30         244.1836           10.04s\n",
      "        40         190.9428            9.27s\n",
      "        50         149.3276            8.79s\n",
      "        60         118.9443            8.35s\n",
      "        70          97.6773            8.12s\n",
      "        80          81.3555            7.82s\n",
      "        90          67.4391            7.62s\n",
      "       100          55.9162            7.28s\n",
      "       200          11.5267            4.30s\n",
      "       300           4.6067            2.06s\n",
      "       400           3.1792            0.00s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  36 out of  36 | elapsed:  4.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1        1268.6124            3.90s\n",
      "         2        1146.5145            3.72s\n",
      "         3        1059.9787            3.74s\n",
      "         4         996.5656            3.58s\n",
      "         5         939.6297            3.55s\n",
      "         6         892.3967            3.49s\n",
      "         7         854.5186            3.51s\n",
      "         8         821.3824            3.50s\n",
      "         9         792.2583            3.44s\n",
      "        10         765.8411            3.45s\n",
      "        20         558.7046            2.90s\n",
      "        30         443.4323            2.50s\n",
      "        40         360.9052            2.08s\n",
      "        50         303.5657            1.71s\n",
      "        60         258.3610            1.34s\n",
      "        70         220.5624            0.99s\n",
      "        80         186.8658            0.65s\n",
      "        90         160.0936            0.33s\n",
      "       100         139.1432            0.00s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=None, error_score='raise',\n",
       "          estimator=GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=6,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=320,\n",
       "              presort='auto', random_state=None, subsample=1.0, verbose=1,\n",
       "              warm_start=False),\n",
       "          fit_params=None, iid=True, n_iter=12, n_jobs=1,\n",
       "          param_distributions={'learning_rate': [0.1, 0.05, 0.15, 0.25], 'n_estimators': [50, 100, 200, 400], 'max_depth': [3, 4, 5, 6, 7, 8]},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score=True, scoring=None, verbose=1)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbParams = { #'verbose' : [1],\n",
    "             'learning_rate':[0.1,0.05,0.15,0.25],  \n",
    "             'n_estimators' :[50, 100, 200, 400], \n",
    "             'max_depth'    :[3,4,5,6,7,8]}\n",
    "gbRSCV = RandomizedSearchCV(gbc, gbParams, verbose=1, return_train_score=True, n_iter=12) #, n_jobs=-1)\n",
    "gbRSCV.fit(vectTexts_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.520084</td>\n",
       "      <td>0.216704</td>\n",
       "      <td>0.019131</td>\n",
       "      <td>0.000940</td>\n",
       "      <td>200</td>\n",
       "      <td>6</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'n_estimators': 200, 'max_depth': 6, 'learning_rate': 0.05}</td>\n",
       "      <td>0.739806</td>\n",
       "      <td>0.755340</td>\n",
       "      <td>0.726562</td>\n",
       "      <td>0.740597</td>\n",
       "      <td>0.011756</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998053</td>\n",
       "      <td>0.998058</td>\n",
       "      <td>0.998704</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.105207</td>\n",
       "      <td>0.048376</td>\n",
       "      <td>0.006821</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>{'n_estimators': 50, 'max_depth': 5, 'learning_rate': 0.25}</td>\n",
       "      <td>0.733981</td>\n",
       "      <td>0.745631</td>\n",
       "      <td>0.730469</td>\n",
       "      <td>0.736706</td>\n",
       "      <td>0.006481</td>\n",
       "      <td>11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998053</td>\n",
       "      <td>0.998058</td>\n",
       "      <td>0.998704</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.958127</td>\n",
       "      <td>0.534730</td>\n",
       "      <td>0.016138</td>\n",
       "      <td>0.001697</td>\n",
       "      <td>200</td>\n",
       "      <td>6</td>\n",
       "      <td>0.15</td>\n",
       "      <td>{'n_estimators': 200, 'max_depth': 6, 'learning_rate': 0.15}</td>\n",
       "      <td>0.726214</td>\n",
       "      <td>0.763107</td>\n",
       "      <td>0.734375</td>\n",
       "      <td>0.741245</td>\n",
       "      <td>0.015835</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998053</td>\n",
       "      <td>0.998058</td>\n",
       "      <td>0.998704</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.781545</td>\n",
       "      <td>1.971219</td>\n",
       "      <td>0.020627</td>\n",
       "      <td>0.003999</td>\n",
       "      <td>400</td>\n",
       "      <td>6</td>\n",
       "      <td>0.15</td>\n",
       "      <td>{'n_estimators': 400, 'max_depth': 6, 'learning_rate': 0.15}</td>\n",
       "      <td>0.728155</td>\n",
       "      <td>0.768932</td>\n",
       "      <td>0.736328</td>\n",
       "      <td>0.744488</td>\n",
       "      <td>0.017628</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998053</td>\n",
       "      <td>0.998058</td>\n",
       "      <td>0.998704</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.341725</td>\n",
       "      <td>1.322557</td>\n",
       "      <td>0.016801</td>\n",
       "      <td>0.002010</td>\n",
       "      <td>400</td>\n",
       "      <td>4</td>\n",
       "      <td>0.25</td>\n",
       "      <td>{'n_estimators': 400, 'max_depth': 4, 'learning_rate': 0.25}</td>\n",
       "      <td>0.749515</td>\n",
       "      <td>0.776699</td>\n",
       "      <td>0.720703</td>\n",
       "      <td>0.749027</td>\n",
       "      <td>0.022852</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998053</td>\n",
       "      <td>0.998058</td>\n",
       "      <td>0.998704</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>13.532249</td>\n",
       "      <td>2.239174</td>\n",
       "      <td>0.025285</td>\n",
       "      <td>0.005240</td>\n",
       "      <td>400</td>\n",
       "      <td>7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'n_estimators': 400, 'max_depth': 7, 'learning_rate': 0.1}</td>\n",
       "      <td>0.732039</td>\n",
       "      <td>0.763107</td>\n",
       "      <td>0.738281</td>\n",
       "      <td>0.744488</td>\n",
       "      <td>0.013429</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998053</td>\n",
       "      <td>0.998058</td>\n",
       "      <td>0.998704</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.416456</td>\n",
       "      <td>1.425685</td>\n",
       "      <td>0.012975</td>\n",
       "      <td>0.002852</td>\n",
       "      <td>200</td>\n",
       "      <td>8</td>\n",
       "      <td>0.25</td>\n",
       "      <td>{'n_estimators': 200, 'max_depth': 8, 'learning_rate': 0.25}</td>\n",
       "      <td>0.737864</td>\n",
       "      <td>0.766990</td>\n",
       "      <td>0.728516</td>\n",
       "      <td>0.744488</td>\n",
       "      <td>0.016385</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998053</td>\n",
       "      <td>0.998058</td>\n",
       "      <td>0.998704</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6.087736</td>\n",
       "      <td>0.314287</td>\n",
       "      <td>0.013142</td>\n",
       "      <td>0.000623</td>\n",
       "      <td>200</td>\n",
       "      <td>4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'n_estimators': 200, 'max_depth': 4, 'learning_rate': 0.1}</td>\n",
       "      <td>0.745631</td>\n",
       "      <td>0.766990</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.743839</td>\n",
       "      <td>0.019725</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998053</td>\n",
       "      <td>0.998058</td>\n",
       "      <td>0.998704</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.649791</td>\n",
       "      <td>0.031695</td>\n",
       "      <td>0.007653</td>\n",
       "      <td>0.000471</td>\n",
       "      <td>50</td>\n",
       "      <td>6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'n_estimators': 50, 'max_depth': 6, 'learning_rate': 0.1}</td>\n",
       "      <td>0.718447</td>\n",
       "      <td>0.755340</td>\n",
       "      <td>0.722656</td>\n",
       "      <td>0.732166</td>\n",
       "      <td>0.016500</td>\n",
       "      <td>12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998053</td>\n",
       "      <td>0.998058</td>\n",
       "      <td>0.998704</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7.710826</td>\n",
       "      <td>0.183527</td>\n",
       "      <td>0.015804</td>\n",
       "      <td>0.000849</td>\n",
       "      <td>200</td>\n",
       "      <td>5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.05}</td>\n",
       "      <td>0.743689</td>\n",
       "      <td>0.763107</td>\n",
       "      <td>0.726562</td>\n",
       "      <td>0.744488</td>\n",
       "      <td>0.014923</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998053</td>\n",
       "      <td>0.998058</td>\n",
       "      <td>0.998704</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.475188</td>\n",
       "      <td>0.045219</td>\n",
       "      <td>0.007319</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>0.25</td>\n",
       "      <td>{'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.25}</td>\n",
       "      <td>0.747573</td>\n",
       "      <td>0.788350</td>\n",
       "      <td>0.724609</td>\n",
       "      <td>0.753567</td>\n",
       "      <td>0.026353</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998053</td>\n",
       "      <td>0.998058</td>\n",
       "      <td>0.998704</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>8.392077</td>\n",
       "      <td>0.422783</td>\n",
       "      <td>0.018964</td>\n",
       "      <td>0.002117</td>\n",
       "      <td>400</td>\n",
       "      <td>3</td>\n",
       "      <td>0.25</td>\n",
       "      <td>{'n_estimators': 400, 'max_depth': 3, 'learning_rate': 0.25}</td>\n",
       "      <td>0.743689</td>\n",
       "      <td>0.776699</td>\n",
       "      <td>0.722656</td>\n",
       "      <td>0.747730</td>\n",
       "      <td>0.022237</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998053</td>\n",
       "      <td>0.998058</td>\n",
       "      <td>0.998704</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       10.520084      0.216704         0.019131        0.000940   \n",
       "1        2.105207      0.048376         0.006821        0.000235   \n",
       "2        7.958127      0.534730         0.016138        0.001697   \n",
       "3       10.781545      1.971219         0.020627        0.003999   \n",
       "4        8.341725      1.322557         0.016801        0.002010   \n",
       "5       13.532249      2.239174         0.025285        0.005240   \n",
       "6        6.416456      1.425685         0.012975        0.002852   \n",
       "7        6.087736      0.314287         0.013142        0.000623   \n",
       "8        2.649791      0.031695         0.007653        0.000471   \n",
       "9        7.710826      0.183527         0.015804        0.000849   \n",
       "10       2.475188      0.045219         0.007319        0.000235   \n",
       "11       8.392077      0.422783         0.018964        0.002117   \n",
       "\n",
       "   param_n_estimators param_max_depth param_learning_rate  \\\n",
       "0                 200               6                0.05   \n",
       "1                  50               5                0.25   \n",
       "2                 200               6                0.15   \n",
       "3                 400               6                0.15   \n",
       "4                 400               4                0.25   \n",
       "5                 400               7                 0.1   \n",
       "6                 200               8                0.25   \n",
       "7                 200               4                 0.1   \n",
       "8                  50               6                 0.1   \n",
       "9                 200               5                0.05   \n",
       "10                100               3                0.25   \n",
       "11                400               3                0.25   \n",
       "\n",
       "                                                          params  \\\n",
       "0   {'n_estimators': 200, 'max_depth': 6, 'learning_rate': 0.05}   \n",
       "1    {'n_estimators': 50, 'max_depth': 5, 'learning_rate': 0.25}   \n",
       "2   {'n_estimators': 200, 'max_depth': 6, 'learning_rate': 0.15}   \n",
       "3   {'n_estimators': 400, 'max_depth': 6, 'learning_rate': 0.15}   \n",
       "4   {'n_estimators': 400, 'max_depth': 4, 'learning_rate': 0.25}   \n",
       "5    {'n_estimators': 400, 'max_depth': 7, 'learning_rate': 0.1}   \n",
       "6   {'n_estimators': 200, 'max_depth': 8, 'learning_rate': 0.25}   \n",
       "7    {'n_estimators': 200, 'max_depth': 4, 'learning_rate': 0.1}   \n",
       "8     {'n_estimators': 50, 'max_depth': 6, 'learning_rate': 0.1}   \n",
       "9   {'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.05}   \n",
       "10  {'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.25}   \n",
       "11  {'n_estimators': 400, 'max_depth': 3, 'learning_rate': 0.25}   \n",
       "\n",
       "    split0_test_score  split1_test_score  split2_test_score  mean_test_score  \\\n",
       "0            0.739806           0.755340           0.726562         0.740597   \n",
       "1            0.733981           0.745631           0.730469         0.736706   \n",
       "2            0.726214           0.763107           0.734375         0.741245   \n",
       "3            0.728155           0.768932           0.736328         0.744488   \n",
       "4            0.749515           0.776699           0.720703         0.749027   \n",
       "5            0.732039           0.763107           0.738281         0.744488   \n",
       "6            0.737864           0.766990           0.728516         0.744488   \n",
       "7            0.745631           0.766990           0.718750         0.743839   \n",
       "8            0.718447           0.755340           0.722656         0.732166   \n",
       "9            0.743689           0.763107           0.726562         0.744488   \n",
       "10           0.747573           0.788350           0.724609         0.753567   \n",
       "11           0.743689           0.776699           0.722656         0.747730   \n",
       "\n",
       "    std_test_score  rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0         0.011756               10                 1.0            0.998053   \n",
       "1         0.006481               11                 1.0            0.998053   \n",
       "2         0.015835                9                 1.0            0.998053   \n",
       "3         0.017628                4                 1.0            0.998053   \n",
       "4         0.022852                2                 1.0            0.998053   \n",
       "5         0.013429                4                 1.0            0.998053   \n",
       "6         0.016385                4                 1.0            0.998053   \n",
       "7         0.019725                8                 1.0            0.998053   \n",
       "8         0.016500               12                 1.0            0.998053   \n",
       "9         0.014923                4                 1.0            0.998053   \n",
       "10        0.026353                1                 1.0            0.998053   \n",
       "11        0.022237                3                 1.0            0.998053   \n",
       "\n",
       "    split2_train_score  mean_train_score  std_train_score  \n",
       "0             0.998058          0.998704         0.000917  \n",
       "1             0.998058          0.998704         0.000917  \n",
       "2             0.998058          0.998704         0.000917  \n",
       "3             0.998058          0.998704         0.000917  \n",
       "4             0.998058          0.998704         0.000917  \n",
       "5             0.998058          0.998704         0.000917  \n",
       "6             0.998058          0.998704         0.000917  \n",
       "7             0.998058          0.998704         0.000917  \n",
       "8             0.998058          0.998704         0.000917  \n",
       "9             0.998058          0.998704         0.000917  \n",
       "10            0.998058          0.998704         0.000917  \n",
       "11            0.998058          0.998704         0.000917  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(gbRSCV.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7267441860465116"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbRSCV.best_estimator_.score(vectTexts_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=2, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=1e-05, verbose=1)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "sksvc = SVC(verbose=1, gamma=0.1, tol=1e-5, C=2, kernel='rbf')\n",
    "sksvc.fit(vectTexts_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.9766536964980544 Test score: 0.7325581395348837\n"
     ]
    }
   ],
   "source": [
    "print('Train score: {} Test score: {}'.format(sksvc.score(vectTexts_train, y_train),sksvc.score(vectTexts_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n",
      "[LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 360 out of 360 | elapsed:  1.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=None, error_score='raise',\n",
       "          estimator=SVC(C=2, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=1e-05, verbose=1),\n",
       "          fit_params=None, iid=True, n_iter=120, n_jobs=1,\n",
       "          param_distributions={'gamma': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000023BAD919940>, 'C': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000023BAD919E80>, 'shrinking': [True, False]},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score=True, scoring=None, verbose=1)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.stats\n",
    "\n",
    "svmParams = { #'verbose' : [1],\n",
    "             'gamma': scipy.stats.uniform(0.005,0.15),#[0.1,0.01,0.02,0.04,0.08],  \n",
    "             'C' : scipy.stats.uniform(0.01,50),#[0.1,10,15, 20,25,40], \n",
    "             'shrinking'    :[True, False]}\n",
    "svmRSCV = RandomizedSearchCV(sksvc, svmParams, verbose=1, return_train_score=True, n_iter=120) #, n_jobs=-1)\n",
    "svmRSCV.fit(vectTexts_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_shrinking</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.206772</td>\n",
       "      <td>0.016503</td>\n",
       "      <td>0.037929</td>\n",
       "      <td>0.001078</td>\n",
       "      <td>26.8431</td>\n",
       "      <td>0.0625746</td>\n",
       "      <td>True</td>\n",
       "      <td>{'C': 26.843146649758435, 'gamma': 0.06257463787001483, 'shrinking': True}</td>\n",
       "      <td>0.745631</td>\n",
       "      <td>0.768932</td>\n",
       "      <td>0.757812</td>\n",
       "      <td>0.757458</td>\n",
       "      <td>0.009525</td>\n",
       "      <td>47</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998053</td>\n",
       "      <td>0.997087</td>\n",
       "      <td>0.998380</td>\n",
       "      <td>0.001211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.195129</td>\n",
       "      <td>0.004592</td>\n",
       "      <td>0.035267</td>\n",
       "      <td>0.002009</td>\n",
       "      <td>22.4475</td>\n",
       "      <td>0.0363221</td>\n",
       "      <td>False</td>\n",
       "      <td>{'C': 22.44749386324993, 'gamma': 0.036322051852327356, 'shrinking': False}</td>\n",
       "      <td>0.735922</td>\n",
       "      <td>0.766990</td>\n",
       "      <td>0.759766</td>\n",
       "      <td>0.754215</td>\n",
       "      <td>0.013285</td>\n",
       "      <td>60</td>\n",
       "      <td>0.993184</td>\n",
       "      <td>0.990263</td>\n",
       "      <td>0.993204</td>\n",
       "      <td>0.992217</td>\n",
       "      <td>0.001382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.205608</td>\n",
       "      <td>0.008843</td>\n",
       "      <td>0.038427</td>\n",
       "      <td>0.000816</td>\n",
       "      <td>38.0444</td>\n",
       "      <td>0.0670948</td>\n",
       "      <td>True</td>\n",
       "      <td>{'C': 38.04436336060919, 'gamma': 0.06709482544061485, 'shrinking': True}</td>\n",
       "      <td>0.745631</td>\n",
       "      <td>0.768932</td>\n",
       "      <td>0.767578</td>\n",
       "      <td>0.760700</td>\n",
       "      <td>0.010685</td>\n",
       "      <td>38</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998053</td>\n",
       "      <td>0.998058</td>\n",
       "      <td>0.998704</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.197146</td>\n",
       "      <td>0.005944</td>\n",
       "      <td>0.031607</td>\n",
       "      <td>0.000848</td>\n",
       "      <td>32.0874</td>\n",
       "      <td>0.0249578</td>\n",
       "      <td>False</td>\n",
       "      <td>{'C': 32.08740962348253, 'gamma': 0.024957754470274603, 'shrinking': False}</td>\n",
       "      <td>0.724272</td>\n",
       "      <td>0.774757</td>\n",
       "      <td>0.763672</td>\n",
       "      <td>0.754215</td>\n",
       "      <td>0.021681</td>\n",
       "      <td>60</td>\n",
       "      <td>0.988315</td>\n",
       "      <td>0.983447</td>\n",
       "      <td>0.991262</td>\n",
       "      <td>0.987675</td>\n",
       "      <td>0.003223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.186367</td>\n",
       "      <td>0.003871</td>\n",
       "      <td>0.041255</td>\n",
       "      <td>0.001026</td>\n",
       "      <td>37.8021</td>\n",
       "      <td>0.153958</td>\n",
       "      <td>False</td>\n",
       "      <td>{'C': 37.80214090102072, 'gamma': 0.15395843390724673, 'shrinking': False}</td>\n",
       "      <td>0.735922</td>\n",
       "      <td>0.739806</td>\n",
       "      <td>0.724609</td>\n",
       "      <td>0.733463</td>\n",
       "      <td>0.006441</td>\n",
       "      <td>119</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998053</td>\n",
       "      <td>0.998058</td>\n",
       "      <td>0.998704</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.201326</td>\n",
       "      <td>0.004043</td>\n",
       "      <td>0.040091</td>\n",
       "      <td>0.000624</td>\n",
       "      <td>32.3605</td>\n",
       "      <td>0.11183</td>\n",
       "      <td>True</td>\n",
       "      <td>{'C': 32.36054590904825, 'gamma': 0.11183037825704656, 'shrinking': True}</td>\n",
       "      <td>0.741748</td>\n",
       "      <td>0.770874</td>\n",
       "      <td>0.742188</td>\n",
       "      <td>0.751621</td>\n",
       "      <td>0.013635</td>\n",
       "      <td>74</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998053</td>\n",
       "      <td>0.998058</td>\n",
       "      <td>0.998704</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.199745</td>\n",
       "      <td>0.003705</td>\n",
       "      <td>0.038593</td>\n",
       "      <td>0.001025</td>\n",
       "      <td>25.605</td>\n",
       "      <td>0.0993973</td>\n",
       "      <td>True</td>\n",
       "      <td>{'C': 25.605038158792023, 'gamma': 0.09939727196250232, 'shrinking': True}</td>\n",
       "      <td>0.747573</td>\n",
       "      <td>0.765049</td>\n",
       "      <td>0.744141</td>\n",
       "      <td>0.752270</td>\n",
       "      <td>0.009157</td>\n",
       "      <td>71</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998053</td>\n",
       "      <td>0.998058</td>\n",
       "      <td>0.998704</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.173878</td>\n",
       "      <td>0.015276</td>\n",
       "      <td>0.032272</td>\n",
       "      <td>0.000623</td>\n",
       "      <td>28.4612</td>\n",
       "      <td>0.0323739</td>\n",
       "      <td>True</td>\n",
       "      <td>{'C': 28.46116634918059, 'gamma': 0.032373927693916706, 'shrinking': True}</td>\n",
       "      <td>0.730097</td>\n",
       "      <td>0.766990</td>\n",
       "      <td>0.757812</td>\n",
       "      <td>0.751621</td>\n",
       "      <td>0.015695</td>\n",
       "      <td>74</td>\n",
       "      <td>0.993184</td>\n",
       "      <td>0.989289</td>\n",
       "      <td>0.993204</td>\n",
       "      <td>0.991892</td>\n",
       "      <td>0.001841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.205110</td>\n",
       "      <td>0.003259</td>\n",
       "      <td>0.039923</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>27.4488</td>\n",
       "      <td>0.11082</td>\n",
       "      <td>True</td>\n",
       "      <td>{'C': 27.44884857837742, 'gamma': 0.11081997427336616, 'shrinking': True}</td>\n",
       "      <td>0.741748</td>\n",
       "      <td>0.770874</td>\n",
       "      <td>0.742188</td>\n",
       "      <td>0.751621</td>\n",
       "      <td>0.013635</td>\n",
       "      <td>74</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998053</td>\n",
       "      <td>0.998058</td>\n",
       "      <td>0.998704</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.164664</td>\n",
       "      <td>0.004749</td>\n",
       "      <td>0.032106</td>\n",
       "      <td>0.000622</td>\n",
       "      <td>9.66537</td>\n",
       "      <td>0.0290361</td>\n",
       "      <td>False</td>\n",
       "      <td>{'C': 9.665370580210976, 'gamma': 0.029036064169539157, 'shrinking': False}</td>\n",
       "      <td>0.747573</td>\n",
       "      <td>0.798058</td>\n",
       "      <td>0.765625</td>\n",
       "      <td>0.770428</td>\n",
       "      <td>0.020907</td>\n",
       "      <td>10</td>\n",
       "      <td>0.963973</td>\n",
       "      <td>0.966894</td>\n",
       "      <td>0.967961</td>\n",
       "      <td>0.966276</td>\n",
       "      <td>0.001686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.183855</td>\n",
       "      <td>0.008818</td>\n",
       "      <td>0.036430</td>\n",
       "      <td>0.001079</td>\n",
       "      <td>31.7197</td>\n",
       "      <td>0.0638521</td>\n",
       "      <td>True</td>\n",
       "      <td>{'C': 31.719696972737808, 'gamma': 0.06385206492431375, 'shrinking': True}</td>\n",
       "      <td>0.743689</td>\n",
       "      <td>0.768932</td>\n",
       "      <td>0.759766</td>\n",
       "      <td>0.757458</td>\n",
       "      <td>0.010443</td>\n",
       "      <td>47</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998053</td>\n",
       "      <td>0.997087</td>\n",
       "      <td>0.998380</td>\n",
       "      <td>0.001211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.190637</td>\n",
       "      <td>0.002544</td>\n",
       "      <td>0.036763</td>\n",
       "      <td>0.001026</td>\n",
       "      <td>45.7413</td>\n",
       "      <td>0.0699777</td>\n",
       "      <td>True</td>\n",
       "      <td>{'C': 45.74126636492902, 'gamma': 0.06997766538249371, 'shrinking': True}</td>\n",
       "      <td>0.749515</td>\n",
       "      <td>0.766990</td>\n",
       "      <td>0.767578</td>\n",
       "      <td>0.761349</td>\n",
       "      <td>0.008384</td>\n",
       "      <td>33</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998053</td>\n",
       "      <td>0.998058</td>\n",
       "      <td>0.998704</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.193311</td>\n",
       "      <td>0.007162</td>\n",
       "      <td>0.036599</td>\n",
       "      <td>0.000846</td>\n",
       "      <td>39.8217</td>\n",
       "      <td>0.0676294</td>\n",
       "      <td>True</td>\n",
       "      <td>{'C': 39.82174434562712, 'gamma': 0.06762938214352827, 'shrinking': True}</td>\n",
       "      <td>0.745631</td>\n",
       "      <td>0.768932</td>\n",
       "      <td>0.767578</td>\n",
       "      <td>0.760700</td>\n",
       "      <td>0.010685</td>\n",
       "      <td>38</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998053</td>\n",
       "      <td>0.998058</td>\n",
       "      <td>0.998704</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.186067</td>\n",
       "      <td>0.001823</td>\n",
       "      <td>0.042087</td>\n",
       "      <td>0.000849</td>\n",
       "      <td>44.7181</td>\n",
       "      <td>0.142868</td>\n",
       "      <td>False</td>\n",
       "      <td>{'C': 44.71806854322029, 'gamma': 0.1428682850658086, 'shrinking': False}</td>\n",
       "      <td>0.739806</td>\n",
       "      <td>0.743689</td>\n",
       "      <td>0.732422</td>\n",
       "      <td>0.738651</td>\n",
       "      <td>0.004670</td>\n",
       "      <td>106</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998053</td>\n",
       "      <td>0.998058</td>\n",
       "      <td>0.998704</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.185299</td>\n",
       "      <td>0.005202</td>\n",
       "      <td>0.041255</td>\n",
       "      <td>0.001245</td>\n",
       "      <td>37.3369</td>\n",
       "      <td>0.126325</td>\n",
       "      <td>False</td>\n",
       "      <td>{'C': 37.33689716333579, 'gamma': 0.12632526634397404, 'shrinking': False}</td>\n",
       "      <td>0.743689</td>\n",
       "      <td>0.759223</td>\n",
       "      <td>0.734375</td>\n",
       "      <td>0.745785</td>\n",
       "      <td>0.010247</td>\n",
       "      <td>90</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998053</td>\n",
       "      <td>0.998058</td>\n",
       "      <td>0.998704</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.183953</td>\n",
       "      <td>0.001065</td>\n",
       "      <td>0.040424</td>\n",
       "      <td>0.000407</td>\n",
       "      <td>18.2976</td>\n",
       "      <td>0.120514</td>\n",
       "      <td>False</td>\n",
       "      <td>{'C': 18.297624376911784, 'gamma': 0.12051449434090082, 'shrinking': False}</td>\n",
       "      <td>0.743689</td>\n",
       "      <td>0.761165</td>\n",
       "      <td>0.736328</td>\n",
       "      <td>0.747082</td>\n",
       "      <td>0.010415</td>\n",
       "      <td>82</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998053</td>\n",
       "      <td>0.998058</td>\n",
       "      <td>0.998704</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.167557</td>\n",
       "      <td>0.013850</td>\n",
       "      <td>0.031939</td>\n",
       "      <td>0.000705</td>\n",
       "      <td>31.9354</td>\n",
       "      <td>0.0270223</td>\n",
       "      <td>True</td>\n",
       "      <td>{'C': 31.935409507119754, 'gamma': 0.02702228294374617, 'shrinking': True}</td>\n",
       "      <td>0.726214</td>\n",
       "      <td>0.770874</td>\n",
       "      <td>0.761719</td>\n",
       "      <td>0.752918</td>\n",
       "      <td>0.019276</td>\n",
       "      <td>67</td>\n",
       "      <td>0.989289</td>\n",
       "      <td>0.984421</td>\n",
       "      <td>0.991262</td>\n",
       "      <td>0.988324</td>\n",
       "      <td>0.002875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.165020</td>\n",
       "      <td>0.005194</td>\n",
       "      <td>0.036265</td>\n",
       "      <td>0.000622</td>\n",
       "      <td>5.71895</td>\n",
       "      <td>0.0612169</td>\n",
       "      <td>False</td>\n",
       "      <td>{'C': 5.718949547438774, 'gamma': 0.06121687533120761, 'shrinking': False}</td>\n",
       "      <td>0.761165</td>\n",
       "      <td>0.788350</td>\n",
       "      <td>0.757812</td>\n",
       "      <td>0.769131</td>\n",
       "      <td>0.013678</td>\n",
       "      <td>12</td>\n",
       "      <td>0.986368</td>\n",
       "      <td>0.983447</td>\n",
       "      <td>0.984466</td>\n",
       "      <td>0.984760</td>\n",
       "      <td>0.001211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.207086</td>\n",
       "      <td>0.003069</td>\n",
       "      <td>0.041254</td>\n",
       "      <td>0.001025</td>\n",
       "      <td>23.246</td>\n",
       "      <td>0.150888</td>\n",
       "      <td>True</td>\n",
       "      <td>{'C': 23.246016166357183, 'gamma': 0.1508877672108333, 'shrinking': True}</td>\n",
       "      <td>0.735922</td>\n",
       "      <td>0.739806</td>\n",
       "      <td>0.730469</td>\n",
       "      <td>0.735409</td>\n",
       "      <td>0.003827</td>\n",
       "      <td>115</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998053</td>\n",
       "      <td>0.998058</td>\n",
       "      <td>0.998704</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.185955</td>\n",
       "      <td>0.001338</td>\n",
       "      <td>0.042420</td>\n",
       "      <td>0.002939</td>\n",
       "      <td>4.70657</td>\n",
       "      <td>0.141802</td>\n",
       "      <td>False</td>\n",
       "      <td>{'C': 4.706565558660487, 'gamma': 0.1418023843759134, 'shrinking': False}</td>\n",
       "      <td>0.747573</td>\n",
       "      <td>0.749515</td>\n",
       "      <td>0.734375</td>\n",
       "      <td>0.743839</td>\n",
       "      <td>0.006720</td>\n",
       "      <td>93</td>\n",
       "      <td>0.999026</td>\n",
       "      <td>0.995131</td>\n",
       "      <td>0.997087</td>\n",
       "      <td>0.997082</td>\n",
       "      <td>0.001590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.220746</td>\n",
       "      <td>0.008939</td>\n",
       "      <td>0.043418</td>\n",
       "      <td>0.001629</td>\n",
       "      <td>13.9493</td>\n",
       "      <td>0.149698</td>\n",
       "      <td>True</td>\n",
       "      <td>{'C': 13.949279743787342, 'gamma': 0.14969826235510802, 'shrinking': True}</td>\n",
       "      <td>0.735922</td>\n",
       "      <td>0.739806</td>\n",
       "      <td>0.734375</td>\n",
       "      <td>0.736706</td>\n",
       "      <td>0.002284</td>\n",
       "      <td>114</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998053</td>\n",
       "      <td>0.998058</td>\n",
       "      <td>0.998704</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.223323</td>\n",
       "      <td>0.025490</td>\n",
       "      <td>0.042586</td>\n",
       "      <td>0.002388</td>\n",
       "      <td>36.4469</td>\n",
       "      <td>0.131632</td>\n",
       "      <td>True</td>\n",
       "      <td>{'C': 36.44694655309395, 'gamma': 0.1316317559099311, 'shrinking': True}</td>\n",
       "      <td>0.739806</td>\n",
       "      <td>0.753398</td>\n",
       "      <td>0.730469</td>\n",
       "      <td>0.741245</td>\n",
       "      <td>0.009412</td>\n",
       "      <td>101</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998053</td>\n",
       "      <td>0.998058</td>\n",
       "      <td>0.998704</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.156543</td>\n",
       "      <td>0.005412</td>\n",
       "      <td>0.030277</td>\n",
       "      <td>0.000625</td>\n",
       "      <td>22.0435</td>\n",
       "      <td>0.0135063</td>\n",
       "      <td>True</td>\n",
       "      <td>{'C': 22.04351796364819, 'gamma': 0.013506312837926415, 'shrinking': True}</td>\n",
       "      <td>0.751456</td>\n",
       "      <td>0.796117</td>\n",
       "      <td>0.755859</td>\n",
       "      <td>0.767834</td>\n",
       "      <td>0.020108</td>\n",
       "      <td>15</td>\n",
       "      <td>0.940604</td>\n",
       "      <td>0.941577</td>\n",
       "      <td>0.935922</td>\n",
       "      <td>0.939368</td>\n",
       "      <td>0.002469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.178670</td>\n",
       "      <td>0.007634</td>\n",
       "      <td>0.033935</td>\n",
       "      <td>0.001078</td>\n",
       "      <td>44.0809</td>\n",
       "      <td>0.0447516</td>\n",
       "      <td>False</td>\n",
       "      <td>{'C': 44.08086062419186, 'gamma': 0.04475158780952486, 'shrinking': False}</td>\n",
       "      <td>0.728155</td>\n",
       "      <td>0.763107</td>\n",
       "      <td>0.763672</td>\n",
       "      <td>0.751621</td>\n",
       "      <td>0.016619</td>\n",
       "      <td>74</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998053</td>\n",
       "      <td>0.997087</td>\n",
       "      <td>0.998380</td>\n",
       "      <td>0.001211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.194895</td>\n",
       "      <td>0.005880</td>\n",
       "      <td>0.036929</td>\n",
       "      <td>0.001411</td>\n",
       "      <td>26.0874</td>\n",
       "      <td>0.0714197</td>\n",
       "      <td>True</td>\n",
       "      <td>{'C': 26.087371214333686, 'gamma': 0.07141969429945556, 'shrinking': True}</td>\n",
       "      <td>0.753398</td>\n",
       "      <td>0.774757</td>\n",
       "      <td>0.767578</td>\n",
       "      <td>0.765240</td>\n",
       "      <td>0.008883</td>\n",
       "      <td>23</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998053</td>\n",
       "      <td>0.997087</td>\n",
       "      <td>0.998380</td>\n",
       "      <td>0.001211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.171769</td>\n",
       "      <td>0.003634</td>\n",
       "      <td>0.036265</td>\n",
       "      <td>0.000942</td>\n",
       "      <td>26.516</td>\n",
       "      <td>0.0663759</td>\n",
       "      <td>False</td>\n",
       "      <td>{'C': 26.516038581198128, 'gamma': 0.06637585067052744, 'shrinking': False}</td>\n",
       "      <td>0.745631</td>\n",
       "      <td>0.768932</td>\n",
       "      <td>0.759766</td>\n",
       "      <td>0.758106</td>\n",
       "      <td>0.009593</td>\n",
       "      <td>43</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998053</td>\n",
       "      <td>0.997087</td>\n",
       "      <td>0.998380</td>\n",
       "      <td>0.001211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.183762</td>\n",
       "      <td>0.009723</td>\n",
       "      <td>0.035267</td>\n",
       "      <td>0.001026</td>\n",
       "      <td>41.0635</td>\n",
       "      <td>0.0588615</td>\n",
       "      <td>False</td>\n",
       "      <td>{'C': 41.06346429028248, 'gamma': 0.0588615041686432, 'shrinking': False}</td>\n",
       "      <td>0.741748</td>\n",
       "      <td>0.766990</td>\n",
       "      <td>0.757812</td>\n",
       "      <td>0.755512</td>\n",
       "      <td>0.010442</td>\n",
       "      <td>56</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998053</td>\n",
       "      <td>0.997087</td>\n",
       "      <td>0.998380</td>\n",
       "      <td>0.001211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.207411</td>\n",
       "      <td>0.005563</td>\n",
       "      <td>0.040756</td>\n",
       "      <td>0.000469</td>\n",
       "      <td>49.6956</td>\n",
       "      <td>0.1156</td>\n",
       "      <td>True</td>\n",
       "      <td>{'C': 49.69559341829586, 'gamma': 0.1156000638287321, 'shrinking': True}</td>\n",
       "      <td>0.737864</td>\n",
       "      <td>0.765049</td>\n",
       "      <td>0.736328</td>\n",
       "      <td>0.746433</td>\n",
       "      <td>0.013197</td>\n",
       "      <td>87</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998053</td>\n",
       "      <td>0.998058</td>\n",
       "      <td>0.998704</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.208639</td>\n",
       "      <td>0.002428</td>\n",
       "      <td>0.041256</td>\n",
       "      <td>0.000942</td>\n",
       "      <td>29.2826</td>\n",
       "      <td>0.124966</td>\n",
       "      <td>True</td>\n",
       "      <td>{'C': 29.28259509022864, 'gamma': 0.12496642435768227, 'shrinking': True}</td>\n",
       "      <td>0.743689</td>\n",
       "      <td>0.759223</td>\n",
       "      <td>0.736328</td>\n",
       "      <td>0.746433</td>\n",
       "      <td>0.009542</td>\n",
       "      <td>87</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998053</td>\n",
       "      <td>0.998058</td>\n",
       "      <td>0.998704</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.215307</td>\n",
       "      <td>0.005936</td>\n",
       "      <td>0.042418</td>\n",
       "      <td>0.000706</td>\n",
       "      <td>35.7264</td>\n",
       "      <td>0.151859</td>\n",
       "      <td>True</td>\n",
       "      <td>{'C': 35.72643754456957, 'gamma': 0.15185936640565448, 'shrinking': True}</td>\n",
       "      <td>0.737864</td>\n",
       "      <td>0.739806</td>\n",
       "      <td>0.728516</td>\n",
       "      <td>0.735409</td>\n",
       "      <td>0.004924</td>\n",
       "      <td>115</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998053</td>\n",
       "      <td>0.998058</td>\n",
       "      <td>0.998704</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.211800</td>\n",
       "      <td>0.009270</td>\n",
       "      <td>0.038093</td>\n",
       "      <td>0.001177</td>\n",
       "      <td>45.7526</td>\n",
       "      <td>0.0703254</td>\n",
       "      <td>True</td>\n",
       "      <td>{'C': 45.75255074920018, 'gamma': 0.07032539780855748, 'shrinking': True}</td>\n",
       "      <td>0.749515</td>\n",
       "      <td>0.766990</td>\n",
       "      <td>0.767578</td>\n",
       "      <td>0.761349</td>\n",
       "      <td>0.008384</td>\n",
       "      <td>33</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998053</td>\n",
       "      <td>0.998058</td>\n",
       "      <td>0.998704</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.186735</td>\n",
       "      <td>0.007208</td>\n",
       "      <td>0.034103</td>\n",
       "      <td>0.002092</td>\n",
       "      <td>28.5796</td>\n",
       "      <td>0.0367689</td>\n",
       "      <td>False</td>\n",
       "      <td>{'C': 28.579562262951438, 'gamma': 0.03676891744397382, 'shrinking': False}</td>\n",
       "      <td>0.735922</td>\n",
       "      <td>0.770874</td>\n",
       "      <td>0.759766</td>\n",
       "      <td>0.755512</td>\n",
       "      <td>0.014594</td>\n",
       "      <td>56</td>\n",
       "      <td>0.995131</td>\n",
       "      <td>0.993184</td>\n",
       "      <td>0.997087</td>\n",
       "      <td>0.995134</td>\n",
       "      <td>0.001594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.192980</td>\n",
       "      <td>0.004523</td>\n",
       "      <td>0.042087</td>\n",
       "      <td>0.000623</td>\n",
       "      <td>6.84393</td>\n",
       "      <td>0.154818</td>\n",
       "      <td>False</td>\n",
       "      <td>{'C': 6.843930035455221, 'gamma': 0.15481759740884374, 'shrinking': False}</td>\n",
       "      <td>0.739806</td>\n",
       "      <td>0.737864</td>\n",
       "      <td>0.728516</td>\n",
       "      <td>0.735409</td>\n",
       "      <td>0.004924</td>\n",
       "      <td>115</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997079</td>\n",
       "      <td>0.997087</td>\n",
       "      <td>0.998055</td>\n",
       "      <td>0.001375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.216089</td>\n",
       "      <td>0.007612</td>\n",
       "      <td>0.043418</td>\n",
       "      <td>0.001080</td>\n",
       "      <td>2.88838</td>\n",
       "      <td>0.144508</td>\n",
       "      <td>True</td>\n",
       "      <td>{'C': 2.8883767649183, 'gamma': 0.14450848965789428, 'shrinking': True}</td>\n",
       "      <td>0.747573</td>\n",
       "      <td>0.741748</td>\n",
       "      <td>0.738281</td>\n",
       "      <td>0.742542</td>\n",
       "      <td>0.003833</td>\n",
       "      <td>97</td>\n",
       "      <td>0.992210</td>\n",
       "      <td>0.990263</td>\n",
       "      <td>0.992233</td>\n",
       "      <td>0.991569</td>\n",
       "      <td>0.000923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.210598</td>\n",
       "      <td>0.004538</td>\n",
       "      <td>0.041256</td>\n",
       "      <td>0.001925</td>\n",
       "      <td>21.4081</td>\n",
       "      <td>0.112174</td>\n",
       "      <td>True</td>\n",
       "      <td>{'C': 21.408117152083804, 'gamma': 0.11217423158705941, 'shrinking': True}</td>\n",
       "      <td>0.741748</td>\n",
       "      <td>0.774757</td>\n",
       "      <td>0.740234</td>\n",
       "      <td>0.752270</td>\n",
       "      <td>0.015936</td>\n",
       "      <td>71</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998053</td>\n",
       "      <td>0.998058</td>\n",
       "      <td>0.998704</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.191635</td>\n",
       "      <td>0.013133</td>\n",
       "      <td>0.033770</td>\n",
       "      <td>0.000942</td>\n",
       "      <td>13.1958</td>\n",
       "      <td>0.0307837</td>\n",
       "      <td>False</td>\n",
       "      <td>{'C': 13.195783384827736, 'gamma': 0.0307836874927562, 'shrinking': False}</td>\n",
       "      <td>0.732039</td>\n",
       "      <td>0.796117</td>\n",
       "      <td>0.755859</td>\n",
       "      <td>0.761349</td>\n",
       "      <td>0.026470</td>\n",
       "      <td>33</td>\n",
       "      <td>0.977605</td>\n",
       "      <td>0.976631</td>\n",
       "      <td>0.981553</td>\n",
       "      <td>0.978596</td>\n",
       "      <td>0.002128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.143061</td>\n",
       "      <td>0.003787</td>\n",
       "      <td>0.030109</td>\n",
       "      <td>0.000623</td>\n",
       "      <td>11.8918</td>\n",
       "      <td>0.0062387</td>\n",
       "      <td>False</td>\n",
       "      <td>{'C': 11.891843364951756, 'gamma': 0.0062386991018075775, 'shrinking': False}</td>\n",
       "      <td>0.737864</td>\n",
       "      <td>0.782524</td>\n",
       "      <td>0.759766</td>\n",
       "      <td>0.760052</td>\n",
       "      <td>0.018251</td>\n",
       "      <td>40</td>\n",
       "      <td>0.836417</td>\n",
       "      <td>0.819864</td>\n",
       "      <td>0.838835</td>\n",
       "      <td>0.831705</td>\n",
       "      <td>0.008431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.197174</td>\n",
       "      <td>0.011922</td>\n",
       "      <td>0.043583</td>\n",
       "      <td>0.003466</td>\n",
       "      <td>14.2976</td>\n",
       "      <td>0.135576</td>\n",
       "      <td>False</td>\n",
       "      <td>{'C': 14.297562057769115, 'gamma': 0.13557619604552612, 'shrinking': False}</td>\n",
       "      <td>0.741748</td>\n",
       "      <td>0.747573</td>\n",
       "      <td>0.730469</td>\n",
       "      <td>0.739948</td>\n",
       "      <td>0.007095</td>\n",
       "      <td>102</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998053</td>\n",
       "      <td>0.998058</td>\n",
       "      <td>0.998704</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.210433</td>\n",
       "      <td>0.003786</td>\n",
       "      <td>0.040090</td>\n",
       "      <td>0.000941</td>\n",
       "      <td>28.6766</td>\n",
       "      <td>0.123702</td>\n",
       "      <td>True</td>\n",
       "      <td>{'C': 28.676582465030595, 'gamma': 0.12370223809640493, 'shrinking': True}</td>\n",
       "      <td>0.743689</td>\n",
       "      <td>0.759223</td>\n",
       "      <td>0.738281</td>\n",
       "      <td>0.747082</td>\n",
       "      <td>0.008877</td>\n",
       "      <td>82</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998053</td>\n",
       "      <td>0.998058</td>\n",
       "      <td>0.998704</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.207273</td>\n",
       "      <td>0.003268</td>\n",
       "      <td>0.042086</td>\n",
       "      <td>0.001245</td>\n",
       "      <td>3.99341</td>\n",
       "      <td>0.143185</td>\n",
       "      <td>True</td>\n",
       "      <td>{'C': 3.9934092111493023, 'gamma': 0.14318546606181284, 'shrinking': True}</td>\n",
       "      <td>0.747573</td>\n",
       "      <td>0.745631</td>\n",
       "      <td>0.734375</td>\n",
       "      <td>0.742542</td>\n",
       "      <td>0.005813</td>\n",
       "      <td>97</td>\n",
       "      <td>0.997079</td>\n",
       "      <td>0.994158</td>\n",
       "      <td>0.996117</td>\n",
       "      <td>0.995784</td>\n",
       "      <td>0.001215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.197624</td>\n",
       "      <td>0.009956</td>\n",
       "      <td>0.042085</td>\n",
       "      <td>0.000849</td>\n",
       "      <td>46.4634</td>\n",
       "      <td>0.146413</td>\n",
       "      <td>False</td>\n",
       "      <td>{'C': 46.46335146383572, 'gamma': 0.146412643475434, 'shrinking': False}</td>\n",
       "      <td>0.739806</td>\n",
       "      <td>0.741748</td>\n",
       "      <td>0.734375</td>\n",
       "      <td>0.738651</td>\n",
       "      <td>0.003118</td>\n",
       "      <td>106</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998053</td>\n",
       "      <td>0.998058</td>\n",
       "      <td>0.998704</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>0.188686</td>\n",
       "      <td>0.004030</td>\n",
       "      <td>0.041255</td>\n",
       "      <td>0.000234</td>\n",
       "      <td>41.091</td>\n",
       "      <td>0.119224</td>\n",
       "      <td>False</td>\n",
       "      <td>{'C': 41.090988184083685, 'gamma': 0.11922420615696916, 'shrinking': False}</td>\n",
       "      <td>0.743689</td>\n",
       "      <td>0.761165</td>\n",
       "      <td>0.736328</td>\n",
       "      <td>0.747082</td>\n",
       "      <td>0.010415</td>\n",
       "      <td>82</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998053</td>\n",
       "      <td>0.998058</td>\n",
       "      <td>0.998704</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0.207445</td>\n",
       "      <td>0.006235</td>\n",
       "      <td>0.042919</td>\n",
       "      <td>0.001468</td>\n",
       "      <td>44.8519</td>\n",
       "      <td>0.140398</td>\n",
       "      <td>False</td>\n",
       "      <td>{'C': 44.851891268051766, 'gamma': 0.14039831918009843, 'shrinking': False}</td>\n",
       "      <td>0.739806</td>\n",
       "      <td>0.743689</td>\n",
       "      <td>0.732422</td>\n",
       "      <td>0.738651</td>\n",
       "      <td>0.004670</td>\n",
       "      <td>106</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998053</td>\n",
       "      <td>0.998058</td>\n",
       "      <td>0.998704</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>0.193302</td>\n",
       "      <td>0.004925</td>\n",
       "      <td>0.043085</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>23.7523</td>\n",
       "      <td>0.129554</td>\n",
       "      <td>False</td>\n",
       "      <td>{'C': 23.752331981008652, 'gamma': 0.1295537331541677, 'shrinking': False}</td>\n",
       "      <td>0.741748</td>\n",
       "      <td>0.757282</td>\n",
       "      <td>0.734375</td>\n",
       "      <td>0.744488</td>\n",
       "      <td>0.009546</td>\n",
       "      <td>91</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998053</td>\n",
       "      <td>0.998058</td>\n",
       "      <td>0.998704</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>0.164852</td>\n",
       "      <td>0.003999</td>\n",
       "      <td>0.037098</td>\n",
       "      <td>0.001176</td>\n",
       "      <td>4.53359</td>\n",
       "      <td>0.0663518</td>\n",
       "      <td>False</td>\n",
       "      <td>{'C': 4.533585548900621, 'gamma': 0.06635178961516651, 'shrinking': False}</td>\n",
       "      <td>0.765049</td>\n",
       "      <td>0.792233</td>\n",
       "      <td>0.761719</td>\n",
       "      <td>0.773022</td>\n",
       "      <td>0.013672</td>\n",
       "      <td>7</td>\n",
       "      <td>0.984421</td>\n",
       "      <td>0.981500</td>\n",
       "      <td>0.983495</td>\n",
       "      <td>0.983138</td>\n",
       "      <td>0.001219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>0.178469</td>\n",
       "      <td>0.000268</td>\n",
       "      <td>0.038594</td>\n",
       "      <td>0.000848</td>\n",
       "      <td>37.4659</td>\n",
       "      <td>0.0883755</td>\n",
       "      <td>False</td>\n",
       "      <td>{'C': 37.46585572822718, 'gamma': 0.08837549799243051, 'shrinking': False}</td>\n",
       "      <td>0.759223</td>\n",
       "      <td>0.770874</td>\n",
       "      <td>0.757812</td>\n",
       "      <td>0.762646</td>\n",
       "      <td>0.005855</td>\n",
       "      <td>29</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998053</td>\n",
       "      <td>0.998058</td>\n",
       "      <td>0.998704</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>0.184108</td>\n",
       "      <td>0.000460</td>\n",
       "      <td>0.035266</td>\n",
       "      <td>0.001647</td>\n",
       "      <td>44.2754</td>\n",
       "      <td>0.0599923</td>\n",
       "      <td>False</td>\n",
       "      <td>{'C': 44.275367464606425, 'gamma': 0.05999230964045979, 'shrinking': False}</td>\n",
       "      <td>0.739806</td>\n",
       "      <td>0.766990</td>\n",
       "      <td>0.757812</td>\n",
       "      <td>0.754864</td>\n",
       "      <td>0.011302</td>\n",
       "      <td>58</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998053</td>\n",
       "      <td>0.998058</td>\n",
       "      <td>0.998704</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>0.203299</td>\n",
       "      <td>0.005030</td>\n",
       "      <td>0.040921</td>\n",
       "      <td>0.001223</td>\n",
       "      <td>46.5196</td>\n",
       "      <td>0.10946</td>\n",
       "      <td>True</td>\n",
       "      <td>{'C': 46.519589506367396, 'gamma': 0.10945987847667181, 'shrinking': True}</td>\n",
       "      <td>0.745631</td>\n",
       "      <td>0.768932</td>\n",
       "      <td>0.742188</td>\n",
       "      <td>0.752270</td>\n",
       "      <td>0.011883</td>\n",
       "      <td>71</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998053</td>\n",
       "      <td>0.998058</td>\n",
       "      <td>0.998704</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>0.191529</td>\n",
       "      <td>0.003750</td>\n",
       "      <td>0.041422</td>\n",
       "      <td>0.001079</td>\n",
       "      <td>15.7728</td>\n",
       "      <td>0.148749</td>\n",
       "      <td>False</td>\n",
       "      <td>{'C': 15.772814962612271, 'gamma': 0.14874943109975358, 'shrinking': False}</td>\n",
       "      <td>0.737864</td>\n",
       "      <td>0.739806</td>\n",
       "      <td>0.736328</td>\n",
       "      <td>0.738003</td>\n",
       "      <td>0.001422</td>\n",
       "      <td>110</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998053</td>\n",
       "      <td>0.998058</td>\n",
       "      <td>0.998704</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>0.199868</td>\n",
       "      <td>0.002753</td>\n",
       "      <td>0.038759</td>\n",
       "      <td>0.001647</td>\n",
       "      <td>8.22392</td>\n",
       "      <td>0.0802927</td>\n",
       "      <td>True</td>\n",
       "      <td>{'C': 8.223915859896598, 'gamma': 0.08029270418563039, 'shrinking': True}</td>\n",
       "      <td>0.763107</td>\n",
       "      <td>0.784466</td>\n",
       "      <td>0.748047</td>\n",
       "      <td>0.765240</td>\n",
       "      <td>0.014937</td>\n",
       "      <td>23</td>\n",
       "      <td>0.997079</td>\n",
       "      <td>0.992210</td>\n",
       "      <td>0.997087</td>\n",
       "      <td>0.995459</td>\n",
       "      <td>0.002297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>0.214259</td>\n",
       "      <td>0.004506</td>\n",
       "      <td>0.042086</td>\n",
       "      <td>0.000848</td>\n",
       "      <td>5.13136</td>\n",
       "      <td>0.143763</td>\n",
       "      <td>True</td>\n",
       "      <td>{'C': 5.131364483823471, 'gamma': 0.14376348421055457, 'shrinking': True}</td>\n",
       "      <td>0.747573</td>\n",
       "      <td>0.745631</td>\n",
       "      <td>0.732422</td>\n",
       "      <td>0.741894</td>\n",
       "      <td>0.006725</td>\n",
       "      <td>100</td>\n",
       "      <td>0.999026</td>\n",
       "      <td>0.995131</td>\n",
       "      <td>0.997087</td>\n",
       "      <td>0.997082</td>\n",
       "      <td>0.001590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>0.199954</td>\n",
       "      <td>0.002652</td>\n",
       "      <td>0.036430</td>\n",
       "      <td>0.003886</td>\n",
       "      <td>34.2231</td>\n",
       "      <td>0.040875</td>\n",
       "      <td>False</td>\n",
       "      <td>{'C': 34.22311871704853, 'gamma': 0.04087496802561965, 'shrinking': False}</td>\n",
       "      <td>0.730097</td>\n",
       "      <td>0.770874</td>\n",
       "      <td>0.769531</td>\n",
       "      <td>0.756809</td>\n",
       "      <td>0.018924</td>\n",
       "      <td>51</td>\n",
       "      <td>0.998053</td>\n",
       "      <td>0.994158</td>\n",
       "      <td>0.997087</td>\n",
       "      <td>0.996433</td>\n",
       "      <td>0.001656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>0.182486</td>\n",
       "      <td>0.003651</td>\n",
       "      <td>0.034102</td>\n",
       "      <td>0.001025</td>\n",
       "      <td>19.2118</td>\n",
       "      <td>0.0433857</td>\n",
       "      <td>True</td>\n",
       "      <td>{'C': 19.211780864993408, 'gamma': 0.04338565065299849, 'shrinking': True}</td>\n",
       "      <td>0.737864</td>\n",
       "      <td>0.780583</td>\n",
       "      <td>0.761719</td>\n",
       "      <td>0.760052</td>\n",
       "      <td>0.017496</td>\n",
       "      <td>40</td>\n",
       "      <td>0.994158</td>\n",
       "      <td>0.992210</td>\n",
       "      <td>0.994175</td>\n",
       "      <td>0.993514</td>\n",
       "      <td>0.000922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>0.193799</td>\n",
       "      <td>0.001542</td>\n",
       "      <td>0.041753</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>11.1252</td>\n",
       "      <td>0.143251</td>\n",
       "      <td>False</td>\n",
       "      <td>{'C': 11.125238170708874, 'gamma': 0.14325089627590562, 'shrinking': False}</td>\n",
       "      <td>0.739806</td>\n",
       "      <td>0.741748</td>\n",
       "      <td>0.736328</td>\n",
       "      <td>0.739300</td>\n",
       "      <td>0.002240</td>\n",
       "      <td>105</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998053</td>\n",
       "      <td>0.998058</td>\n",
       "      <td>0.998704</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>0.145390</td>\n",
       "      <td>0.002713</td>\n",
       "      <td>0.034434</td>\n",
       "      <td>0.000706</td>\n",
       "      <td>4.96407</td>\n",
       "      <td>0.0410863</td>\n",
       "      <td>True</td>\n",
       "      <td>{'C': 4.9640684918865645, 'gamma': 0.041086294752994704, 'shrinking': True}</td>\n",
       "      <td>0.763107</td>\n",
       "      <td>0.801942</td>\n",
       "      <td>0.765625</td>\n",
       "      <td>0.776913</td>\n",
       "      <td>0.017754</td>\n",
       "      <td>4</td>\n",
       "      <td>0.962999</td>\n",
       "      <td>0.962025</td>\n",
       "      <td>0.968932</td>\n",
       "      <td>0.964652</td>\n",
       "      <td>0.003052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>0.193912</td>\n",
       "      <td>0.018060</td>\n",
       "      <td>0.031939</td>\n",
       "      <td>0.001078</td>\n",
       "      <td>21.9416</td>\n",
       "      <td>0.0282627</td>\n",
       "      <td>False</td>\n",
       "      <td>{'C': 21.94157269756067, 'gamma': 0.028262696582931703, 'shrinking': False}</td>\n",
       "      <td>0.733981</td>\n",
       "      <td>0.784466</td>\n",
       "      <td>0.761719</td>\n",
       "      <td>0.760052</td>\n",
       "      <td>0.020664</td>\n",
       "      <td>40</td>\n",
       "      <td>0.983447</td>\n",
       "      <td>0.981500</td>\n",
       "      <td>0.986408</td>\n",
       "      <td>0.983785</td>\n",
       "      <td>0.002018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>0.211099</td>\n",
       "      <td>0.002270</td>\n",
       "      <td>0.040755</td>\n",
       "      <td>0.000849</td>\n",
       "      <td>38.3624</td>\n",
       "      <td>0.104186</td>\n",
       "      <td>True</td>\n",
       "      <td>{'C': 38.362438435257545, 'gamma': 0.10418640638704982, 'shrinking': True}</td>\n",
       "      <td>0.749515</td>\n",
       "      <td>0.763107</td>\n",
       "      <td>0.746094</td>\n",
       "      <td>0.752918</td>\n",
       "      <td>0.007349</td>\n",
       "      <td>67</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998053</td>\n",
       "      <td>0.998058</td>\n",
       "      <td>0.998704</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>0.201116</td>\n",
       "      <td>0.004804</td>\n",
       "      <td>0.041256</td>\n",
       "      <td>0.000236</td>\n",
       "      <td>36.8215</td>\n",
       "      <td>0.101538</td>\n",
       "      <td>False</td>\n",
       "      <td>{'C': 36.82149782715173, 'gamma': 0.10153758918896479, 'shrinking': False}</td>\n",
       "      <td>0.747573</td>\n",
       "      <td>0.766990</td>\n",
       "      <td>0.746094</td>\n",
       "      <td>0.753567</td>\n",
       "      <td>0.009525</td>\n",
       "      <td>62</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998053</td>\n",
       "      <td>0.998058</td>\n",
       "      <td>0.998704</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>0.212219</td>\n",
       "      <td>0.005648</td>\n",
       "      <td>0.042909</td>\n",
       "      <td>0.001087</td>\n",
       "      <td>21.0114</td>\n",
       "      <td>0.146864</td>\n",
       "      <td>True</td>\n",
       "      <td>{'C': 21.011417182976075, 'gamma': 0.1468642041823018, 'shrinking': True}</td>\n",
       "      <td>0.739806</td>\n",
       "      <td>0.739806</td>\n",
       "      <td>0.734375</td>\n",
       "      <td>0.738003</td>\n",
       "      <td>0.002558</td>\n",
       "      <td>110</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998053</td>\n",
       "      <td>0.998058</td>\n",
       "      <td>0.998704</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>0.217714</td>\n",
       "      <td>0.016254</td>\n",
       "      <td>0.028779</td>\n",
       "      <td>0.001697</td>\n",
       "      <td>44.2148</td>\n",
       "      <td>0.00584601</td>\n",
       "      <td>False</td>\n",
       "      <td>{'C': 44.2147673631182, 'gamma': 0.005846013087073871, 'shrinking': False}</td>\n",
       "      <td>0.755340</td>\n",
       "      <td>0.786408</td>\n",
       "      <td>0.757812</td>\n",
       "      <td>0.766537</td>\n",
       "      <td>0.014107</td>\n",
       "      <td>20</td>\n",
       "      <td>0.891918</td>\n",
       "      <td>0.894839</td>\n",
       "      <td>0.898058</td>\n",
       "      <td>0.894939</td>\n",
       "      <td>0.002508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  param_C  \\\n",
       "0         0.206772      0.016503         0.037929        0.001078  26.8431   \n",
       "1         0.195129      0.004592         0.035267        0.002009  22.4475   \n",
       "2         0.205608      0.008843         0.038427        0.000816  38.0444   \n",
       "3         0.197146      0.005944         0.031607        0.000848  32.0874   \n",
       "4         0.186367      0.003871         0.041255        0.001026  37.8021   \n",
       "5         0.201326      0.004043         0.040091        0.000624  32.3605   \n",
       "6         0.199745      0.003705         0.038593        0.001025   25.605   \n",
       "7         0.173878      0.015276         0.032272        0.000623  28.4612   \n",
       "8         0.205110      0.003259         0.039923        0.000406  27.4488   \n",
       "9         0.164664      0.004749         0.032106        0.000622  9.66537   \n",
       "10        0.183855      0.008818         0.036430        0.001079  31.7197   \n",
       "11        0.190637      0.002544         0.036763        0.001026  45.7413   \n",
       "12        0.193311      0.007162         0.036599        0.000846  39.8217   \n",
       "13        0.186067      0.001823         0.042087        0.000849  44.7181   \n",
       "14        0.185299      0.005202         0.041255        0.001245  37.3369   \n",
       "15        0.183953      0.001065         0.040424        0.000407  18.2976   \n",
       "16        0.167557      0.013850         0.031939        0.000705  31.9354   \n",
       "17        0.165020      0.005194         0.036265        0.000622  5.71895   \n",
       "18        0.207086      0.003069         0.041254        0.001025   23.246   \n",
       "19        0.185955      0.001338         0.042420        0.002939  4.70657   \n",
       "20        0.220746      0.008939         0.043418        0.001629  13.9493   \n",
       "21        0.223323      0.025490         0.042586        0.002388  36.4469   \n",
       "22        0.156543      0.005412         0.030277        0.000625  22.0435   \n",
       "23        0.178670      0.007634         0.033935        0.001078  44.0809   \n",
       "24        0.194895      0.005880         0.036929        0.001411  26.0874   \n",
       "25        0.171769      0.003634         0.036265        0.000942   26.516   \n",
       "26        0.183762      0.009723         0.035267        0.001026  41.0635   \n",
       "27        0.207411      0.005563         0.040756        0.000469  49.6956   \n",
       "28        0.208639      0.002428         0.041256        0.000942  29.2826   \n",
       "29        0.215307      0.005936         0.042418        0.000706  35.7264   \n",
       "..             ...           ...              ...             ...      ...   \n",
       "90        0.211800      0.009270         0.038093        0.001177  45.7526   \n",
       "91        0.186735      0.007208         0.034103        0.002092  28.5796   \n",
       "92        0.192980      0.004523         0.042087        0.000623  6.84393   \n",
       "93        0.216089      0.007612         0.043418        0.001080  2.88838   \n",
       "94        0.210598      0.004538         0.041256        0.001925  21.4081   \n",
       "95        0.191635      0.013133         0.033770        0.000942  13.1958   \n",
       "96        0.143061      0.003787         0.030109        0.000623  11.8918   \n",
       "97        0.197174      0.011922         0.043583        0.003466  14.2976   \n",
       "98        0.210433      0.003786         0.040090        0.000941  28.6766   \n",
       "99        0.207273      0.003268         0.042086        0.001245  3.99341   \n",
       "100       0.197624      0.009956         0.042085        0.000849  46.4634   \n",
       "101       0.188686      0.004030         0.041255        0.000234   41.091   \n",
       "102       0.207445      0.006235         0.042919        0.001468  44.8519   \n",
       "103       0.193302      0.004925         0.043085        0.001429  23.7523   \n",
       "104       0.164852      0.003999         0.037098        0.001176  4.53359   \n",
       "105       0.178469      0.000268         0.038594        0.000848  37.4659   \n",
       "106       0.184108      0.000460         0.035266        0.001647  44.2754   \n",
       "107       0.203299      0.005030         0.040921        0.001223  46.5196   \n",
       "108       0.191529      0.003750         0.041422        0.001079  15.7728   \n",
       "109       0.199868      0.002753         0.038759        0.001647  8.22392   \n",
       "110       0.214259      0.004506         0.042086        0.000848  5.13136   \n",
       "111       0.199954      0.002652         0.036430        0.003886  34.2231   \n",
       "112       0.182486      0.003651         0.034102        0.001025  19.2118   \n",
       "113       0.193799      0.001542         0.041753        0.000235  11.1252   \n",
       "114       0.145390      0.002713         0.034434        0.000706  4.96407   \n",
       "115       0.193912      0.018060         0.031939        0.001078  21.9416   \n",
       "116       0.211099      0.002270         0.040755        0.000849  38.3624   \n",
       "117       0.201116      0.004804         0.041256        0.000236  36.8215   \n",
       "118       0.212219      0.005648         0.042909        0.001087  21.0114   \n",
       "119       0.217714      0.016254         0.028779        0.001697  44.2148   \n",
       "\n",
       "    param_gamma param_shrinking  \\\n",
       "0     0.0625746            True   \n",
       "1     0.0363221           False   \n",
       "2     0.0670948            True   \n",
       "3     0.0249578           False   \n",
       "4      0.153958           False   \n",
       "5       0.11183            True   \n",
       "6     0.0993973            True   \n",
       "7     0.0323739            True   \n",
       "8       0.11082            True   \n",
       "9     0.0290361           False   \n",
       "10    0.0638521            True   \n",
       "11    0.0699777            True   \n",
       "12    0.0676294            True   \n",
       "13     0.142868           False   \n",
       "14     0.126325           False   \n",
       "15     0.120514           False   \n",
       "16    0.0270223            True   \n",
       "17    0.0612169           False   \n",
       "18     0.150888            True   \n",
       "19     0.141802           False   \n",
       "20     0.149698            True   \n",
       "21     0.131632            True   \n",
       "22    0.0135063            True   \n",
       "23    0.0447516           False   \n",
       "24    0.0714197            True   \n",
       "25    0.0663759           False   \n",
       "26    0.0588615           False   \n",
       "27       0.1156            True   \n",
       "28     0.124966            True   \n",
       "29     0.151859            True   \n",
       "..          ...             ...   \n",
       "90    0.0703254            True   \n",
       "91    0.0367689           False   \n",
       "92     0.154818           False   \n",
       "93     0.144508            True   \n",
       "94     0.112174            True   \n",
       "95    0.0307837           False   \n",
       "96    0.0062387           False   \n",
       "97     0.135576           False   \n",
       "98     0.123702            True   \n",
       "99     0.143185            True   \n",
       "100    0.146413           False   \n",
       "101    0.119224           False   \n",
       "102    0.140398           False   \n",
       "103    0.129554           False   \n",
       "104   0.0663518           False   \n",
       "105   0.0883755           False   \n",
       "106   0.0599923           False   \n",
       "107     0.10946            True   \n",
       "108    0.148749           False   \n",
       "109   0.0802927            True   \n",
       "110    0.143763            True   \n",
       "111    0.040875           False   \n",
       "112   0.0433857            True   \n",
       "113    0.143251           False   \n",
       "114   0.0410863            True   \n",
       "115   0.0282627           False   \n",
       "116    0.104186            True   \n",
       "117    0.101538           False   \n",
       "118    0.146864            True   \n",
       "119  0.00584601           False   \n",
       "\n",
       "                                                                            params  \\\n",
       "0       {'C': 26.843146649758435, 'gamma': 0.06257463787001483, 'shrinking': True}   \n",
       "1      {'C': 22.44749386324993, 'gamma': 0.036322051852327356, 'shrinking': False}   \n",
       "2        {'C': 38.04436336060919, 'gamma': 0.06709482544061485, 'shrinking': True}   \n",
       "3      {'C': 32.08740962348253, 'gamma': 0.024957754470274603, 'shrinking': False}   \n",
       "4       {'C': 37.80214090102072, 'gamma': 0.15395843390724673, 'shrinking': False}   \n",
       "5        {'C': 32.36054590904825, 'gamma': 0.11183037825704656, 'shrinking': True}   \n",
       "6       {'C': 25.605038158792023, 'gamma': 0.09939727196250232, 'shrinking': True}   \n",
       "7       {'C': 28.46116634918059, 'gamma': 0.032373927693916706, 'shrinking': True}   \n",
       "8        {'C': 27.44884857837742, 'gamma': 0.11081997427336616, 'shrinking': True}   \n",
       "9      {'C': 9.665370580210976, 'gamma': 0.029036064169539157, 'shrinking': False}   \n",
       "10      {'C': 31.719696972737808, 'gamma': 0.06385206492431375, 'shrinking': True}   \n",
       "11       {'C': 45.74126636492902, 'gamma': 0.06997766538249371, 'shrinking': True}   \n",
       "12       {'C': 39.82174434562712, 'gamma': 0.06762938214352827, 'shrinking': True}   \n",
       "13       {'C': 44.71806854322029, 'gamma': 0.1428682850658086, 'shrinking': False}   \n",
       "14      {'C': 37.33689716333579, 'gamma': 0.12632526634397404, 'shrinking': False}   \n",
       "15     {'C': 18.297624376911784, 'gamma': 0.12051449434090082, 'shrinking': False}   \n",
       "16      {'C': 31.935409507119754, 'gamma': 0.02702228294374617, 'shrinking': True}   \n",
       "17      {'C': 5.718949547438774, 'gamma': 0.06121687533120761, 'shrinking': False}   \n",
       "18       {'C': 23.246016166357183, 'gamma': 0.1508877672108333, 'shrinking': True}   \n",
       "19       {'C': 4.706565558660487, 'gamma': 0.1418023843759134, 'shrinking': False}   \n",
       "20      {'C': 13.949279743787342, 'gamma': 0.14969826235510802, 'shrinking': True}   \n",
       "21        {'C': 36.44694655309395, 'gamma': 0.1316317559099311, 'shrinking': True}   \n",
       "22      {'C': 22.04351796364819, 'gamma': 0.013506312837926415, 'shrinking': True}   \n",
       "23      {'C': 44.08086062419186, 'gamma': 0.04475158780952486, 'shrinking': False}   \n",
       "24      {'C': 26.087371214333686, 'gamma': 0.07141969429945556, 'shrinking': True}   \n",
       "25     {'C': 26.516038581198128, 'gamma': 0.06637585067052744, 'shrinking': False}   \n",
       "26       {'C': 41.06346429028248, 'gamma': 0.0588615041686432, 'shrinking': False}   \n",
       "27        {'C': 49.69559341829586, 'gamma': 0.1156000638287321, 'shrinking': True}   \n",
       "28       {'C': 29.28259509022864, 'gamma': 0.12496642435768227, 'shrinking': True}   \n",
       "29       {'C': 35.72643754456957, 'gamma': 0.15185936640565448, 'shrinking': True}   \n",
       "..                                                                             ...   \n",
       "90       {'C': 45.75255074920018, 'gamma': 0.07032539780855748, 'shrinking': True}   \n",
       "91     {'C': 28.579562262951438, 'gamma': 0.03676891744397382, 'shrinking': False}   \n",
       "92      {'C': 6.843930035455221, 'gamma': 0.15481759740884374, 'shrinking': False}   \n",
       "93         {'C': 2.8883767649183, 'gamma': 0.14450848965789428, 'shrinking': True}   \n",
       "94      {'C': 21.408117152083804, 'gamma': 0.11217423158705941, 'shrinking': True}   \n",
       "95      {'C': 13.195783384827736, 'gamma': 0.0307836874927562, 'shrinking': False}   \n",
       "96   {'C': 11.891843364951756, 'gamma': 0.0062386991018075775, 'shrinking': False}   \n",
       "97     {'C': 14.297562057769115, 'gamma': 0.13557619604552612, 'shrinking': False}   \n",
       "98      {'C': 28.676582465030595, 'gamma': 0.12370223809640493, 'shrinking': True}   \n",
       "99      {'C': 3.9934092111493023, 'gamma': 0.14318546606181284, 'shrinking': True}   \n",
       "100       {'C': 46.46335146383572, 'gamma': 0.146412643475434, 'shrinking': False}   \n",
       "101    {'C': 41.090988184083685, 'gamma': 0.11922420615696916, 'shrinking': False}   \n",
       "102    {'C': 44.851891268051766, 'gamma': 0.14039831918009843, 'shrinking': False}   \n",
       "103     {'C': 23.752331981008652, 'gamma': 0.1295537331541677, 'shrinking': False}   \n",
       "104     {'C': 4.533585548900621, 'gamma': 0.06635178961516651, 'shrinking': False}   \n",
       "105     {'C': 37.46585572822718, 'gamma': 0.08837549799243051, 'shrinking': False}   \n",
       "106    {'C': 44.275367464606425, 'gamma': 0.05999230964045979, 'shrinking': False}   \n",
       "107     {'C': 46.519589506367396, 'gamma': 0.10945987847667181, 'shrinking': True}   \n",
       "108    {'C': 15.772814962612271, 'gamma': 0.14874943109975358, 'shrinking': False}   \n",
       "109      {'C': 8.223915859896598, 'gamma': 0.08029270418563039, 'shrinking': True}   \n",
       "110      {'C': 5.131364483823471, 'gamma': 0.14376348421055457, 'shrinking': True}   \n",
       "111     {'C': 34.22311871704853, 'gamma': 0.04087496802561965, 'shrinking': False}   \n",
       "112     {'C': 19.211780864993408, 'gamma': 0.04338565065299849, 'shrinking': True}   \n",
       "113    {'C': 11.125238170708874, 'gamma': 0.14325089627590562, 'shrinking': False}   \n",
       "114    {'C': 4.9640684918865645, 'gamma': 0.041086294752994704, 'shrinking': True}   \n",
       "115    {'C': 21.94157269756067, 'gamma': 0.028262696582931703, 'shrinking': False}   \n",
       "116     {'C': 38.362438435257545, 'gamma': 0.10418640638704982, 'shrinking': True}   \n",
       "117     {'C': 36.82149782715173, 'gamma': 0.10153758918896479, 'shrinking': False}   \n",
       "118      {'C': 21.011417182976075, 'gamma': 0.1468642041823018, 'shrinking': True}   \n",
       "119     {'C': 44.2147673631182, 'gamma': 0.005846013087073871, 'shrinking': False}   \n",
       "\n",
       "     split0_test_score  split1_test_score  split2_test_score  mean_test_score  \\\n",
       "0             0.745631           0.768932           0.757812         0.757458   \n",
       "1             0.735922           0.766990           0.759766         0.754215   \n",
       "2             0.745631           0.768932           0.767578         0.760700   \n",
       "3             0.724272           0.774757           0.763672         0.754215   \n",
       "4             0.735922           0.739806           0.724609         0.733463   \n",
       "5             0.741748           0.770874           0.742188         0.751621   \n",
       "6             0.747573           0.765049           0.744141         0.752270   \n",
       "7             0.730097           0.766990           0.757812         0.751621   \n",
       "8             0.741748           0.770874           0.742188         0.751621   \n",
       "9             0.747573           0.798058           0.765625         0.770428   \n",
       "10            0.743689           0.768932           0.759766         0.757458   \n",
       "11            0.749515           0.766990           0.767578         0.761349   \n",
       "12            0.745631           0.768932           0.767578         0.760700   \n",
       "13            0.739806           0.743689           0.732422         0.738651   \n",
       "14            0.743689           0.759223           0.734375         0.745785   \n",
       "15            0.743689           0.761165           0.736328         0.747082   \n",
       "16            0.726214           0.770874           0.761719         0.752918   \n",
       "17            0.761165           0.788350           0.757812         0.769131   \n",
       "18            0.735922           0.739806           0.730469         0.735409   \n",
       "19            0.747573           0.749515           0.734375         0.743839   \n",
       "20            0.735922           0.739806           0.734375         0.736706   \n",
       "21            0.739806           0.753398           0.730469         0.741245   \n",
       "22            0.751456           0.796117           0.755859         0.767834   \n",
       "23            0.728155           0.763107           0.763672         0.751621   \n",
       "24            0.753398           0.774757           0.767578         0.765240   \n",
       "25            0.745631           0.768932           0.759766         0.758106   \n",
       "26            0.741748           0.766990           0.757812         0.755512   \n",
       "27            0.737864           0.765049           0.736328         0.746433   \n",
       "28            0.743689           0.759223           0.736328         0.746433   \n",
       "29            0.737864           0.739806           0.728516         0.735409   \n",
       "..                 ...                ...                ...              ...   \n",
       "90            0.749515           0.766990           0.767578         0.761349   \n",
       "91            0.735922           0.770874           0.759766         0.755512   \n",
       "92            0.739806           0.737864           0.728516         0.735409   \n",
       "93            0.747573           0.741748           0.738281         0.742542   \n",
       "94            0.741748           0.774757           0.740234         0.752270   \n",
       "95            0.732039           0.796117           0.755859         0.761349   \n",
       "96            0.737864           0.782524           0.759766         0.760052   \n",
       "97            0.741748           0.747573           0.730469         0.739948   \n",
       "98            0.743689           0.759223           0.738281         0.747082   \n",
       "99            0.747573           0.745631           0.734375         0.742542   \n",
       "100           0.739806           0.741748           0.734375         0.738651   \n",
       "101           0.743689           0.761165           0.736328         0.747082   \n",
       "102           0.739806           0.743689           0.732422         0.738651   \n",
       "103           0.741748           0.757282           0.734375         0.744488   \n",
       "104           0.765049           0.792233           0.761719         0.773022   \n",
       "105           0.759223           0.770874           0.757812         0.762646   \n",
       "106           0.739806           0.766990           0.757812         0.754864   \n",
       "107           0.745631           0.768932           0.742188         0.752270   \n",
       "108           0.737864           0.739806           0.736328         0.738003   \n",
       "109           0.763107           0.784466           0.748047         0.765240   \n",
       "110           0.747573           0.745631           0.732422         0.741894   \n",
       "111           0.730097           0.770874           0.769531         0.756809   \n",
       "112           0.737864           0.780583           0.761719         0.760052   \n",
       "113           0.739806           0.741748           0.736328         0.739300   \n",
       "114           0.763107           0.801942           0.765625         0.776913   \n",
       "115           0.733981           0.784466           0.761719         0.760052   \n",
       "116           0.749515           0.763107           0.746094         0.752918   \n",
       "117           0.747573           0.766990           0.746094         0.753567   \n",
       "118           0.739806           0.739806           0.734375         0.738003   \n",
       "119           0.755340           0.786408           0.757812         0.766537   \n",
       "\n",
       "     std_test_score  rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0          0.009525               47            1.000000            0.998053   \n",
       "1          0.013285               60            0.993184            0.990263   \n",
       "2          0.010685               38            1.000000            0.998053   \n",
       "3          0.021681               60            0.988315            0.983447   \n",
       "4          0.006441              119            1.000000            0.998053   \n",
       "5          0.013635               74            1.000000            0.998053   \n",
       "6          0.009157               71            1.000000            0.998053   \n",
       "7          0.015695               74            0.993184            0.989289   \n",
       "8          0.013635               74            1.000000            0.998053   \n",
       "9          0.020907               10            0.963973            0.966894   \n",
       "10         0.010443               47            1.000000            0.998053   \n",
       "11         0.008384               33            1.000000            0.998053   \n",
       "12         0.010685               38            1.000000            0.998053   \n",
       "13         0.004670              106            1.000000            0.998053   \n",
       "14         0.010247               90            1.000000            0.998053   \n",
       "15         0.010415               82            1.000000            0.998053   \n",
       "16         0.019276               67            0.989289            0.984421   \n",
       "17         0.013678               12            0.986368            0.983447   \n",
       "18         0.003827              115            1.000000            0.998053   \n",
       "19         0.006720               93            0.999026            0.995131   \n",
       "20         0.002284              114            1.000000            0.998053   \n",
       "21         0.009412              101            1.000000            0.998053   \n",
       "22         0.020108               15            0.940604            0.941577   \n",
       "23         0.016619               74            1.000000            0.998053   \n",
       "24         0.008883               23            1.000000            0.998053   \n",
       "25         0.009593               43            1.000000            0.998053   \n",
       "26         0.010442               56            1.000000            0.998053   \n",
       "27         0.013197               87            1.000000            0.998053   \n",
       "28         0.009542               87            1.000000            0.998053   \n",
       "29         0.004924              115            1.000000            0.998053   \n",
       "..              ...              ...                 ...                 ...   \n",
       "90         0.008384               33            1.000000            0.998053   \n",
       "91         0.014594               56            0.995131            0.993184   \n",
       "92         0.004924              115            1.000000            0.997079   \n",
       "93         0.003833               97            0.992210            0.990263   \n",
       "94         0.015936               71            1.000000            0.998053   \n",
       "95         0.026470               33            0.977605            0.976631   \n",
       "96         0.018251               40            0.836417            0.819864   \n",
       "97         0.007095              102            1.000000            0.998053   \n",
       "98         0.008877               82            1.000000            0.998053   \n",
       "99         0.005813               97            0.997079            0.994158   \n",
       "100        0.003118              106            1.000000            0.998053   \n",
       "101        0.010415               82            1.000000            0.998053   \n",
       "102        0.004670              106            1.000000            0.998053   \n",
       "103        0.009546               91            1.000000            0.998053   \n",
       "104        0.013672                7            0.984421            0.981500   \n",
       "105        0.005855               29            1.000000            0.998053   \n",
       "106        0.011302               58            1.000000            0.998053   \n",
       "107        0.011883               71            1.000000            0.998053   \n",
       "108        0.001422              110            1.000000            0.998053   \n",
       "109        0.014937               23            0.997079            0.992210   \n",
       "110        0.006725              100            0.999026            0.995131   \n",
       "111        0.018924               51            0.998053            0.994158   \n",
       "112        0.017496               40            0.994158            0.992210   \n",
       "113        0.002240              105            1.000000            0.998053   \n",
       "114        0.017754                4            0.962999            0.962025   \n",
       "115        0.020664               40            0.983447            0.981500   \n",
       "116        0.007349               67            1.000000            0.998053   \n",
       "117        0.009525               62            1.000000            0.998053   \n",
       "118        0.002558              110            1.000000            0.998053   \n",
       "119        0.014107               20            0.891918            0.894839   \n",
       "\n",
       "     split2_train_score  mean_train_score  std_train_score  \n",
       "0              0.997087          0.998380         0.001211  \n",
       "1              0.993204          0.992217         0.001382  \n",
       "2              0.998058          0.998704         0.000917  \n",
       "3              0.991262          0.987675         0.003223  \n",
       "4              0.998058          0.998704         0.000917  \n",
       "5              0.998058          0.998704         0.000917  \n",
       "6              0.998058          0.998704         0.000917  \n",
       "7              0.993204          0.991892         0.001841  \n",
       "8              0.998058          0.998704         0.000917  \n",
       "9              0.967961          0.966276         0.001686  \n",
       "10             0.997087          0.998380         0.001211  \n",
       "11             0.998058          0.998704         0.000917  \n",
       "12             0.998058          0.998704         0.000917  \n",
       "13             0.998058          0.998704         0.000917  \n",
       "14             0.998058          0.998704         0.000917  \n",
       "15             0.998058          0.998704         0.000917  \n",
       "16             0.991262          0.988324         0.002875  \n",
       "17             0.984466          0.984760         0.001211  \n",
       "18             0.998058          0.998704         0.000917  \n",
       "19             0.997087          0.997082         0.001590  \n",
       "20             0.998058          0.998704         0.000917  \n",
       "21             0.998058          0.998704         0.000917  \n",
       "22             0.935922          0.939368         0.002469  \n",
       "23             0.997087          0.998380         0.001211  \n",
       "24             0.997087          0.998380         0.001211  \n",
       "25             0.997087          0.998380         0.001211  \n",
       "26             0.997087          0.998380         0.001211  \n",
       "27             0.998058          0.998704         0.000917  \n",
       "28             0.998058          0.998704         0.000917  \n",
       "29             0.998058          0.998704         0.000917  \n",
       "..                  ...               ...              ...  \n",
       "90             0.998058          0.998704         0.000917  \n",
       "91             0.997087          0.995134         0.001594  \n",
       "92             0.997087          0.998055         0.001375  \n",
       "93             0.992233          0.991569         0.000923  \n",
       "94             0.998058          0.998704         0.000917  \n",
       "95             0.981553          0.978596         0.002128  \n",
       "96             0.838835          0.831705         0.008431  \n",
       "97             0.998058          0.998704         0.000917  \n",
       "98             0.998058          0.998704         0.000917  \n",
       "99             0.996117          0.995784         0.001215  \n",
       "100            0.998058          0.998704         0.000917  \n",
       "101            0.998058          0.998704         0.000917  \n",
       "102            0.998058          0.998704         0.000917  \n",
       "103            0.998058          0.998704         0.000917  \n",
       "104            0.983495          0.983138         0.001219  \n",
       "105            0.998058          0.998704         0.000917  \n",
       "106            0.998058          0.998704         0.000917  \n",
       "107            0.998058          0.998704         0.000917  \n",
       "108            0.998058          0.998704         0.000917  \n",
       "109            0.997087          0.995459         0.002297  \n",
       "110            0.997087          0.997082         0.001590  \n",
       "111            0.997087          0.996433         0.001656  \n",
       "112            0.994175          0.993514         0.000922  \n",
       "113            0.998058          0.998704         0.000917  \n",
       "114            0.968932          0.964652         0.003052  \n",
       "115            0.986408          0.983785         0.002018  \n",
       "116            0.998058          0.998704         0.000917  \n",
       "117            0.998058          0.998704         0.000917  \n",
       "118            0.998058          0.998704         0.000917  \n",
       "119            0.898058          0.894939         0.002508  \n",
       "\n",
       "[120 rows x 19 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(svmRSCV.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7558139534883721"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svmRSCV.best_estimator_.score(vectTexts_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8081395348837209"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svmRSCV.best_estimator_.score(vectTexts_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
