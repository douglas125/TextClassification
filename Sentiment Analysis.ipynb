{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis\n",
    "\n",
    "Download the Foursquare annotated comments in Brazilian Portuguese: https://www.kaggle.com/thaisalmeida/tips-foursquare/version/1\n",
    "\n",
    "Place the files in subfolder 'docs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "pd.set_option('max_colwidth',150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texto</th>\n",
       "      <th>rotulo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A comida é deliciosa, mas pedi limonada suiça e me disseram que hoje estavam todos muito ocupados e que ninguém conseguiria me atender....melhor i...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A partir desta sexta feira dia 11 começam a abrir para jantar mas corre pois é só até as 22 hrs e no domingo dia das mães, estarão aberto durante ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Joint burguer e brewdog</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Agora de segunda a sexta o Habanero vai abrir no almoço com pratos mexicanos e tradicionais!</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Experimente o drink \"Dona Diabla\". Muito bom!</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Nova senha do Wifi: 1129508219</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Wi-fi 1129508219</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Adoramos a pizza carbonara e a paulistana. Não surpreendeu tanto, mas vale a pena por resgatar o tradicionalismo. Dica @Gourmet_For</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>O diferencial desse Burger King é que você mesmo serve o refrigerante, e a vontade!</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Unico defeito estacionamento pago!</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>24h é 24h.</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Excelente Burger King: bom atendimento, ambiente agradável e refil para refrigerante. Evite o inconveniente estacionamento pago estacionando ao re...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>o atendimento aqui é simplesmente um lixo</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>O Drive-Truh mais lento da cidade!!</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Cheio de bêbados depois das 2 da manhã :D</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Recinto sujo, sem manutenção. Não há segurança pra conter a briga que ocorreu agora há pouco. O refrigerante está aguado, sem gosto, horrível. O l...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                    texto  \\\n",
       "0   A comida é deliciosa, mas pedi limonada suiça e me disseram que hoje estavam todos muito ocupados e que ninguém conseguiria me atender....melhor i...   \n",
       "1   A partir desta sexta feira dia 11 começam a abrir para jantar mas corre pois é só até as 22 hrs e no domingo dia das mães, estarão aberto durante ...   \n",
       "2                                                                                                                                 Joint burguer e brewdog   \n",
       "3                                                            Agora de segunda a sexta o Habanero vai abrir no almoço com pratos mexicanos e tradicionais!   \n",
       "4                                                                                                           Experimente o drink \"Dona Diabla\". Muito bom!   \n",
       "5                                                                                                                          Nova senha do Wifi: 1129508219   \n",
       "6                                                                                                                                        Wi-fi 1129508219   \n",
       "7                     Adoramos a pizza carbonara e a paulistana. Não surpreendeu tanto, mas vale a pena por resgatar o tradicionalismo. Dica @Gourmet_For   \n",
       "8                                                                     O diferencial desse Burger King é que você mesmo serve o refrigerante, e a vontade!   \n",
       "9                                                                                                                      Unico defeito estacionamento pago!   \n",
       "10                                                                                                                                             24h é 24h.   \n",
       "11  Excelente Burger King: bom atendimento, ambiente agradável e refil para refrigerante. Evite o inconveniente estacionamento pago estacionando ao re...   \n",
       "12                                                                                                              o atendimento aqui é simplesmente um lixo   \n",
       "13                                                                                                                    O Drive-Truh mais lento da cidade!!   \n",
       "14                                                                                                              Cheio de bêbados depois das 2 da manhã :D   \n",
       "15  Recinto sujo, sem manutenção. Não há segurança pra conter a briga que ocorreu agora há pouco. O refrigerante está aguado, sem gosto, horrível. O l...   \n",
       "\n",
       "    rotulo  \n",
       "0     -1.0  \n",
       "1      0.0  \n",
       "2      0.0  \n",
       "3      0.0  \n",
       "4      1.0  \n",
       "5      0.0  \n",
       "6      0.0  \n",
       "7      1.0  \n",
       "8      1.0  \n",
       "9     -1.0  \n",
       "10     0.0  \n",
       "11     1.0  \n",
       "12    -1.0  \n",
       "13    -1.0  \n",
       "14    -1.0  \n",
       "15    -1.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('docs/tips_scenario1_train.csv')\n",
    "df.head(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def splitWithPunctuation(text):\n",
    "    return re.findall(r\"[\\w']+|[.,!?;:\\\"]\", text)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mas', 'que', ':', '\"', 'legal', '\"']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitWithPunctuation('mas que: \"legal\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1714, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline: Bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df['texto'].astype(str).tolist()\n",
    "categs = df['rotulo'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(texts, categs, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "countVec = CountVectorizer()\n",
    "vectTexts_train = countVec.fit_transform(X_train)\n",
    "vectTexts_test = countVec.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1542x4781 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 25423 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectTexts_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "mnb.fit(vectTexts_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9137483787289234"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb.score(vectTexts_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7790697674418605"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb.score(vectTexts_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=None, error_score='raise',\n",
       "          estimator=MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),\n",
       "          fit_params=None, iid=True, n_iter=10, n_jobs=1,\n",
       "          param_distributions={'alpha': [0.001, 0.1, 1, 10, 100], 'fit_prior': [True, False]},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score=True, scoring=None, verbose=1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnbParams = { #'verbose' : [1],\n",
    "             'alpha':[0.001, 0.1,1,10, 100],  \n",
    "             'fit_prior' :[True, False]}\n",
    "mnbRSCV = RandomizedSearchCV(mnb, mnbParams, verbose=1, return_train_score=True) #, n_jobs=-1)\n",
    "mnbRSCV.fit(vectTexts_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_fit_prior</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.005208</td>\n",
       "      <td>7.365134e-03</td>\n",
       "      <td>0.005208</td>\n",
       "      <td>7.365471e-03</td>\n",
       "      <td>True</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'fit_prior': True, 'alpha': 0.001}</td>\n",
       "      <td>0.753398</td>\n",
       "      <td>0.782524</td>\n",
       "      <td>0.748047</td>\n",
       "      <td>0.761349</td>\n",
       "      <td>0.015153</td>\n",
       "      <td>3</td>\n",
       "      <td>0.988315</td>\n",
       "      <td>0.986368</td>\n",
       "      <td>0.989320</td>\n",
       "      <td>0.988001</td>\n",
       "      <td>0.001226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>False</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'fit_prior': False, 'alpha': 0.001}</td>\n",
       "      <td>0.741748</td>\n",
       "      <td>0.768932</td>\n",
       "      <td>0.753906</td>\n",
       "      <td>0.754864</td>\n",
       "      <td>0.011129</td>\n",
       "      <td>4</td>\n",
       "      <td>0.991237</td>\n",
       "      <td>0.986368</td>\n",
       "      <td>0.988350</td>\n",
       "      <td>0.988651</td>\n",
       "      <td>0.001999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.006229</td>\n",
       "      <td>7.440478e-03</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>4.713704e-04</td>\n",
       "      <td>True</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'fit_prior': True, 'alpha': 0.1}</td>\n",
       "      <td>0.737864</td>\n",
       "      <td>0.765049</td>\n",
       "      <td>0.697266</td>\n",
       "      <td>0.733463</td>\n",
       "      <td>0.027834</td>\n",
       "      <td>5</td>\n",
       "      <td>0.982473</td>\n",
       "      <td>0.979552</td>\n",
       "      <td>0.986408</td>\n",
       "      <td>0.982811</td>\n",
       "      <td>0.002809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001999</td>\n",
       "      <td>1.123916e-07</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>2.247832e-07</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'fit_prior': False, 'alpha': 0.1}</td>\n",
       "      <td>0.704854</td>\n",
       "      <td>0.728155</td>\n",
       "      <td>0.667969</td>\n",
       "      <td>0.700389</td>\n",
       "      <td>0.024762</td>\n",
       "      <td>7</td>\n",
       "      <td>0.978578</td>\n",
       "      <td>0.977605</td>\n",
       "      <td>0.983495</td>\n",
       "      <td>0.979893</td>\n",
       "      <td>0.002578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.002045</td>\n",
       "      <td>6.479383e-05</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>4.713704e-04</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>{'fit_prior': True, 'alpha': 1}</td>\n",
       "      <td>0.790291</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.791016</td>\n",
       "      <td>0.793774</td>\n",
       "      <td>0.004419</td>\n",
       "      <td>1</td>\n",
       "      <td>0.913340</td>\n",
       "      <td>0.910419</td>\n",
       "      <td>0.913592</td>\n",
       "      <td>0.912450</td>\n",
       "      <td>0.001440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>{'fit_prior': False, 'alpha': 1}</td>\n",
       "      <td>0.786408</td>\n",
       "      <td>0.803883</td>\n",
       "      <td>0.775391</td>\n",
       "      <td>0.788586</td>\n",
       "      <td>0.011728</td>\n",
       "      <td>2</td>\n",
       "      <td>0.926972</td>\n",
       "      <td>0.927945</td>\n",
       "      <td>0.933010</td>\n",
       "      <td>0.929309</td>\n",
       "      <td>0.002647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "      <td>{'fit_prior': True, 'alpha': 10}</td>\n",
       "      <td>0.689320</td>\n",
       "      <td>0.685437</td>\n",
       "      <td>0.693359</td>\n",
       "      <td>0.689364</td>\n",
       "      <td>0.003233</td>\n",
       "      <td>8</td>\n",
       "      <td>0.702045</td>\n",
       "      <td>0.696203</td>\n",
       "      <td>0.693204</td>\n",
       "      <td>0.697150</td>\n",
       "      <td>0.003671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>{'fit_prior': False, 'alpha': 10}</td>\n",
       "      <td>0.704854</td>\n",
       "      <td>0.700971</td>\n",
       "      <td>0.708984</td>\n",
       "      <td>0.704929</td>\n",
       "      <td>0.003270</td>\n",
       "      <td>6</td>\n",
       "      <td>0.741967</td>\n",
       "      <td>0.720545</td>\n",
       "      <td>0.722330</td>\n",
       "      <td>0.728281</td>\n",
       "      <td>0.009705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.005208</td>\n",
       "      <td>7.365358e-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>True</td>\n",
       "      <td>100</td>\n",
       "      <td>{'fit_prior': True, 'alpha': 100}</td>\n",
       "      <td>0.681553</td>\n",
       "      <td>0.681553</td>\n",
       "      <td>0.683594</td>\n",
       "      <td>0.682231</td>\n",
       "      <td>0.000961</td>\n",
       "      <td>10</td>\n",
       "      <td>0.682571</td>\n",
       "      <td>0.682571</td>\n",
       "      <td>0.681553</td>\n",
       "      <td>0.682232</td>\n",
       "      <td>0.000480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>False</td>\n",
       "      <td>100</td>\n",
       "      <td>{'fit_prior': False, 'alpha': 100}</td>\n",
       "      <td>0.689320</td>\n",
       "      <td>0.683495</td>\n",
       "      <td>0.689453</td>\n",
       "      <td>0.687419</td>\n",
       "      <td>0.002779</td>\n",
       "      <td>9</td>\n",
       "      <td>0.694255</td>\n",
       "      <td>0.691334</td>\n",
       "      <td>0.691262</td>\n",
       "      <td>0.692284</td>\n",
       "      <td>0.001394</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.005208  7.365134e-03         0.005208    7.365471e-03   \n",
       "1       0.000000  0.000000e+00         0.000000    0.000000e+00   \n",
       "2       0.006229  7.440478e-03         0.000333    4.713704e-04   \n",
       "3       0.001999  1.123916e-07         0.001000    2.247832e-07   \n",
       "4       0.002045  6.479383e-05         0.000333    4.713704e-04   \n",
       "5       0.000000  0.000000e+00         0.000000    0.000000e+00   \n",
       "6       0.000000  0.000000e+00         0.000000    0.000000e+00   \n",
       "7       0.000000  0.000000e+00         0.000000    0.000000e+00   \n",
       "8       0.005208  7.365358e-03         0.000000    0.000000e+00   \n",
       "9       0.000000  0.000000e+00         0.000000    0.000000e+00   \n",
       "\n",
       "  param_fit_prior param_alpha                                params  \\\n",
       "0            True       0.001   {'fit_prior': True, 'alpha': 0.001}   \n",
       "1           False       0.001  {'fit_prior': False, 'alpha': 0.001}   \n",
       "2            True         0.1     {'fit_prior': True, 'alpha': 0.1}   \n",
       "3           False         0.1    {'fit_prior': False, 'alpha': 0.1}   \n",
       "4            True           1       {'fit_prior': True, 'alpha': 1}   \n",
       "5           False           1      {'fit_prior': False, 'alpha': 1}   \n",
       "6            True          10      {'fit_prior': True, 'alpha': 10}   \n",
       "7           False          10     {'fit_prior': False, 'alpha': 10}   \n",
       "8            True         100     {'fit_prior': True, 'alpha': 100}   \n",
       "9           False         100    {'fit_prior': False, 'alpha': 100}   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  mean_test_score  \\\n",
       "0           0.753398           0.782524           0.748047         0.761349   \n",
       "1           0.741748           0.768932           0.753906         0.754864   \n",
       "2           0.737864           0.765049           0.697266         0.733463   \n",
       "3           0.704854           0.728155           0.667969         0.700389   \n",
       "4           0.790291           0.800000           0.791016         0.793774   \n",
       "5           0.786408           0.803883           0.775391         0.788586   \n",
       "6           0.689320           0.685437           0.693359         0.689364   \n",
       "7           0.704854           0.700971           0.708984         0.704929   \n",
       "8           0.681553           0.681553           0.683594         0.682231   \n",
       "9           0.689320           0.683495           0.689453         0.687419   \n",
       "\n",
       "   std_test_score  rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0        0.015153                3            0.988315            0.986368   \n",
       "1        0.011129                4            0.991237            0.986368   \n",
       "2        0.027834                5            0.982473            0.979552   \n",
       "3        0.024762                7            0.978578            0.977605   \n",
       "4        0.004419                1            0.913340            0.910419   \n",
       "5        0.011728                2            0.926972            0.927945   \n",
       "6        0.003233                8            0.702045            0.696203   \n",
       "7        0.003270                6            0.741967            0.720545   \n",
       "8        0.000961               10            0.682571            0.682571   \n",
       "9        0.002779                9            0.694255            0.691334   \n",
       "\n",
       "   split2_train_score  mean_train_score  std_train_score  \n",
       "0            0.989320          0.988001         0.001226  \n",
       "1            0.988350          0.988651         0.001999  \n",
       "2            0.986408          0.982811         0.002809  \n",
       "3            0.983495          0.979893         0.002578  \n",
       "4            0.913592          0.912450         0.001440  \n",
       "5            0.933010          0.929309         0.002647  \n",
       "6            0.693204          0.697150         0.003671  \n",
       "7            0.722330          0.728281         0.009705  \n",
       "8            0.681553          0.682232         0.000480  \n",
       "9            0.691262          0.692284         0.001394  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(mnbRSCV.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7790697674418605"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnbRSCV.best_estimator_.score(vectTexts_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embedding Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Embeddings import WordEmbeddingBR, splitWithPunctuation\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading NILC word embeddings. More available at http://nilc.icmc.usp.br/embeddings\n",
      "glove50 exists. Skipping.\n",
      "cbow50_wang2vec exists. Skipping.\n",
      "cbow50_fasttext exists. Skipping.\n",
      "skip50_word2vec exists. Skipping.\n",
      "Done!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['cbow50_fasttext',\n",
       " 'cbow50_wang2vec',\n",
       " 'glove50',\n",
       " 'skip50_word2vec',\n",
       " 'skip_s300_word2vec']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WordEmbeddingBR.downloadNILCEmbeddings()\n",
    "WordEmbeddingBR.getAvailableEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading embedding file: skip_s300_word2vec.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "934967it [02:38, 5914.47it/s]\n"
     ]
    }
   ],
   "source": [
    "wee = WordEmbeddingBR('skip_s300_word2vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = max([len(x) for x in X_train])\n",
    "def getSentenceVector(x, emb):\n",
    "    wordArray = splitWithPunctuation(x)\n",
    "    ans = np.zeros( (maxlen, emb.embDim) )\n",
    "    for i,w in enumerate(wordArray):\n",
    "        if len(w) > 2:\n",
    "            ans[i] = emb.encodeWord(w.lower())\n",
    "            ans[i] /= (np.linalg.norm(ans[i])+1e-4)\n",
    "        \n",
    "    return np.sum(ans,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Muito caro pelo tamanho e sabor. Fomos em dois e gastamos R$60,00. Para fast food de tamanho normal, foi muito.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getSentenceVector(X_train[2], wee).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Achei a comida bem medíocre. Prato com muitas coisas, mas nada com sabor. Não vale o que custa.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.01614947, -0.10834916, -0.05412925, -0.68149838, -0.34972678,\n",
       "        0.07611305,  0.21173427, -0.16032821, -0.09424525, -0.49070412,\n",
       "       -0.98033918, -0.55583156, -0.36792939, -0.25768241, -0.14422328,\n",
       "       -0.18532498, -0.37150617,  0.33750424,  0.80553468,  0.57310063,\n",
       "        1.1218442 , -0.23137208, -0.43360203, -0.37138272,  0.15888166,\n",
       "        0.00609828,  0.65231598,  0.67753354, -0.08889965,  0.25209472,\n",
       "       -0.82058552,  0.40230038, -0.24429756,  0.08174712, -0.27499635,\n",
       "       -0.04251375, -0.10124676, -0.39328442, -0.13845402, -0.00286722,\n",
       "        0.08634738,  0.31591046,  0.24507671,  0.57419708,  0.1381439 ,\n",
       "       -0.28199261,  0.69349179,  0.0255523 ,  0.1906665 ,  0.04768168,\n",
       "       -0.43295604, -0.11906724, -0.18540661,  0.11029822, -0.25131733,\n",
       "        0.35577184, -0.13817987,  0.19460735,  0.20334827,  0.08174238,\n",
       "        0.35756133,  1.24393274, -0.03804483,  0.85921946, -0.11411306,\n",
       "       -0.2901375 ,  0.20000887, -1.02227981,  0.14509503,  0.21253157,\n",
       "        0.05159791,  0.68194951,  0.44394827, -0.06307669,  0.56861204,\n",
       "        0.0811925 , -0.24850383,  0.02500243,  0.57102346, -0.7589592 ,\n",
       "        0.67579438, -0.49010337,  0.18007549, -0.27138866,  0.38221733,\n",
       "       -0.05245645,  0.62696572, -0.4524083 ,  0.11997484,  0.34447917,\n",
       "        0.00823511, -0.21702435, -0.27375723,  0.21300866, -0.25577503,\n",
       "       -0.16800074,  0.62219178, -0.77775738,  0.93623758, -0.07360079,\n",
       "        0.35689384, -0.42426381,  0.34370686,  0.30487964, -0.84823811,\n",
       "        0.56751058,  0.14638213,  0.03543009, -0.55581767,  0.08793094,\n",
       "       -0.28375693,  0.64584831, -0.64693669, -0.01578086, -0.31492951,\n",
       "       -0.19091774,  0.51077702,  0.24973838, -0.26292228, -0.37478306,\n",
       "       -0.34002347,  0.13442317, -0.14937949,  0.09411065, -0.39328099,\n",
       "       -0.31100302,  0.4500634 , -0.06690285, -0.23801543, -0.97544452,\n",
       "        0.39118726, -0.1504515 , -0.43121323, -0.30185264, -0.71611301,\n",
       "        0.40336248,  0.11670263,  0.63904599,  0.41580601,  0.0143917 ,\n",
       "       -0.02431959,  0.18069987,  0.22092707,  0.56351169, -0.61089522,\n",
       "        0.3793546 , -0.3746322 ,  0.33024188,  0.11020898,  0.35791918,\n",
       "        0.48697245,  0.07250617, -0.15257748, -0.19569926, -0.27389941,\n",
       "       -0.37824161, -0.40659691, -1.04794691,  0.18333985,  0.10518092,\n",
       "        0.22887759, -0.75356277,  0.26522281,  0.2408327 , -0.84659189,\n",
       "        0.3269723 , -0.33463618, -0.2909238 , -0.21465097, -0.07060703,\n",
       "       -0.67522916,  0.12983548,  0.76148569, -0.26118027,  1.15848903,\n",
       "       -0.38248693, -0.17107976, -0.55207782, -0.29731017,  0.81760698,\n",
       "       -0.15644668, -0.29010573, -0.15988918,  0.55269433,  0.1409869 ,\n",
       "        0.52399786,  0.13771456, -0.69486389,  0.3961106 ,  0.68926842,\n",
       "       -0.41662999, -0.56882011,  0.35504357, -0.28048019,  0.06327518,\n",
       "       -0.00557957, -0.4788571 , -0.20091733,  0.57919351, -0.00846689,\n",
       "        0.58580518,  0.50695295,  0.05830112, -0.22943778,  0.35602464,\n",
       "        0.32158273, -0.41793942,  0.21327044, -0.48694118, -0.38885704,\n",
       "        0.05769246,  0.70714078, -0.04531646, -0.04971374,  0.13633809,\n",
       "        0.03954803, -0.17461784, -0.14552734, -0.2547901 ,  0.08838938,\n",
       "        0.48489433, -0.07455718,  0.53951309,  0.17744014, -0.02403631,\n",
       "       -0.50659101, -0.26031618, -0.32728253,  0.19353755,  0.21322569,\n",
       "        0.96938914,  0.84510706, -0.13996569,  0.64453053, -0.55611401,\n",
       "       -0.71975119, -0.05110313, -0.29779727, -0.3098777 , -0.26762631,\n",
       "       -0.12061974,  0.01823781, -0.74644666, -0.00746657, -0.35438452,\n",
       "       -0.33343457,  0.02519119, -0.53788316,  0.30379016, -0.61838475,\n",
       "       -0.43550517,  0.39580805, -0.68692699,  0.4174866 ,  0.10225828,\n",
       "        0.76913567, -0.39022968,  0.1000925 ,  0.43859418, -0.06741455,\n",
       "       -0.49009437,  0.23463618, -0.01062798, -0.32948271, -0.05852406,\n",
       "        0.05048265, -0.00898627,  0.1392106 ,  0.25398139, -0.36859127,\n",
       "       -0.7010695 , -0.01499047, -0.05986606, -0.37824043, -0.18696835,\n",
       "        0.40944431, -0.18306419, -0.19225972,  0.13633429,  0.15749721,\n",
       "       -0.43777257,  0.18042998,  0.22305968,  0.21229824,  0.68913915,\n",
       "       -0.30763121,  0.03150913,  0.31883832, -0.29230936, -0.03731792,\n",
       "       -0.06316917, -0.1447342 , -0.13635976, -0.10860098, -0.61457697,\n",
       "        0.12890431,  0.35346512,  0.23759711,  0.50154448,  0.03309892])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectTexts_train = [getSentenceVector(x, wee).reshape((-1,)) for x in X_train]\n",
    "vectTexts_test = [getSentenceVector(x, wee).reshape((-1,)) for x in X_test]\n",
    "getSentenceVector(X_train[0], wee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1        1292.7515            1.24m\n",
      "         2        1160.9407            1.30m\n",
      "         3        1047.6714            1.29m\n",
      "         4         955.1006            1.29m\n",
      "         5         866.7839            1.29m\n",
      "         6         794.9990            1.29m\n",
      "         7         732.1851            1.30m\n",
      "         8         675.2564            1.30m\n",
      "         9         623.0586            1.30m\n",
      "        10         575.3102            1.29m\n",
      "        20         294.0879            1.23m\n",
      "        30         175.8658            1.17m\n",
      "        40         110.3201            1.13m\n",
      "        50          71.8176            1.09m\n",
      "        60          47.4958            1.05m\n",
      "        70          33.5867            1.00m\n",
      "        80          23.5397           57.74s\n",
      "        90          17.4062           55.17s\n",
      "       100          13.1753           52.60s\n",
      "       200           4.6168           27.14s\n",
      "       300           4.3792            3.77s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=6,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=320,\n",
       "              presort='auto', random_state=None, subsample=1.0, verbose=1,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#try some of scikit learn classifiers\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "\n",
    "gbc = GradientBoostingClassifier(verbose=1, learning_rate=0.1, n_estimators=320, max_depth=6)\n",
    "gbc.fit(vectTexts_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.9980544747081712 Test score: 0.7093023255813954\n"
     ]
    }
   ],
   "source": [
    "print('Train score: {} Test score: {}'.format(gbc.score(vectTexts_train, y_train),gbc.score(vectTexts_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         828.9811            5.66s\n",
      "         2         730.0465            5.58s\n",
      "         3         649.2909            5.72s\n",
      "         4         579.4302            5.54s\n",
      "         5         512.3739            5.52s\n",
      "         6         453.0767            5.51s\n",
      "         7         409.0992            5.41s\n",
      "         8         369.8419            5.24s\n",
      "         9         337.4782            5.17s\n",
      "        10         306.7292            5.01s\n",
      "        20         139.7330            3.76s\n",
      "        30          70.8567            2.50s\n",
      "        40          38.8864            1.24s\n",
      "        50          22.4526            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         827.8430            5.86s\n",
      "         2         721.7885            5.67s\n",
      "         3         634.7844            5.81s\n",
      "         4         562.0605            5.62s\n",
      "         5         505.3403            5.59s\n",
      "         6         451.1208            5.52s\n",
      "         7         404.4146            5.46s\n",
      "         8         364.4684            5.26s\n",
      "         9         331.7916            5.18s\n",
      "        10         304.6324            5.02s\n",
      "        20         134.8005            3.78s\n",
      "        30          71.9102            2.50s\n",
      "        40          41.8462            1.24s\n",
      "        50          25.4400            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         816.1968            5.79s\n",
      "         2         697.5785            6.42s\n",
      "         3         608.3945            6.04s\n",
      "         4         533.9999            6.00s\n",
      "         5         473.4996            5.87s\n",
      "         6         418.9906            5.65s\n",
      "         7         379.4645            5.56s\n",
      "         8         340.2728            5.38s\n",
      "         9         309.7698            5.26s\n",
      "        10         284.1558            5.08s\n",
      "        20         127.1257            3.78s\n",
      "        30          68.5647            2.49s\n",
      "        40          38.1524            1.24s\n",
      "        50          22.8279            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         856.7518           14.45s\n",
      "         2         769.2461           14.38s\n",
      "         3         697.7982           14.86s\n",
      "         4         638.6280           14.78s\n",
      "         5         584.1215           14.47s\n",
      "         6         534.4857           14.49s\n",
      "         7         484.9428           14.31s\n",
      "         8         444.9719           14.34s\n",
      "         9         406.7113           14.23s\n",
      "        10         372.4640           14.18s\n",
      "        20         167.4844           12.88s\n",
      "        30          81.6738           11.43s\n",
      "        40          44.1166            9.75s\n",
      "        50          24.7888            8.08s\n",
      "        60          14.0093            6.46s\n",
      "        70           8.0153            4.83s\n",
      "        80           4.6785            3.21s\n",
      "        90           2.7269            1.60s\n",
      "       100           1.5981            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         848.8269           15.00s\n",
      "         2         756.0906           14.89s\n",
      "         3         674.9953           15.12s\n",
      "         4         609.8709           14.91s\n",
      "         5         550.5031           14.89s\n",
      "         6         498.4425           14.92s\n",
      "         7         452.3944           14.88s\n",
      "         8         413.8446           14.78s\n",
      "         9         376.0104           14.66s\n",
      "        10         342.9082           14.45s\n",
      "        20         152.0113           13.26s\n",
      "        30          78.3258           11.47s\n",
      "        40          43.8812            9.75s\n",
      "        50          26.5536            8.06s\n",
      "        60          16.9242            6.41s\n",
      "        70          11.4039            4.81s\n",
      "        80           7.9701            3.21s\n",
      "        90           6.0385            1.60s\n",
      "       100           4.8875            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         845.6757           15.15s\n",
      "         2         746.3240           16.18s\n",
      "         3         666.3720           15.93s\n",
      "         4         594.4135           15.60s\n",
      "         5         537.4950           15.64s\n",
      "         6         484.1394           15.50s\n",
      "         7         435.2656           15.40s\n",
      "         8         392.3641           15.16s\n",
      "         9         356.5836           15.09s\n",
      "        10         324.0896           14.79s\n",
      "        20         141.7209           13.12s\n",
      "        30          73.7962           11.41s\n",
      "        40          41.2760            9.77s\n",
      "        50          25.1325            8.11s\n",
      "        60          15.5980            6.49s\n",
      "        70          10.3968            4.86s\n",
      "        80           7.3811            3.23s\n",
      "        90           5.7323            1.61s\n",
      "       100           4.6625            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         899.1319           14.32s\n",
      "         2         847.1696           13.86s\n",
      "         3         802.8729           13.65s\n",
      "         4         762.0751           13.62s\n",
      "         5         726.2422           13.61s\n",
      "         6         695.6421           13.54s\n",
      "         7         666.5708           13.48s\n",
      "         8         642.7174           13.36s\n",
      "         9         622.0172           13.22s\n",
      "        10         599.9250           13.20s\n",
      "        20         448.0213           12.36s\n",
      "        30         358.0649           11.61s\n",
      "        40         296.0024           10.85s\n",
      "        50         249.1008           10.11s\n",
      "        60         215.6412            9.38s\n",
      "        70         185.4718            8.68s\n",
      "        80         160.1647            7.99s\n",
      "        90         140.6166            7.32s\n",
      "       100         124.5721            6.64s\n",
      "       200          39.6315            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         903.3374           12.44s\n",
      "         2         850.7225           13.56s\n",
      "         3         805.7859           13.42s\n",
      "         4         765.8905           12.80s\n",
      "         5         730.1387           12.72s\n",
      "         6         699.2231           13.37s\n",
      "         7         672.7674           13.80s\n",
      "         8         645.9788           13.79s\n",
      "         9         622.0416           13.68s\n",
      "        10         599.8764           13.59s\n",
      "        20         447.7615           12.86s\n",
      "        30         361.3603           11.94s\n",
      "        40         300.6484           11.10s\n",
      "        50         257.3961           10.30s\n",
      "        60         221.3743            9.56s\n",
      "        70         196.3389            8.84s\n",
      "        80         171.1451            8.14s\n",
      "        90         148.8663            7.45s\n",
      "       100         131.0093            6.77s\n",
      "       200          42.2714            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         900.4649           13.53s\n",
      "         2         845.3314           13.66s\n",
      "         3         796.8977           13.66s\n",
      "         4         753.5696           13.57s\n",
      "         5         716.0993           13.57s\n",
      "         6         683.3047           13.71s\n",
      "         7         654.3775           13.71s\n",
      "         8         626.5096           13.69s\n",
      "         9         603.6359           13.57s\n",
      "        10         582.0282           13.46s\n",
      "        20         426.4522           12.51s\n",
      "        30         344.5444           11.92s\n",
      "        40         285.5900           11.06s\n",
      "        50         241.6632           10.28s\n",
      "        60         207.2061            9.55s\n",
      "        70         178.3980            8.82s\n",
      "        80         155.9575            8.10s\n",
      "        90         135.9570            7.40s\n",
      "       100         120.0841            6.70s\n",
      "       200          38.5116            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         895.4619            1.40m\n",
      "         2         835.6846            1.45m\n",
      "         3         781.9680            1.48m\n",
      "         4         732.0428            1.49m\n",
      "         5         687.6688            1.50m\n",
      "         6         647.5188            1.50m\n",
      "         7         611.4749            1.50m\n",
      "         8         577.2425            1.50m\n",
      "         9         545.3152            1.50m\n",
      "        10         514.5394            1.50m\n",
      "        20         297.7246            1.49m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        30         169.9454            1.49m\n",
      "        40          98.4174            1.47m\n",
      "        50          59.2979            1.43m\n",
      "        60          36.7638            1.40m\n",
      "        70          22.9115            1.36m\n",
      "        80          14.7844            1.32m\n",
      "        90           9.4897            1.27m\n",
      "       100           6.0925            1.23m\n",
      "       200           0.3004           40.46s\n",
      "       300           0.2917           13.62s\n",
      "       400           0.2917            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         891.2424            1.35m\n",
      "         2         827.4574            1.45m\n",
      "         3         773.2979            1.47m\n",
      "         4         720.9781            1.49m\n",
      "         5         671.4364            1.51m\n",
      "         6         628.3645            1.51m\n",
      "         7         588.4769            1.51m\n",
      "         8         551.9916            1.52m\n",
      "         9         517.2990            1.54m\n",
      "        10         486.1422            1.54m\n",
      "        20         264.6243            1.52m\n",
      "        30         150.3349            1.49m\n",
      "        40          88.1885            1.46m\n",
      "        50          53.6026            1.42m\n",
      "        60          33.5717            1.38m\n",
      "        70          22.2738            1.33m\n",
      "        80          15.5151            1.28m\n",
      "        90          11.2060            1.24m\n",
      "       100           8.4383            1.19m\n",
      "       200           3.0761           42.06s\n",
      "       300           2.9208           16.87s\n",
      "       400           2.8542            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         894.6487            1.34m\n",
      "         2         831.2819            1.45m\n",
      "         3         771.9910            1.45m\n",
      "         4         718.8668            1.47m\n",
      "         5         669.5979            1.50m\n",
      "         6         624.4151            1.51m\n",
      "         7         583.1746            1.52m\n",
      "         8         544.2904            1.52m\n",
      "         9         509.9720            1.53m\n",
      "        10         478.4401            1.53m\n",
      "        20         257.4371            1.53m\n",
      "        30         148.4418            1.49m\n",
      "        40          86.6764            1.46m\n",
      "        50          52.7257            1.41m\n",
      "        60          32.8831            1.37m\n",
      "        70          21.4288            1.33m\n",
      "        80          14.6157            1.28m\n",
      "        90          10.3699            1.24m\n",
      "       100           7.7656            1.19m\n",
      "       200           3.0556           41.45s\n",
      "       300           2.9142           16.64s\n",
      "       400           2.8489            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         899.1319           24.94s\n",
      "         2         847.1696           24.87s\n",
      "         3         802.8729           24.81s\n",
      "         4         762.0751           26.42s\n",
      "         5         726.2422           26.02s\n",
      "         6         695.6421           25.74s\n",
      "         7         666.5708           26.39s\n",
      "         8         642.7174           26.09s\n",
      "         9         622.0172           25.85s\n",
      "        10         599.9250           26.25s\n",
      "        20         448.0213           25.28s\n",
      "        30         358.0649           25.12s\n",
      "        40         296.0024           24.38s\n",
      "        50         249.1008           23.58s\n",
      "        60         215.6412           22.82s\n",
      "        70         185.4718           22.08s\n",
      "        80         160.1647           21.33s\n",
      "        90         140.6166           20.60s\n",
      "       100         124.5721           19.91s\n",
      "       200          39.6315           12.99s\n",
      "       300          13.5425            6.42s\n",
      "       400           4.6567            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         903.3374           24.94s\n",
      "         2         850.7089           24.87s\n",
      "         3         805.7700           26.88s\n",
      "         4         765.8696           26.30s\n",
      "         5         730.1126           25.92s\n",
      "         6         699.2208           26.68s\n",
      "         7         672.7833           26.32s\n",
      "         8         646.1279           26.03s\n",
      "         9         621.6605           26.47s\n",
      "        10         601.3787           26.49s\n",
      "        20         445.1778           25.37s\n",
      "        30         357.8925           24.56s\n",
      "        40         300.4320           23.71s\n",
      "        50         257.8266           22.79s\n",
      "        60         225.3903           22.17s\n",
      "        70         197.5183           21.35s\n",
      "        80         174.2604           20.68s\n",
      "        90         153.9122           20.05s\n",
      "       100         135.4961           19.32s\n",
      "       200          42.6027           12.87s\n",
      "       300          16.6159            6.44s\n",
      "       400           8.1648            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         900.4649           27.12s\n",
      "         2         845.3314           28.45s\n",
      "         3         796.8977           28.20s\n",
      "         4         753.5696           27.93s\n",
      "         5         716.0993           27.81s\n",
      "         6         683.3047           27.65s\n",
      "         7         654.3775           27.51s\n",
      "         8         626.5096           27.49s\n",
      "         9         603.6359           27.37s\n",
      "        10         582.0282           27.18s\n",
      "        20         426.4522           26.21s\n",
      "        30         344.5444           25.04s\n",
      "        40         285.5900           24.21s\n",
      "        50         241.6632           23.40s\n",
      "        60         207.2061           22.67s\n",
      "        70         178.3980           21.95s\n",
      "        80         155.9575           21.29s\n",
      "        90         135.9570           20.61s\n",
      "       100         120.0841           19.91s\n",
      "       200          38.5116           13.11s\n",
      "       300          14.9348            6.53s\n",
      "       400           6.9855            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         787.8400            5.00s\n",
      "         2         670.6446            5.13s\n",
      "         3         582.0078            4.87s\n",
      "         4         513.1457            4.72s\n",
      "         5         454.4948            4.57s\n",
      "         6         407.5885            4.45s\n",
      "         7         364.8986            4.37s\n",
      "         8         328.6691            4.26s\n",
      "         9         299.8019            4.20s\n",
      "        10         269.6115            4.08s\n",
      "        20         124.1318            2.91s\n",
      "        30          67.4227            1.91s\n",
      "        40          39.7625            0.94s\n",
      "        50          23.0851            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         791.3093            4.59s\n",
      "         2         669.5323            4.44s\n",
      "         3         580.0684            4.37s\n",
      "         4         506.0929            4.46s\n",
      "         5         451.7599            4.35s\n",
      "         6         400.5113            4.39s\n",
      "         7         356.8396            4.28s\n",
      "         8         317.0514            4.18s\n",
      "         9         287.5116            4.09s\n",
      "        10         262.6419            3.97s\n",
      "        20         134.1841            2.88s\n",
      "        30          78.5318            1.88s\n",
      "        40          47.8190            0.93s\n",
      "        50          29.9530            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         776.6889            4.70s\n",
      "         2         643.5804            4.65s\n",
      "         3         542.1901            4.60s\n",
      "         4         475.4971            4.45s\n",
      "         5         418.2423            4.37s\n",
      "         6         374.8490            4.29s\n",
      "         7         338.1207            4.18s\n",
      "         8         308.1518            4.09s\n",
      "         9         276.5359            3.99s\n",
      "        10         250.7633            3.89s\n",
      "        20         123.0063            2.85s\n",
      "        30          69.6690            1.89s\n",
      "        40          41.9413            0.94s\n",
      "        50          27.7965            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         870.8835            2.81s\n",
      "         2         801.1346            3.26s\n",
      "         3         745.1165            3.29s\n",
      "         4         696.0137            3.23s\n",
      "         5         651.7530            3.16s\n",
      "         6         619.6635            3.07s\n",
      "         7         589.2467            3.00s\n",
      "         8         557.9800            2.93s\n",
      "         9         536.6174            2.85s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        10         510.8394            2.80s\n",
      "        20         357.5080            2.04s\n",
      "        30         271.9804            1.34s\n",
      "        40         213.0237            0.66s\n",
      "        50         173.9547            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         876.7533            3.06s\n",
      "         2         805.9608            3.37s\n",
      "         3         747.4050            3.18s\n",
      "         4         698.7659            3.22s\n",
      "         5         657.7161            3.00s\n",
      "         6         620.7328            3.06s\n",
      "         7         588.8819            2.97s\n",
      "         8         560.6086            2.88s\n",
      "         9         532.9693            2.85s\n",
      "        10         509.4466            2.73s\n",
      "        20         358.3749            2.05s\n",
      "        30         277.1252            1.36s\n",
      "        40         221.6860            0.68s\n",
      "        50         180.7958            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         871.0254            3.33s\n",
      "         2         797.1890            3.29s\n",
      "         3         734.4410            3.21s\n",
      "         4         685.4242            3.15s\n",
      "         5         639.6504            3.08s\n",
      "         6         603.4707            3.04s\n",
      "         7         572.1540            2.94s\n",
      "         8         541.2320            2.92s\n",
      "         9         513.6275            2.86s\n",
      "        10         487.5779            2.78s\n",
      "        20         339.1187            2.04s\n",
      "        30         259.5510            1.35s\n",
      "        40         200.6950            0.67s\n",
      "        50         161.3256            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         850.9201           18.70s\n",
      "         2         764.8880           19.10s\n",
      "         3         695.3388           18.91s\n",
      "         4         631.5642           19.15s\n",
      "         5         584.3282           18.95s\n",
      "         6         542.3167           18.97s\n",
      "         7         502.0081           18.93s\n",
      "         8         465.6418           18.81s\n",
      "         9         434.2986           18.69s\n",
      "        10         403.7979           18.96s\n",
      "        20         234.7777           17.49s\n",
      "        30         151.2876           16.37s\n",
      "        40         103.4362           15.11s\n",
      "        50          73.4330           14.06s\n",
      "        60          51.3809           13.03s\n",
      "        70          36.5447           12.02s\n",
      "        80          26.1675           11.05s\n",
      "        90          18.6418           10.11s\n",
      "       100          13.7021            9.17s\n",
      "       200           0.7947            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         852.6176           18.66s\n",
      "         2         765.4075           18.56s\n",
      "         3         694.2435           18.47s\n",
      "         4         635.2702           18.37s\n",
      "         5         584.9351           18.39s\n",
      "         6         539.0162           18.38s\n",
      "         7         498.9205           18.25s\n",
      "         8         459.0805           18.12s\n",
      "         9         427.9049           18.33s\n",
      "        10         399.9719           18.24s\n",
      "        20         228.1038           17.08s\n",
      "        30         149.9329           16.06s\n",
      "        40         103.2085           15.13s\n",
      "        50          73.4017           14.14s\n",
      "        60          52.3581           13.13s\n",
      "        70          38.9312           12.15s\n",
      "        80          29.2908           11.17s\n",
      "        90          22.4148           10.19s\n",
      "       100          17.1402            9.30s\n",
      "       200           3.7423            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         844.9277           18.66s\n",
      "         2         749.7266           18.56s\n",
      "         3         671.6954           18.61s\n",
      "         4         604.2948           19.24s\n",
      "         5         553.6923           18.70s\n",
      "         6         509.2620           18.53s\n",
      "         7         473.8298           18.39s\n",
      "         8         439.9926           18.33s\n",
      "         9         409.0997           18.34s\n",
      "        10         381.0822           18.22s\n",
      "        20         220.4771           16.91s\n",
      "        30         138.6540           15.84s\n",
      "        40          96.6828           14.72s\n",
      "        50          69.7126           13.66s\n",
      "        60          50.4490           12.70s\n",
      "        70          38.3797           11.73s\n",
      "        80          28.7995           10.79s\n",
      "        90          21.8452            9.87s\n",
      "       100          16.6519            8.97s\n",
      "       200           3.6100            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         775.5725           10.72s\n",
      "         2         642.7326           10.50s\n",
      "         3         540.4604           10.65s\n",
      "         4         458.8103           10.51s\n",
      "         5         389.4191           10.19s\n",
      "         6         328.2002           10.14s\n",
      "         7         275.1266            9.93s\n",
      "         8         231.9189            9.80s\n",
      "         9         198.2486            9.57s\n",
      "        10         168.3053            9.41s\n",
      "        20          37.3846            7.16s\n",
      "        30           8.7101            4.81s\n",
      "        40           2.2823            2.38s\n",
      "        50           0.6661            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         771.2034            9.95s\n",
      "         2         620.2879           10.50s\n",
      "         3         512.7106           10.53s\n",
      "         4         428.4080           10.60s\n",
      "         5         356.2441           10.44s\n",
      "         6         292.6364           10.34s\n",
      "         7         245.3486           10.20s\n",
      "         8         204.5458           10.03s\n",
      "         9         171.3586            9.91s\n",
      "        10         144.3642            9.64s\n",
      "        20          34.0375            7.18s\n",
      "        30          10.7493            4.76s\n",
      "        40           5.4358            2.33s\n",
      "        50           3.7733            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         767.5578            9.95s\n",
      "         2         623.1826           10.50s\n",
      "         3         505.8940           10.68s\n",
      "         4         415.8108           10.54s\n",
      "         5         346.3616           10.50s\n",
      "         6         287.5589           10.39s\n",
      "         7         241.3119           10.17s\n",
      "         8         203.8877            9.92s\n",
      "         9         171.8776            9.75s\n",
      "        10         146.3156            9.49s\n",
      "        20          32.4538            7.21s\n",
      "        30          10.5029            4.75s\n",
      "        40           5.2402            2.31s\n",
      "        50           3.6873            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         885.4515            4.59s\n",
      "         2         821.5423            4.12s\n",
      "         3         767.8724            4.16s\n",
      "         4         719.8020            4.13s\n",
      "         5         674.8413            4.22s\n",
      "         6         638.4713            4.01s\n",
      "         7         600.0219            4.03s\n",
      "         8         570.6067            3.86s\n",
      "         9         540.0598            3.84s\n",
      "        10         513.2430            3.69s\n",
      "        20         333.3809            2.81s\n",
      "        30         234.8255            1.87s\n",
      "        40         171.0970            0.93s\n",
      "        50         131.2129            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         887.0049            5.36s\n",
      "         2         821.9969            4.50s\n",
      "         3         766.0390            4.41s\n",
      "         4         718.8618            4.33s\n",
      "         5         674.4813            4.23s\n",
      "         6         638.4179            4.13s\n",
      "         7         604.4227            4.04s\n",
      "         8         570.1071            3.94s\n",
      "         9         540.1546            3.92s\n",
      "        10         514.0546            3.82s\n",
      "        20         330.9809            2.84s\n",
      "        30         233.9671            1.88s\n",
      "        40         176.3553            0.93s\n",
      "        50         136.0776            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         884.0989            4.59s\n",
      "         2         813.4787            4.50s\n",
      "         3         751.4243            4.41s\n",
      "         4         696.5609            4.49s\n",
      "         5         647.9876            4.36s\n",
      "         6         605.2485            4.24s\n",
      "         7         570.8893            4.13s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         8         538.3072            3.98s\n",
      "         9         508.9305            3.88s\n",
      "        10         483.1873            3.79s\n",
      "        20         306.7554            2.83s\n",
      "        30         216.6812            1.87s\n",
      "        40         161.5602            0.92s\n",
      "        50         122.1975            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         791.3794            8.42s\n",
      "         2         667.0974            8.96s\n",
      "         3         568.0344            8.60s\n",
      "         4         487.8983            8.65s\n",
      "         5         413.9688            8.61s\n",
      "         6         354.7553            8.46s\n",
      "         7         307.3574            8.27s\n",
      "         8         262.2731            8.14s\n",
      "         9         228.1565            7.99s\n",
      "        10         198.9460            7.76s\n",
      "        20          53.2628            5.93s\n",
      "        30          15.6800            3.98s\n",
      "        40           5.3888            1.97s\n",
      "        50           1.9565            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         780.8178            8.42s\n",
      "         2         642.6633            8.95s\n",
      "         3         535.4155            8.96s\n",
      "         4         454.2560            8.91s\n",
      "         5         388.3932            8.80s\n",
      "         6         326.5455            8.78s\n",
      "         7         278.8024            8.55s\n",
      "         8         236.7155            8.46s\n",
      "         9         205.7986            8.26s\n",
      "        10         178.2286            8.00s\n",
      "        20          49.9759            6.02s\n",
      "        30          19.1188            3.96s\n",
      "        40           8.9605            1.96s\n",
      "        50           5.2496            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         776.4276            9.95s\n",
      "         2         636.2930            9.75s\n",
      "         3         529.6903            9.55s\n",
      "         4         439.5160            9.43s\n",
      "         5         370.3512            9.21s\n",
      "         6         313.0843            8.88s\n",
      "         7         267.4043            8.68s\n",
      "         8         229.0080            8.56s\n",
      "         9         196.2578            8.35s\n",
      "        10         170.9633            8.07s\n",
      "        20          46.9908            6.02s\n",
      "        30          17.4843            3.96s\n",
      "        40           8.0709            1.96s\n",
      "        50           4.9419            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         907.5566           31.09s\n",
      "         2         857.9956           30.94s\n",
      "         3         812.7176           30.78s\n",
      "         4         771.1161           30.62s\n",
      "         5         734.3600           29.86s\n",
      "         6         701.2085           29.81s\n",
      "         7         669.5670           29.62s\n",
      "         8         640.1309           29.53s\n",
      "         9         611.8264           29.10s\n",
      "        10         586.0731           29.02s\n",
      "        20         377.0594           28.07s\n",
      "        30         252.7754           26.71s\n",
      "        40         172.5669           25.28s\n",
      "        50         120.5004           23.81s\n",
      "        60          85.5700           22.30s\n",
      "        70          61.4732           20.74s\n",
      "        80          44.0800           19.15s\n",
      "        90          32.4758           17.57s\n",
      "       100          24.5305           15.94s\n",
      "       200           1.8110            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         902.3152           31.09s\n",
      "         2         851.3056           30.94s\n",
      "         3         804.0571           30.32s\n",
      "         4         759.2601           30.71s\n",
      "         5         719.2143           30.53s\n",
      "         6         680.3236           30.55s\n",
      "         7         647.4233           30.36s\n",
      "         8         614.7383           30.17s\n",
      "         9         583.0961           30.02s\n",
      "        10         554.9272           30.15s\n",
      "        20         344.2300           28.76s\n",
      "        30         224.9130           27.40s\n",
      "        40         152.8618           25.79s\n",
      "        50         108.5329           24.12s\n",
      "        60          79.1310           22.50s\n",
      "        70          59.3928           20.82s\n",
      "        80          44.6138           19.19s\n",
      "        90          34.1545           17.56s\n",
      "       100          26.7782           15.92s\n",
      "       200           5.0818            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         903.4400           30.37s\n",
      "         2         847.1364           30.58s\n",
      "         3         795.7793           31.37s\n",
      "         4         749.0947           31.07s\n",
      "         5         706.0867           30.82s\n",
      "         6         667.5338           31.11s\n",
      "         7         631.1121           30.84s\n",
      "         8         598.3615           30.97s\n",
      "         9         565.6874           30.79s\n",
      "        10         535.4384           30.83s\n",
      "        20         327.2712           29.09s\n",
      "        30         212.2812           27.84s\n",
      "        40         143.1952           26.04s\n",
      "        50         101.6853           24.27s\n",
      "        60          74.0261           22.58s\n",
      "        70          54.7521           20.85s\n",
      "        80          41.6348           19.19s\n",
      "        90          31.8634           17.56s\n",
      "       100          24.7936           15.92s\n",
      "       200           4.5590            0.00s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  36 out of  36 | elapsed:  9.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1        1258.4575            9.19s\n",
      "         2        1106.8200            9.00s\n",
      "         3         984.9409            8.81s\n",
      "         4         885.6764            8.62s\n",
      "         5         798.6325            8.44s\n",
      "         6         724.7979            8.20s\n",
      "         7         666.5253            8.02s\n",
      "         8         610.7853            7.90s\n",
      "         9         562.4058            7.63s\n",
      "        10         518.3656            7.52s\n",
      "        20         273.3905            5.59s\n",
      "        30         166.9851            3.70s\n",
      "        40         108.6725            1.84s\n",
      "        50          71.5063            0.00s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=None, error_score='raise',\n",
       "          estimator=GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=6,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=320,\n",
       "              presort='auto', random_state=None, subsample=1.0, verbose=1,\n",
       "              warm_start=False),\n",
       "          fit_params=None, iid=True, n_iter=12, n_jobs=1,\n",
       "          param_distributions={'learning_rate': [0.1, 0.05, 0.15, 0.25], 'n_estimators': [50, 100, 200, 400], 'max_depth': [3, 4, 5, 6, 7, 8]},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score=True, scoring=None, verbose=1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbParams = { #'verbose' : [1],\n",
    "             'learning_rate':[0.1,0.05,0.15,0.25],  \n",
    "             'n_estimators' :[50, 100, 200, 400], \n",
    "             'max_depth'    :[3,4,5,6,7,8]}\n",
    "gbRSCV = RandomizedSearchCV(gbc, gbParams, verbose=1, return_train_score=True, n_iter=12) #, n_jobs=-1)\n",
    "gbRSCV.fit(vectTexts_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.186692</td>\n",
       "      <td>0.011586</td>\n",
       "      <td>0.013457</td>\n",
       "      <td>0.006113</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>0.15</td>\n",
       "      <td>{'n_estimators': 50, 'max_depth': 5, 'learning_rate': 0.15}</td>\n",
       "      <td>0.768932</td>\n",
       "      <td>0.776699</td>\n",
       "      <td>0.769531</td>\n",
       "      <td>0.771725</td>\n",
       "      <td>0.003531</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998053</td>\n",
       "      <td>0.998058</td>\n",
       "      <td>0.998704</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.968433</td>\n",
       "      <td>0.064983</td>\n",
       "      <td>0.012676</td>\n",
       "      <td>0.007301</td>\n",
       "      <td>100</td>\n",
       "      <td>6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'n_estimators': 100, 'max_depth': 6, 'learning_rate': 0.1}</td>\n",
       "      <td>0.766990</td>\n",
       "      <td>0.761165</td>\n",
       "      <td>0.742188</td>\n",
       "      <td>0.756809</td>\n",
       "      <td>0.010580</td>\n",
       "      <td>12</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998053</td>\n",
       "      <td>0.998058</td>\n",
       "      <td>0.998704</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.281129</td>\n",
       "      <td>0.095497</td>\n",
       "      <td>0.008713</td>\n",
       "      <td>0.001767</td>\n",
       "      <td>200</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'n_estimators': 200, 'max_depth': 3, 'learning_rate': 0.1}</td>\n",
       "      <td>0.770874</td>\n",
       "      <td>0.788350</td>\n",
       "      <td>0.744141</td>\n",
       "      <td>0.767834</td>\n",
       "      <td>0.018167</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998053</td>\n",
       "      <td>0.998058</td>\n",
       "      <td>0.998704</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52.719727</td>\n",
       "      <td>8.268400</td>\n",
       "      <td>0.023386</td>\n",
       "      <td>0.005521</td>\n",
       "      <td>400</td>\n",
       "      <td>8</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'n_estimators': 400, 'max_depth': 8, 'learning_rate': 0.05}</td>\n",
       "      <td>0.745631</td>\n",
       "      <td>0.778641</td>\n",
       "      <td>0.761719</td>\n",
       "      <td>0.761997</td>\n",
       "      <td>0.013491</td>\n",
       "      <td>10</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998053</td>\n",
       "      <td>0.998058</td>\n",
       "      <td>0.998704</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25.733291</td>\n",
       "      <td>0.172211</td>\n",
       "      <td>0.014068</td>\n",
       "      <td>0.001365</td>\n",
       "      <td>400</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'n_estimators': 400, 'max_depth': 3, 'learning_rate': 0.1}</td>\n",
       "      <td>0.768932</td>\n",
       "      <td>0.784466</td>\n",
       "      <td>0.742188</td>\n",
       "      <td>0.765240</td>\n",
       "      <td>0.017449</td>\n",
       "      <td>6</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998053</td>\n",
       "      <td>0.998058</td>\n",
       "      <td>0.998704</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.679662</td>\n",
       "      <td>0.032846</td>\n",
       "      <td>0.004349</td>\n",
       "      <td>0.000496</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>0.25</td>\n",
       "      <td>{'n_estimators': 50, 'max_depth': 4, 'learning_rate': 0.25}</td>\n",
       "      <td>0.770874</td>\n",
       "      <td>0.792233</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.771077</td>\n",
       "      <td>0.017234</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998053</td>\n",
       "      <td>0.998058</td>\n",
       "      <td>0.998704</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.349383</td>\n",
       "      <td>0.037126</td>\n",
       "      <td>0.004185</td>\n",
       "      <td>0.001052</td>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>0.15</td>\n",
       "      <td>{'n_estimators': 50, 'max_depth': 3, 'learning_rate': 0.15}</td>\n",
       "      <td>0.765049</td>\n",
       "      <td>0.786408</td>\n",
       "      <td>0.742188</td>\n",
       "      <td>0.764591</td>\n",
       "      <td>0.018047</td>\n",
       "      <td>9</td>\n",
       "      <td>0.982473</td>\n",
       "      <td>0.983447</td>\n",
       "      <td>0.987379</td>\n",
       "      <td>0.984433</td>\n",
       "      <td>0.002121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>18.063109</td>\n",
       "      <td>0.229219</td>\n",
       "      <td>0.011752</td>\n",
       "      <td>0.003073</td>\n",
       "      <td>200</td>\n",
       "      <td>4</td>\n",
       "      <td>0.15</td>\n",
       "      <td>{'n_estimators': 200, 'max_depth': 4, 'learning_rate': 0.15}</td>\n",
       "      <td>0.766990</td>\n",
       "      <td>0.784466</td>\n",
       "      <td>0.748047</td>\n",
       "      <td>0.766537</td>\n",
       "      <td>0.014864</td>\n",
       "      <td>5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998053</td>\n",
       "      <td>0.998058</td>\n",
       "      <td>0.998704</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11.465650</td>\n",
       "      <td>0.160040</td>\n",
       "      <td>0.010648</td>\n",
       "      <td>0.006001</td>\n",
       "      <td>50</td>\n",
       "      <td>8</td>\n",
       "      <td>0.15</td>\n",
       "      <td>{'n_estimators': 50, 'max_depth': 8, 'learning_rate': 0.15}</td>\n",
       "      <td>0.753398</td>\n",
       "      <td>0.780583</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.761349</td>\n",
       "      <td>0.013690</td>\n",
       "      <td>11</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998053</td>\n",
       "      <td>0.998058</td>\n",
       "      <td>0.998704</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.636918</td>\n",
       "      <td>0.022885</td>\n",
       "      <td>0.006923</td>\n",
       "      <td>0.006694</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'n_estimators': 50, 'max_depth': 4, 'learning_rate': 0.1}</td>\n",
       "      <td>0.757282</td>\n",
       "      <td>0.778641</td>\n",
       "      <td>0.759766</td>\n",
       "      <td>0.765240</td>\n",
       "      <td>0.009544</td>\n",
       "      <td>6</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.994158</td>\n",
       "      <td>0.997087</td>\n",
       "      <td>0.997082</td>\n",
       "      <td>0.002385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9.725446</td>\n",
       "      <td>0.064512</td>\n",
       "      <td>0.009235</td>\n",
       "      <td>0.003469</td>\n",
       "      <td>50</td>\n",
       "      <td>7</td>\n",
       "      <td>0.15</td>\n",
       "      <td>{'n_estimators': 50, 'max_depth': 7, 'learning_rate': 0.15}</td>\n",
       "      <td>0.765049</td>\n",
       "      <td>0.776699</td>\n",
       "      <td>0.753906</td>\n",
       "      <td>0.765240</td>\n",
       "      <td>0.009302</td>\n",
       "      <td>6</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998053</td>\n",
       "      <td>0.998058</td>\n",
       "      <td>0.998704</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>31.274880</td>\n",
       "      <td>0.196186</td>\n",
       "      <td>0.007174</td>\n",
       "      <td>0.001595</td>\n",
       "      <td>200</td>\n",
       "      <td>6</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'n_estimators': 200, 'max_depth': 6, 'learning_rate': 0.05}</td>\n",
       "      <td>0.759223</td>\n",
       "      <td>0.790291</td>\n",
       "      <td>0.751953</td>\n",
       "      <td>0.767185</td>\n",
       "      <td>0.016629</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998053</td>\n",
       "      <td>0.998058</td>\n",
       "      <td>0.998704</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        6.186692      0.011586         0.013457        0.006113   \n",
       "1       15.968433      0.064983         0.012676        0.007301   \n",
       "2       13.281129      0.095497         0.008713        0.001767   \n",
       "3       52.719727      8.268400         0.023386        0.005521   \n",
       "4       25.733291      0.172211         0.014068        0.001365   \n",
       "5        4.679662      0.032846         0.004349        0.000496   \n",
       "6        3.349383      0.037126         0.004185        0.001052   \n",
       "7       18.063109      0.229219         0.011752        0.003073   \n",
       "8       11.465650      0.160040         0.010648        0.006001   \n",
       "9        4.636918      0.022885         0.006923        0.006694   \n",
       "10       9.725446      0.064512         0.009235        0.003469   \n",
       "11      31.274880      0.196186         0.007174        0.001595   \n",
       "\n",
       "   param_n_estimators param_max_depth param_learning_rate  \\\n",
       "0                  50               5                0.15   \n",
       "1                 100               6                 0.1   \n",
       "2                 200               3                 0.1   \n",
       "3                 400               8                0.05   \n",
       "4                 400               3                 0.1   \n",
       "5                  50               4                0.25   \n",
       "6                  50               3                0.15   \n",
       "7                 200               4                0.15   \n",
       "8                  50               8                0.15   \n",
       "9                  50               4                 0.1   \n",
       "10                 50               7                0.15   \n",
       "11                200               6                0.05   \n",
       "\n",
       "                                                          params  \\\n",
       "0    {'n_estimators': 50, 'max_depth': 5, 'learning_rate': 0.15}   \n",
       "1    {'n_estimators': 100, 'max_depth': 6, 'learning_rate': 0.1}   \n",
       "2    {'n_estimators': 200, 'max_depth': 3, 'learning_rate': 0.1}   \n",
       "3   {'n_estimators': 400, 'max_depth': 8, 'learning_rate': 0.05}   \n",
       "4    {'n_estimators': 400, 'max_depth': 3, 'learning_rate': 0.1}   \n",
       "5    {'n_estimators': 50, 'max_depth': 4, 'learning_rate': 0.25}   \n",
       "6    {'n_estimators': 50, 'max_depth': 3, 'learning_rate': 0.15}   \n",
       "7   {'n_estimators': 200, 'max_depth': 4, 'learning_rate': 0.15}   \n",
       "8    {'n_estimators': 50, 'max_depth': 8, 'learning_rate': 0.15}   \n",
       "9     {'n_estimators': 50, 'max_depth': 4, 'learning_rate': 0.1}   \n",
       "10   {'n_estimators': 50, 'max_depth': 7, 'learning_rate': 0.15}   \n",
       "11  {'n_estimators': 200, 'max_depth': 6, 'learning_rate': 0.05}   \n",
       "\n",
       "    split0_test_score  split1_test_score  split2_test_score  mean_test_score  \\\n",
       "0            0.768932           0.776699           0.769531         0.771725   \n",
       "1            0.766990           0.761165           0.742188         0.756809   \n",
       "2            0.770874           0.788350           0.744141         0.767834   \n",
       "3            0.745631           0.778641           0.761719         0.761997   \n",
       "4            0.768932           0.784466           0.742188         0.765240   \n",
       "5            0.770874           0.792233           0.750000         0.771077   \n",
       "6            0.765049           0.786408           0.742188         0.764591   \n",
       "7            0.766990           0.784466           0.748047         0.766537   \n",
       "8            0.753398           0.780583           0.750000         0.761349   \n",
       "9            0.757282           0.778641           0.759766         0.765240   \n",
       "10           0.765049           0.776699           0.753906         0.765240   \n",
       "11           0.759223           0.790291           0.751953         0.767185   \n",
       "\n",
       "    std_test_score  rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0         0.003531                1            1.000000            0.998053   \n",
       "1         0.010580               12            1.000000            0.998053   \n",
       "2         0.018167                3            1.000000            0.998053   \n",
       "3         0.013491               10            1.000000            0.998053   \n",
       "4         0.017449                6            1.000000            0.998053   \n",
       "5         0.017234                2            1.000000            0.998053   \n",
       "6         0.018047                9            0.982473            0.983447   \n",
       "7         0.014864                5            1.000000            0.998053   \n",
       "8         0.013690               11            1.000000            0.998053   \n",
       "9         0.009544                6            1.000000            0.994158   \n",
       "10        0.009302                6            1.000000            0.998053   \n",
       "11        0.016629                4            1.000000            0.998053   \n",
       "\n",
       "    split2_train_score  mean_train_score  std_train_score  \n",
       "0             0.998058          0.998704         0.000917  \n",
       "1             0.998058          0.998704         0.000917  \n",
       "2             0.998058          0.998704         0.000917  \n",
       "3             0.998058          0.998704         0.000917  \n",
       "4             0.998058          0.998704         0.000917  \n",
       "5             0.998058          0.998704         0.000917  \n",
       "6             0.987379          0.984433         0.002121  \n",
       "7             0.998058          0.998704         0.000917  \n",
       "8             0.998058          0.998704         0.000917  \n",
       "9             0.997087          0.997082         0.002385  \n",
       "10            0.998058          0.998704         0.000917  \n",
       "11            0.998058          0.998704         0.000917  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(gbRSCV.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7267441860465116"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbRSCV.best_estimator_.score(vectTexts_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=2, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=1e-05, verbose=1)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "sksvc = SVC(verbose=1, gamma=0.1, tol=1e-5, C=2, kernel='rbf')\n",
    "sksvc.fit(vectTexts_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.9870298313878081 Test score: 0.75\n"
     ]
    }
   ],
   "source": [
    "print('Train score: {} Test score: {}'.format(sksvc.score(vectTexts_train, y_train),sksvc.score(vectTexts_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n",
      "[LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 360 out of 360 | elapsed:  4.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=None, error_score='raise',\n",
       "          estimator=SVC(C=2, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=1e-05, verbose=1),\n",
       "          fit_params=None, iid=True, n_iter=120, n_jobs=1,\n",
       "          param_distributions={'gamma': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000018922952080>, 'C': <scipy.stats._distn_infrastructure.rv_frozen object at 0x00000189229525C0>, 'shrinking': [True, False]},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score=True, scoring=None, verbose=1)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.stats\n",
    "\n",
    "svmParams = { #'verbose' : [1],\n",
    "             'gamma': scipy.stats.uniform(0.005,0.15),#[0.1,0.01,0.02,0.04,0.08],  \n",
    "             'C' : scipy.stats.uniform(0.01,50),#[0.1,10,15, 20,25,40], \n",
    "             'shrinking'    :[True, False]}\n",
    "svmRSCV = RandomizedSearchCV(sksvc, svmParams, verbose=1, return_train_score=True, n_iter=120) #, n_jobs=-1)\n",
    "svmRSCV.fit(vectTexts_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_shrinking</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.490553</td>\n",
       "      <td>0.008267</td>\n",
       "      <td>0.130203</td>\n",
       "      <td>7.365527e-03</td>\n",
       "      <td>19.2625</td>\n",
       "      <td>0.154259</td>\n",
       "      <td>True</td>\n",
       "      <td>{'C': 19.26248752837037, 'gamma': 0.15425898456052756, 'shrinking': True}</td>\n",
       "      <td>0.739806</td>\n",
       "      <td>0.743689</td>\n",
       "      <td>0.730469</td>\n",
       "      <td>0.738003</td>\n",
       "      <td>0.005544</td>\n",
       "      <td>114</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998053</td>\n",
       "      <td>0.998058</td>\n",
       "      <td>0.998704</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.357690</td>\n",
       "      <td>0.013125</td>\n",
       "      <td>0.098955</td>\n",
       "      <td>7.365527e-03</td>\n",
       "      <td>47.4678</td>\n",
       "      <td>0.0407651</td>\n",
       "      <td>True</td>\n",
       "      <td>{'C': 47.467764705122015, 'gamma': 0.04076509881741229, 'shrinking': True}</td>\n",
       "      <td>0.778641</td>\n",
       "      <td>0.803883</td>\n",
       "      <td>0.767578</td>\n",
       "      <td>0.783398</td>\n",
       "      <td>0.015193</td>\n",
       "      <td>22</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998053</td>\n",
       "      <td>0.998058</td>\n",
       "      <td>0.998704</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.358646</td>\n",
       "      <td>0.004679</td>\n",
       "      <td>0.114579</td>\n",
       "      <td>7.365639e-03</td>\n",
       "      <td>45.1782</td>\n",
       "      <td>0.0746224</td>\n",
       "      <td>False</td>\n",
       "      <td>{'C': 45.17822268576651, 'gamma': 0.07462240280077816, 'shrinking': False}</td>\n",
       "      <td>0.765049</td>\n",
       "      <td>0.796117</td>\n",
       "      <td>0.765625</td>\n",
       "      <td>0.775616</td>\n",
       "      <td>0.014519</td>\n",
       "      <td>49</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998053</td>\n",
       "      <td>0.998058</td>\n",
       "      <td>0.998704</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.400697</td>\n",
       "      <td>0.005669</td>\n",
       "      <td>0.114579</td>\n",
       "      <td>7.365358e-03</td>\n",
       "      <td>35.2666</td>\n",
       "      <td>0.101341</td>\n",
       "      <td>False</td>\n",
       "      <td>{'C': 35.266567421761586, 'gamma': 0.10134095762731304, 'shrinking': False}</td>\n",
       "      <td>0.753398</td>\n",
       "      <td>0.768932</td>\n",
       "      <td>0.738281</td>\n",
       "      <td>0.753567</td>\n",
       "      <td>0.012508</td>\n",
       "      <td>79</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998053</td>\n",
       "      <td>0.998058</td>\n",
       "      <td>0.998704</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.271918</td>\n",
       "      <td>0.004669</td>\n",
       "      <td>0.097434</td>\n",
       "      <td>5.215195e-03</td>\n",
       "      <td>27.4638</td>\n",
       "      <td>0.026813</td>\n",
       "      <td>False</td>\n",
       "      <td>{'C': 27.463828618924303, 'gamma': 0.026813031995736276, 'shrinking': False}</td>\n",
       "      <td>0.790291</td>\n",
       "      <td>0.801942</td>\n",
       "      <td>0.763672</td>\n",
       "      <td>0.785344</td>\n",
       "      <td>0.016004</td>\n",
       "      <td>7</td>\n",
       "      <td>0.999026</td>\n",
       "      <td>0.993184</td>\n",
       "      <td>0.997087</td>\n",
       "      <td>0.996433</td>\n",
       "      <td>0.002430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.262663</td>\n",
       "      <td>0.006621</td>\n",
       "      <td>0.088538</td>\n",
       "      <td>7.365583e-03</td>\n",
       "      <td>49.3714</td>\n",
       "      <td>0.0220207</td>\n",
       "      <td>True</td>\n",
       "      <td>{'C': 49.371396677766676, 'gamma': 0.022020693132256117, 'shrinking': True}</td>\n",
       "      <td>0.766990</td>\n",
       "      <td>0.788350</td>\n",
       "      <td>0.759766</td>\n",
       "      <td>0.771725</td>\n",
       "      <td>0.012136</td>\n",
       "      <td>58</td>\n",
       "      <td>0.999026</td>\n",
       "      <td>0.995131</td>\n",
       "      <td>0.998058</td>\n",
       "      <td>0.997405</td>\n",
       "      <td>0.001656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.447708</td>\n",
       "      <td>0.005450</td>\n",
       "      <td>0.109370</td>\n",
       "      <td>7.018853e-07</td>\n",
       "      <td>29.2905</td>\n",
       "      <td>0.0689445</td>\n",
       "      <td>True</td>\n",
       "      <td>{'C': 29.290475010392882, 'gamma': 0.06894445193558148, 'shrinking': True}</td>\n",
       "      <td>0.776699</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.769531</td>\n",
       "      <td>0.782101</td>\n",
       "      <td>0.013008</td>\n",
       "      <td>33</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998053</td>\n",
       "      <td>0.998058</td>\n",
       "      <td>0.998704</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.477364</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.119788</td>\n",
       "      <td>7.365808e-03</td>\n",
       "      <td>28.9505</td>\n",
       "      <td>0.102491</td>\n",
       "      <td>True</td>\n",
       "      <td>{'C': 28.950492540808934, 'gamma': 0.1024906153826446, 'shrinking': True}</td>\n",
       "      <td>0.755340</td>\n",
       "      <td>0.765049</td>\n",
       "      <td>0.738281</td>\n",
       "      <td>0.752918</td>\n",
       "      <td>0.011056</td>\n",
       "      <td>81</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998053</td>\n",
       "      <td>0.998058</td>\n",
       "      <td>0.998704</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.342583</td>\n",
       "      <td>0.005131</td>\n",
       "      <td>0.109371</td>\n",
       "      <td>2.973602e-07</td>\n",
       "      <td>41.9842</td>\n",
       "      <td>0.0639297</td>\n",
       "      <td>False</td>\n",
       "      <td>{'C': 41.984178947732715, 'gamma': 0.06392974884132539, 'shrinking': False}</td>\n",
       "      <td>0.774757</td>\n",
       "      <td>0.807767</td>\n",
       "      <td>0.767578</td>\n",
       "      <td>0.783398</td>\n",
       "      <td>0.017503</td>\n",
       "      <td>22</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998053</td>\n",
       "      <td>0.998058</td>\n",
       "      <td>0.998704</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.355870</td>\n",
       "      <td>0.008014</td>\n",
       "      <td>0.093746</td>\n",
       "      <td>3.371748e-07</td>\n",
       "      <td>14.8467</td>\n",
       "      <td>0.0350516</td>\n",
       "      <td>True</td>\n",
       "      <td>{'C': 14.846698448499513, 'gamma': 0.03505164225045203, 'shrinking': True}</td>\n",
       "      <td>0.786408</td>\n",
       "      <td>0.801942</td>\n",
       "      <td>0.763672</td>\n",
       "      <td>0.784047</td>\n",
       "      <td>0.015705</td>\n",
       "      <td>15</td>\n",
       "      <td>0.997079</td>\n",
       "      <td>0.991237</td>\n",
       "      <td>0.996117</td>\n",
       "      <td>0.994811</td>\n",
       "      <td>0.002558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.443700</td>\n",
       "      <td>0.005953</td>\n",
       "      <td>0.109371</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.15025</td>\n",
       "      <td>0.0689186</td>\n",
       "      <td>True</td>\n",
       "      <td>{'C': 4.150247492305144, 'gamma': 0.06891857854507473, 'shrinking': True}</td>\n",
       "      <td>0.770874</td>\n",
       "      <td>0.786408</td>\n",
       "      <td>0.771484</td>\n",
       "      <td>0.776265</td>\n",
       "      <td>0.007187</td>\n",
       "      <td>48</td>\n",
       "      <td>0.996105</td>\n",
       "      <td>0.988315</td>\n",
       "      <td>0.994175</td>\n",
       "      <td>0.992865</td>\n",
       "      <td>0.003312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.358232</td>\n",
       "      <td>0.011389</td>\n",
       "      <td>0.109371</td>\n",
       "      <td>4.052337e-07</td>\n",
       "      <td>33.0955</td>\n",
       "      <td>0.0712146</td>\n",
       "      <td>False</td>\n",
       "      <td>{'C': 33.09550591871901, 'gamma': 0.07121457954208432, 'shrinking': False}</td>\n",
       "      <td>0.768932</td>\n",
       "      <td>0.798058</td>\n",
       "      <td>0.769531</td>\n",
       "      <td>0.778859</td>\n",
       "      <td>0.013598</td>\n",
       "      <td>46</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998053</td>\n",
       "      <td>0.998058</td>\n",
       "      <td>0.998704</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.394910</td>\n",
       "      <td>0.004605</td>\n",
       "      <td>0.119786</td>\n",
       "      <td>7.366539e-03</td>\n",
       "      <td>0.382329</td>\n",
       "      <td>0.121264</td>\n",
       "      <td>False</td>\n",
       "      <td>{'C': 0.38232933612978415, 'gamma': 0.12126362122164655, 'shrinking': False}</td>\n",
       "      <td>0.693204</td>\n",
       "      <td>0.681553</td>\n",
       "      <td>0.705078</td>\n",
       "      <td>0.693256</td>\n",
       "      <td>0.009599</td>\n",
       "      <td>119</td>\n",
       "      <td>0.720545</td>\n",
       "      <td>0.703992</td>\n",
       "      <td>0.719417</td>\n",
       "      <td>0.714652</td>\n",
       "      <td>0.007551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.483953</td>\n",
       "      <td>0.005181</td>\n",
       "      <td>0.124995</td>\n",
       "      <td>4.052337e-07</td>\n",
       "      <td>4.65606</td>\n",
       "      <td>0.144236</td>\n",
       "      <td>True</td>\n",
       "      <td>{'C': 4.656057923385682, 'gamma': 0.14423578395322106, 'shrinking': True}</td>\n",
       "      <td>0.741748</td>\n",
       "      <td>0.743689</td>\n",
       "      <td>0.736328</td>\n",
       "      <td>0.740597</td>\n",
       "      <td>0.003112</td>\n",
       "      <td>111</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998053</td>\n",
       "      <td>0.998058</td>\n",
       "      <td>0.998704</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.479941</td>\n",
       "      <td>0.008295</td>\n",
       "      <td>0.109371</td>\n",
       "      <td>8.485379e-07</td>\n",
       "      <td>8.69826</td>\n",
       "      <td>0.104208</td>\n",
       "      <td>True</td>\n",
       "      <td>{'C': 8.698260890203485, 'gamma': 0.10420839875892418, 'shrinking': True}</td>\n",
       "      <td>0.753398</td>\n",
       "      <td>0.761165</td>\n",
       "      <td>0.738281</td>\n",
       "      <td>0.750973</td>\n",
       "      <td>0.009494</td>\n",
       "      <td>86</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998053</td>\n",
       "      <td>0.998058</td>\n",
       "      <td>0.998704</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.435567</td>\n",
       "      <td>0.015291</td>\n",
       "      <td>0.128181</td>\n",
       "      <td>2.560313e-03</td>\n",
       "      <td>2.69753</td>\n",
       "      <td>0.148885</td>\n",
       "      <td>False</td>\n",
       "      <td>{'C': 2.697533207714371, 'gamma': 0.14888472962984606, 'shrinking': False}</td>\n",
       "      <td>0.735922</td>\n",
       "      <td>0.741748</td>\n",
       "      <td>0.730469</td>\n",
       "      <td>0.736057</td>\n",
       "      <td>0.004603</td>\n",
       "      <td>117</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.993184</td>\n",
       "      <td>0.994175</td>\n",
       "      <td>0.995786</td>\n",
       "      <td>0.003007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.483643</td>\n",
       "      <td>0.006964</td>\n",
       "      <td>0.119787</td>\n",
       "      <td>7.365583e-03</td>\n",
       "      <td>8.97329</td>\n",
       "      <td>0.116828</td>\n",
       "      <td>True</td>\n",
       "      <td>{'C': 8.973288997623152, 'gamma': 0.11682763944017847, 'shrinking': True}</td>\n",
       "      <td>0.745631</td>\n",
       "      <td>0.759223</td>\n",
       "      <td>0.726562</td>\n",
       "      <td>0.743839</td>\n",
       "      <td>0.013387</td>\n",
       "      <td>96</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998053</td>\n",
       "      <td>0.998058</td>\n",
       "      <td>0.998704</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.489988</td>\n",
       "      <td>0.001343</td>\n",
       "      <td>0.125821</td>\n",
       "      <td>1.168311e-03</td>\n",
       "      <td>4.71161</td>\n",
       "      <td>0.14614</td>\n",
       "      <td>True</td>\n",
       "      <td>{'C': 4.71161019549783, 'gamma': 0.14613998373041326, 'shrinking': True}</td>\n",
       "      <td>0.741748</td>\n",
       "      <td>0.743689</td>\n",
       "      <td>0.736328</td>\n",
       "      <td>0.740597</td>\n",
       "      <td>0.003112</td>\n",
       "      <td>111</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998053</td>\n",
       "      <td>0.998058</td>\n",
       "      <td>0.998704</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.465456</td>\n",
       "      <td>0.004471</td>\n",
       "      <td>0.114579</td>\n",
       "      <td>7.365246e-03</td>\n",
       "      <td>18.6899</td>\n",
       "      <td>0.0875379</td>\n",
       "      <td>True</td>\n",
       "      <td>{'C': 18.689872019819923, 'gamma': 0.0875379249268066, 'shrinking': True}</td>\n",
       "      <td>0.765049</td>\n",
       "      <td>0.782524</td>\n",
       "      <td>0.746094</td>\n",
       "      <td>0.764591</td>\n",
       "      <td>0.014869</td>\n",
       "      <td>63</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998053</td>\n",
       "      <td>0.998058</td>\n",
       "      <td>0.998704</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.345717</td>\n",
       "      <td>0.004889</td>\n",
       "      <td>0.088538</td>\n",
       "      <td>7.365134e-03</td>\n",
       "      <td>38.1606</td>\n",
       "      <td>0.0324731</td>\n",
       "      <td>True</td>\n",
       "      <td>{'C': 38.1605766718631, 'gamma': 0.03247311384933184, 'shrinking': True}</td>\n",
       "      <td>0.778641</td>\n",
       "      <td>0.803883</td>\n",
       "      <td>0.765625</td>\n",
       "      <td>0.782750</td>\n",
       "      <td>0.015880</td>\n",
       "      <td>28</td>\n",
       "      <td>0.999026</td>\n",
       "      <td>0.997079</td>\n",
       "      <td>0.998058</td>\n",
       "      <td>0.998054</td>\n",
       "      <td>0.000795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.466490</td>\n",
       "      <td>0.006284</td>\n",
       "      <td>0.114580</td>\n",
       "      <td>7.364459e-03</td>\n",
       "      <td>42.7214</td>\n",
       "      <td>0.090361</td>\n",
       "      <td>True</td>\n",
       "      <td>{'C': 42.7214141275145, 'gamma': 0.09036100380457267, 'shrinking': True}</td>\n",
       "      <td>0.763107</td>\n",
       "      <td>0.780583</td>\n",
       "      <td>0.748047</td>\n",
       "      <td>0.763943</td>\n",
       "      <td>0.013289</td>\n",
       "      <td>65</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998053</td>\n",
       "      <td>0.998058</td>\n",
       "      <td>0.998704</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.387061</td>\n",
       "      <td>0.008028</td>\n",
       "      <td>0.119787</td>\n",
       "      <td>7.365696e-03</td>\n",
       "      <td>11.0006</td>\n",
       "      <td>0.0925419</td>\n",
       "      <td>False</td>\n",
       "      <td>{'C': 11.00063583368149, 'gamma': 0.09254190604268656, 'shrinking': False}</td>\n",
       "      <td>0.759223</td>\n",
       "      <td>0.772816</td>\n",
       "      <td>0.742188</td>\n",
       "      <td>0.758106</td>\n",
       "      <td>0.012523</td>\n",
       "      <td>74</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998053</td>\n",
       "      <td>0.998058</td>\n",
       "      <td>0.998704</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.261218</td>\n",
       "      <td>0.007007</td>\n",
       "      <td>0.093746</td>\n",
       "      <td>1.123916e-07</td>\n",
       "      <td>2.29245</td>\n",
       "      <td>0.022649</td>\n",
       "      <td>False</td>\n",
       "      <td>{'C': 2.292452511635402, 'gamma': 0.022648975967004322, 'shrinking': False}</td>\n",
       "      <td>0.786408</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.775391</td>\n",
       "      <td>0.787289</td>\n",
       "      <td>0.010061</td>\n",
       "      <td>3</td>\n",
       "      <td>0.909445</td>\n",
       "      <td>0.900682</td>\n",
       "      <td>0.905825</td>\n",
       "      <td>0.905317</td>\n",
       "      <td>0.003596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.444733</td>\n",
       "      <td>0.007487</td>\n",
       "      <td>0.109371</td>\n",
       "      <td>2.247832e-07</td>\n",
       "      <td>13.3742</td>\n",
       "      <td>0.0662412</td>\n",
       "      <td>True</td>\n",
       "      <td>{'C': 13.374157403935339, 'gamma': 0.06624124171058018, 'shrinking': True}</td>\n",
       "      <td>0.770874</td>\n",
       "      <td>0.801942</td>\n",
       "      <td>0.771484</td>\n",
       "      <td>0.781453</td>\n",
       "      <td>0.014511</td>\n",
       "      <td>37</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997079</td>\n",
       "      <td>0.998058</td>\n",
       "      <td>0.998379</td>\n",
       "      <td>0.001214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.460929</td>\n",
       "      <td>0.005729</td>\n",
       "      <td>0.119787</td>\n",
       "      <td>7.365527e-03</td>\n",
       "      <td>17.9887</td>\n",
       "      <td>0.0884335</td>\n",
       "      <td>True</td>\n",
       "      <td>{'C': 17.988650756701695, 'gamma': 0.08843347002863645, 'shrinking': True}</td>\n",
       "      <td>0.765049</td>\n",
       "      <td>0.782524</td>\n",
       "      <td>0.746094</td>\n",
       "      <td>0.764591</td>\n",
       "      <td>0.014869</td>\n",
       "      <td>63</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998053</td>\n",
       "      <td>0.998058</td>\n",
       "      <td>0.998704</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.397009</td>\n",
       "      <td>0.005008</td>\n",
       "      <td>0.118287</td>\n",
       "      <td>6.567020e-03</td>\n",
       "      <td>27.0323</td>\n",
       "      <td>0.100304</td>\n",
       "      <td>False</td>\n",
       "      <td>{'C': 27.032310831604626, 'gamma': 0.10030404157242598, 'shrinking': False}</td>\n",
       "      <td>0.753398</td>\n",
       "      <td>0.768932</td>\n",
       "      <td>0.740234</td>\n",
       "      <td>0.754215</td>\n",
       "      <td>0.011724</td>\n",
       "      <td>78</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998053</td>\n",
       "      <td>0.998058</td>\n",
       "      <td>0.998704</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.294354</td>\n",
       "      <td>0.000987</td>\n",
       "      <td>0.093740</td>\n",
       "      <td>8.768706e-06</td>\n",
       "      <td>0.065385</td>\n",
       "      <td>0.0319357</td>\n",
       "      <td>True</td>\n",
       "      <td>{'C': 0.06538502485824547, 'gamma': 0.031935688793944164, 'shrinking': True}</td>\n",
       "      <td>0.681553</td>\n",
       "      <td>0.681553</td>\n",
       "      <td>0.683594</td>\n",
       "      <td>0.682231</td>\n",
       "      <td>0.000961</td>\n",
       "      <td>120</td>\n",
       "      <td>0.682571</td>\n",
       "      <td>0.682571</td>\n",
       "      <td>0.681553</td>\n",
       "      <td>0.682232</td>\n",
       "      <td>0.000480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.367684</td>\n",
       "      <td>0.011996</td>\n",
       "      <td>0.093746</td>\n",
       "      <td>1.946680e-07</td>\n",
       "      <td>20.1643</td>\n",
       "      <td>0.0371033</td>\n",
       "      <td>True</td>\n",
       "      <td>{'C': 20.164310563216905, 'gamma': 0.037103263294673824, 'shrinking': True}</td>\n",
       "      <td>0.794175</td>\n",
       "      <td>0.798058</td>\n",
       "      <td>0.769531</td>\n",
       "      <td>0.787289</td>\n",
       "      <td>0.012620</td>\n",
       "      <td>3</td>\n",
       "      <td>0.999026</td>\n",
       "      <td>0.995131</td>\n",
       "      <td>0.998058</td>\n",
       "      <td>0.997405</td>\n",
       "      <td>0.001656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.411121</td>\n",
       "      <td>0.003426</td>\n",
       "      <td>0.124995</td>\n",
       "      <td>2.247832e-07</td>\n",
       "      <td>26.914</td>\n",
       "      <td>0.117371</td>\n",
       "      <td>False</td>\n",
       "      <td>{'C': 26.91396934414255, 'gamma': 0.11737137340071307, 'shrinking': False}</td>\n",
       "      <td>0.745631</td>\n",
       "      <td>0.759223</td>\n",
       "      <td>0.728516</td>\n",
       "      <td>0.744488</td>\n",
       "      <td>0.012556</td>\n",
       "      <td>89</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998053</td>\n",
       "      <td>0.998058</td>\n",
       "      <td>0.998704</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.474933</td>\n",
       "      <td>0.006635</td>\n",
       "      <td>0.109371</td>\n",
       "      <td>1.123916e-07</td>\n",
       "      <td>5.63032</td>\n",
       "      <td>0.10113</td>\n",
       "      <td>True</td>\n",
       "      <td>{'C': 5.630324577077462, 'gamma': 0.10113024673770687, 'shrinking': True}</td>\n",
       "      <td>0.753398</td>\n",
       "      <td>0.765049</td>\n",
       "      <td>0.740234</td>\n",
       "      <td>0.752918</td>\n",
       "      <td>0.010131</td>\n",
       "      <td>81</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995131</td>\n",
       "      <td>0.997087</td>\n",
       "      <td>0.997406</td>\n",
       "      <td>0.002000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.346257</td>\n",
       "      <td>0.010683</td>\n",
       "      <td>0.109371</td>\n",
       "      <td>1.123916e-07</td>\n",
       "      <td>7.40204</td>\n",
       "      <td>0.066673</td>\n",
       "      <td>False</td>\n",
       "      <td>{'C': 7.402038266848, 'gamma': 0.06667297102799205, 'shrinking': False}</td>\n",
       "      <td>0.765049</td>\n",
       "      <td>0.801942</td>\n",
       "      <td>0.775391</td>\n",
       "      <td>0.780804</td>\n",
       "      <td>0.015552</td>\n",
       "      <td>40</td>\n",
       "      <td>0.999026</td>\n",
       "      <td>0.992210</td>\n",
       "      <td>0.996117</td>\n",
       "      <td>0.995784</td>\n",
       "      <td>0.002793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.436360</td>\n",
       "      <td>0.011811</td>\n",
       "      <td>0.109371</td>\n",
       "      <td>1.123916e-07</td>\n",
       "      <td>41.2496</td>\n",
       "      <td>0.0604683</td>\n",
       "      <td>True</td>\n",
       "      <td>{'C': 41.24959812437073, 'gamma': 0.06046825586739161, 'shrinking': True}</td>\n",
       "      <td>0.766990</td>\n",
       "      <td>0.811650</td>\n",
       "      <td>0.769531</td>\n",
       "      <td>0.782750</td>\n",
       "      <td>0.020492</td>\n",
       "      <td>28</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998053</td>\n",
       "      <td>0.998058</td>\n",
       "      <td>0.998704</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.456094</td>\n",
       "      <td>0.008951</td>\n",
       "      <td>0.113751</td>\n",
       "      <td>8.015518e-03</td>\n",
       "      <td>26.513</td>\n",
       "      <td>0.0806078</td>\n",
       "      <td>True</td>\n",
       "      <td>{'C': 26.512992915036346, 'gamma': 0.08060777748997125, 'shrinking': True}</td>\n",
       "      <td>0.770874</td>\n",
       "      <td>0.794175</td>\n",
       "      <td>0.759766</td>\n",
       "      <td>0.774968</td>\n",
       "      <td>0.014337</td>\n",
       "      <td>50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998053</td>\n",
       "      <td>0.998058</td>\n",
       "      <td>0.998704</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.263259</td>\n",
       "      <td>0.006246</td>\n",
       "      <td>0.088535</td>\n",
       "      <td>7.364235e-03</td>\n",
       "      <td>26.1</td>\n",
       "      <td>0.0193134</td>\n",
       "      <td>True</td>\n",
       "      <td>{'C': 26.100014297576994, 'gamma': 0.01931339897662503, 'shrinking': True}</td>\n",
       "      <td>0.768932</td>\n",
       "      <td>0.784466</td>\n",
       "      <td>0.761719</td>\n",
       "      <td>0.771725</td>\n",
       "      <td>0.009490</td>\n",
       "      <td>58</td>\n",
       "      <td>0.996105</td>\n",
       "      <td>0.990263</td>\n",
       "      <td>0.996117</td>\n",
       "      <td>0.994162</td>\n",
       "      <td>0.002757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.261243</td>\n",
       "      <td>0.007217</td>\n",
       "      <td>0.083330</td>\n",
       "      <td>7.365246e-03</td>\n",
       "      <td>28.7436</td>\n",
       "      <td>0.0181597</td>\n",
       "      <td>False</td>\n",
       "      <td>{'C': 28.74359759695357, 'gamma': 0.018159694883001915, 'shrinking': False}</td>\n",
       "      <td>0.765049</td>\n",
       "      <td>0.782524</td>\n",
       "      <td>0.759766</td>\n",
       "      <td>0.769131</td>\n",
       "      <td>0.009726</td>\n",
       "      <td>60</td>\n",
       "      <td>0.996105</td>\n",
       "      <td>0.990263</td>\n",
       "      <td>0.996117</td>\n",
       "      <td>0.994162</td>\n",
       "      <td>0.002757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.249965</td>\n",
       "      <td>0.012048</td>\n",
       "      <td>0.083330</td>\n",
       "      <td>7.365471e-03</td>\n",
       "      <td>40.4004</td>\n",
       "      <td>0.0120501</td>\n",
       "      <td>True</td>\n",
       "      <td>{'C': 40.40035795318392, 'gamma': 0.012050115885966146, 'shrinking': True}</td>\n",
       "      <td>0.761165</td>\n",
       "      <td>0.774757</td>\n",
       "      <td>0.751953</td>\n",
       "      <td>0.762646</td>\n",
       "      <td>0.009364</td>\n",
       "      <td>67</td>\n",
       "      <td>0.992210</td>\n",
       "      <td>0.986368</td>\n",
       "      <td>0.994175</td>\n",
       "      <td>0.990918</td>\n",
       "      <td>0.003316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.312370</td>\n",
       "      <td>0.001097</td>\n",
       "      <td>0.098954</td>\n",
       "      <td>7.365077e-03</td>\n",
       "      <td>32.353</td>\n",
       "      <td>0.0462698</td>\n",
       "      <td>False</td>\n",
       "      <td>{'C': 32.35296561800621, 'gamma': 0.04626978131094986, 'shrinking': False}</td>\n",
       "      <td>0.774757</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.773438</td>\n",
       "      <td>0.782750</td>\n",
       "      <td>0.012227</td>\n",
       "      <td>28</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997079</td>\n",
       "      <td>0.998058</td>\n",
       "      <td>0.998379</td>\n",
       "      <td>0.001214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.236604</td>\n",
       "      <td>0.010438</td>\n",
       "      <td>0.083330</td>\n",
       "      <td>7.365358e-03</td>\n",
       "      <td>2.8418</td>\n",
       "      <td>0.0109268</td>\n",
       "      <td>False</td>\n",
       "      <td>{'C': 2.8418033563420604, 'gamma': 0.010926818745688016, 'shrinking': False}</td>\n",
       "      <td>0.786408</td>\n",
       "      <td>0.776699</td>\n",
       "      <td>0.757812</td>\n",
       "      <td>0.773671</td>\n",
       "      <td>0.011864</td>\n",
       "      <td>55</td>\n",
       "      <td>0.867575</td>\n",
       "      <td>0.856865</td>\n",
       "      <td>0.863107</td>\n",
       "      <td>0.862516</td>\n",
       "      <td>0.004393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.232956</td>\n",
       "      <td>0.012335</td>\n",
       "      <td>0.093748</td>\n",
       "      <td>2.657295e-06</td>\n",
       "      <td>5.18722</td>\n",
       "      <td>0.0120731</td>\n",
       "      <td>True</td>\n",
       "      <td>{'C': 5.187219861835652, 'gamma': 0.012073147217292596, 'shrinking': True}</td>\n",
       "      <td>0.784466</td>\n",
       "      <td>0.794175</td>\n",
       "      <td>0.773438</td>\n",
       "      <td>0.784047</td>\n",
       "      <td>0.008467</td>\n",
       "      <td>15</td>\n",
       "      <td>0.907498</td>\n",
       "      <td>0.902629</td>\n",
       "      <td>0.912621</td>\n",
       "      <td>0.907583</td>\n",
       "      <td>0.004080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.401434</td>\n",
       "      <td>0.008301</td>\n",
       "      <td>0.119790</td>\n",
       "      <td>7.367664e-03</td>\n",
       "      <td>31.2269</td>\n",
       "      <td>0.106368</td>\n",
       "      <td>False</td>\n",
       "      <td>{'C': 31.226913546371623, 'gamma': 0.10636773963939428, 'shrinking': False}</td>\n",
       "      <td>0.759223</td>\n",
       "      <td>0.763107</td>\n",
       "      <td>0.738281</td>\n",
       "      <td>0.753567</td>\n",
       "      <td>0.010893</td>\n",
       "      <td>79</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998053</td>\n",
       "      <td>0.998058</td>\n",
       "      <td>0.998704</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.395589</td>\n",
       "      <td>0.007939</td>\n",
       "      <td>0.109371</td>\n",
       "      <td>2.247832e-07</td>\n",
       "      <td>12.049</td>\n",
       "      <td>0.0983427</td>\n",
       "      <td>False</td>\n",
       "      <td>{'C': 12.048963026484323, 'gamma': 0.09834265606220108, 'shrinking': False}</td>\n",
       "      <td>0.753398</td>\n",
       "      <td>0.770874</td>\n",
       "      <td>0.740234</td>\n",
       "      <td>0.754864</td>\n",
       "      <td>0.012545</td>\n",
       "      <td>77</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998053</td>\n",
       "      <td>0.998058</td>\n",
       "      <td>0.998704</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>0.470859</td>\n",
       "      <td>0.004115</td>\n",
       "      <td>0.114580</td>\n",
       "      <td>7.364684e-03</td>\n",
       "      <td>24.6417</td>\n",
       "      <td>0.0931146</td>\n",
       "      <td>True</td>\n",
       "      <td>{'C': 24.64168022883977, 'gamma': 0.09311460483872955, 'shrinking': True}</td>\n",
       "      <td>0.761165</td>\n",
       "      <td>0.776699</td>\n",
       "      <td>0.742188</td>\n",
       "      <td>0.760052</td>\n",
       "      <td>0.014104</td>\n",
       "      <td>70</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998053</td>\n",
       "      <td>0.998058</td>\n",
       "      <td>0.998704</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0.236667</td>\n",
       "      <td>0.002109</td>\n",
       "      <td>0.088538</td>\n",
       "      <td>7.365358e-03</td>\n",
       "      <td>1.64123</td>\n",
       "      <td>0.0120562</td>\n",
       "      <td>True</td>\n",
       "      <td>{'C': 1.6412297618941374, 'gamma': 0.012056245564175989, 'shrinking': True}</td>\n",
       "      <td>0.770874</td>\n",
       "      <td>0.763107</td>\n",
       "      <td>0.755859</td>\n",
       "      <td>0.763294</td>\n",
       "      <td>0.006128</td>\n",
       "      <td>66</td>\n",
       "      <td>0.826680</td>\n",
       "      <td>0.828627</td>\n",
       "      <td>0.829126</td>\n",
       "      <td>0.828144</td>\n",
       "      <td>0.001056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>0.442383</td>\n",
       "      <td>0.005631</td>\n",
       "      <td>0.104163</td>\n",
       "      <td>7.365302e-03</td>\n",
       "      <td>13.3739</td>\n",
       "      <td>0.0636064</td>\n",
       "      <td>True</td>\n",
       "      <td>{'C': 13.373916691096655, 'gamma': 0.063606397540602, 'shrinking': True}</td>\n",
       "      <td>0.776699</td>\n",
       "      <td>0.803883</td>\n",
       "      <td>0.771484</td>\n",
       "      <td>0.784047</td>\n",
       "      <td>0.014207</td>\n",
       "      <td>15</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997079</td>\n",
       "      <td>0.998058</td>\n",
       "      <td>0.998379</td>\n",
       "      <td>0.001214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>0.313114</td>\n",
       "      <td>0.001829</td>\n",
       "      <td>0.093746</td>\n",
       "      <td>3.893359e-07</td>\n",
       "      <td>35.6938</td>\n",
       "      <td>0.0462329</td>\n",
       "      <td>False</td>\n",
       "      <td>{'C': 35.69381054066936, 'gamma': 0.0462328665583005, 'shrinking': False}</td>\n",
       "      <td>0.774757</td>\n",
       "      <td>0.801942</td>\n",
       "      <td>0.773438</td>\n",
       "      <td>0.783398</td>\n",
       "      <td>0.013142</td>\n",
       "      <td>22</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998053</td>\n",
       "      <td>0.998058</td>\n",
       "      <td>0.998704</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>0.398743</td>\n",
       "      <td>0.011208</td>\n",
       "      <td>0.114579</td>\n",
       "      <td>7.365302e-03</td>\n",
       "      <td>6.30682</td>\n",
       "      <td>0.107742</td>\n",
       "      <td>False</td>\n",
       "      <td>{'C': 6.306815740587758, 'gamma': 0.10774160561426925, 'shrinking': False}</td>\n",
       "      <td>0.757282</td>\n",
       "      <td>0.755340</td>\n",
       "      <td>0.742188</td>\n",
       "      <td>0.751621</td>\n",
       "      <td>0.006698</td>\n",
       "      <td>85</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997079</td>\n",
       "      <td>0.998058</td>\n",
       "      <td>0.998379</td>\n",
       "      <td>0.001214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>0.407702</td>\n",
       "      <td>0.013119</td>\n",
       "      <td>0.130203</td>\n",
       "      <td>7.365021e-03</td>\n",
       "      <td>10.5791</td>\n",
       "      <td>0.124569</td>\n",
       "      <td>False</td>\n",
       "      <td>{'C': 10.57910244128353, 'gamma': 0.1245693546683232, 'shrinking': False}</td>\n",
       "      <td>0.743689</td>\n",
       "      <td>0.759223</td>\n",
       "      <td>0.728516</td>\n",
       "      <td>0.743839</td>\n",
       "      <td>0.012531</td>\n",
       "      <td>96</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998053</td>\n",
       "      <td>0.998058</td>\n",
       "      <td>0.998704</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>0.335754</td>\n",
       "      <td>0.010207</td>\n",
       "      <td>0.109371</td>\n",
       "      <td>1.123916e-07</td>\n",
       "      <td>32.879</td>\n",
       "      <td>0.059114</td>\n",
       "      <td>False</td>\n",
       "      <td>{'C': 32.878984128268506, 'gamma': 0.059114012269919504, 'shrinking': False}</td>\n",
       "      <td>0.768932</td>\n",
       "      <td>0.811650</td>\n",
       "      <td>0.771484</td>\n",
       "      <td>0.784047</td>\n",
       "      <td>0.019575</td>\n",
       "      <td>15</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998053</td>\n",
       "      <td>0.998058</td>\n",
       "      <td>0.998704</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>0.446554</td>\n",
       "      <td>0.004192</td>\n",
       "      <td>0.109737</td>\n",
       "      <td>5.187434e-04</td>\n",
       "      <td>23.6719</td>\n",
       "      <td>0.0694544</td>\n",
       "      <td>True</td>\n",
       "      <td>{'C': 23.671900054044677, 'gamma': 0.06945444963150091, 'shrinking': True}</td>\n",
       "      <td>0.772816</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.769531</td>\n",
       "      <td>0.780804</td>\n",
       "      <td>0.013659</td>\n",
       "      <td>40</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998053</td>\n",
       "      <td>0.998058</td>\n",
       "      <td>0.998704</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>0.478278</td>\n",
       "      <td>0.003288</td>\n",
       "      <td>0.124995</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>6.9413</td>\n",
       "      <td>0.119653</td>\n",
       "      <td>True</td>\n",
       "      <td>{'C': 6.941303174125791, 'gamma': 0.11965306437143686, 'shrinking': True}</td>\n",
       "      <td>0.743689</td>\n",
       "      <td>0.757282</td>\n",
       "      <td>0.730469</td>\n",
       "      <td>0.743839</td>\n",
       "      <td>0.010941</td>\n",
       "      <td>96</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998053</td>\n",
       "      <td>0.998058</td>\n",
       "      <td>0.998704</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>0.281041</td>\n",
       "      <td>0.008396</td>\n",
       "      <td>0.098955</td>\n",
       "      <td>7.365021e-03</td>\n",
       "      <td>45.3136</td>\n",
       "      <td>0.0361607</td>\n",
       "      <td>False</td>\n",
       "      <td>{'C': 45.31356601834488, 'gamma': 0.0361606606243135, 'shrinking': False}</td>\n",
       "      <td>0.782524</td>\n",
       "      <td>0.803883</td>\n",
       "      <td>0.769531</td>\n",
       "      <td>0.785344</td>\n",
       "      <td>0.014159</td>\n",
       "      <td>7</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997079</td>\n",
       "      <td>0.998058</td>\n",
       "      <td>0.998379</td>\n",
       "      <td>0.001214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>0.474374</td>\n",
       "      <td>0.002104</td>\n",
       "      <td>0.119787</td>\n",
       "      <td>7.364403e-03</td>\n",
       "      <td>29.827</td>\n",
       "      <td>0.095629</td>\n",
       "      <td>True</td>\n",
       "      <td>{'C': 29.827002236085743, 'gamma': 0.09562895301932473, 'shrinking': True}</td>\n",
       "      <td>0.761165</td>\n",
       "      <td>0.770874</td>\n",
       "      <td>0.744141</td>\n",
       "      <td>0.758755</td>\n",
       "      <td>0.011041</td>\n",
       "      <td>71</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998053</td>\n",
       "      <td>0.998058</td>\n",
       "      <td>0.998704</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>0.466553</td>\n",
       "      <td>0.005318</td>\n",
       "      <td>0.125529</td>\n",
       "      <td>7.553839e-04</td>\n",
       "      <td>26.0832</td>\n",
       "      <td>0.0969888</td>\n",
       "      <td>True</td>\n",
       "      <td>{'C': 26.08318200276695, 'gamma': 0.0969887771494705, 'shrinking': True}</td>\n",
       "      <td>0.759223</td>\n",
       "      <td>0.770874</td>\n",
       "      <td>0.740234</td>\n",
       "      <td>0.756809</td>\n",
       "      <td>0.012619</td>\n",
       "      <td>76</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998053</td>\n",
       "      <td>0.998058</td>\n",
       "      <td>0.998704</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>0.468890</td>\n",
       "      <td>0.008287</td>\n",
       "      <td>0.119821</td>\n",
       "      <td>7.389072e-03</td>\n",
       "      <td>8.68249</td>\n",
       "      <td>0.0924986</td>\n",
       "      <td>True</td>\n",
       "      <td>{'C': 8.682492247264607, 'gamma': 0.09249857486925743, 'shrinking': True}</td>\n",
       "      <td>0.759223</td>\n",
       "      <td>0.770874</td>\n",
       "      <td>0.746094</td>\n",
       "      <td>0.758755</td>\n",
       "      <td>0.010117</td>\n",
       "      <td>71</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997079</td>\n",
       "      <td>0.998058</td>\n",
       "      <td>0.998379</td>\n",
       "      <td>0.001214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>0.280888</td>\n",
       "      <td>0.006503</td>\n",
       "      <td>0.098955</td>\n",
       "      <td>7.366033e-03</td>\n",
       "      <td>35.8174</td>\n",
       "      <td>0.0347452</td>\n",
       "      <td>False</td>\n",
       "      <td>{'C': 35.81738243474779, 'gamma': 0.03474518078781474, 'shrinking': False}</td>\n",
       "      <td>0.786408</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.771484</td>\n",
       "      <td>0.785992</td>\n",
       "      <td>0.011639</td>\n",
       "      <td>5</td>\n",
       "      <td>0.999026</td>\n",
       "      <td>0.997079</td>\n",
       "      <td>0.998058</td>\n",
       "      <td>0.998054</td>\n",
       "      <td>0.000795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>0.450861</td>\n",
       "      <td>0.005477</td>\n",
       "      <td>0.114579</td>\n",
       "      <td>7.365302e-03</td>\n",
       "      <td>37.7087</td>\n",
       "      <td>0.0768557</td>\n",
       "      <td>True</td>\n",
       "      <td>{'C': 37.70866368316434, 'gamma': 0.07685566779127499, 'shrinking': True}</td>\n",
       "      <td>0.766990</td>\n",
       "      <td>0.794175</td>\n",
       "      <td>0.763672</td>\n",
       "      <td>0.774968</td>\n",
       "      <td>0.013669</td>\n",
       "      <td>50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998053</td>\n",
       "      <td>0.998058</td>\n",
       "      <td>0.998704</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>0.419297</td>\n",
       "      <td>0.006615</td>\n",
       "      <td>0.124994</td>\n",
       "      <td>4.495664e-07</td>\n",
       "      <td>9.79117</td>\n",
       "      <td>0.139521</td>\n",
       "      <td>False</td>\n",
       "      <td>{'C': 9.791171060322286, 'gamma': 0.13952095406748038, 'shrinking': False}</td>\n",
       "      <td>0.741748</td>\n",
       "      <td>0.753398</td>\n",
       "      <td>0.734375</td>\n",
       "      <td>0.743191</td>\n",
       "      <td>0.007829</td>\n",
       "      <td>100</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998053</td>\n",
       "      <td>0.998058</td>\n",
       "      <td>0.998704</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>0.251277</td>\n",
       "      <td>0.011860</td>\n",
       "      <td>0.088538</td>\n",
       "      <td>7.364909e-03</td>\n",
       "      <td>32.5323</td>\n",
       "      <td>0.0114984</td>\n",
       "      <td>False</td>\n",
       "      <td>{'C': 32.53231206080328, 'gamma': 0.01149843652562267, 'shrinking': False}</td>\n",
       "      <td>0.763107</td>\n",
       "      <td>0.780583</td>\n",
       "      <td>0.761719</td>\n",
       "      <td>0.768482</td>\n",
       "      <td>0.008587</td>\n",
       "      <td>61</td>\n",
       "      <td>0.986368</td>\n",
       "      <td>0.984421</td>\n",
       "      <td>0.988350</td>\n",
       "      <td>0.986379</td>\n",
       "      <td>0.001604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>0.448305</td>\n",
       "      <td>0.009034</td>\n",
       "      <td>0.109223</td>\n",
       "      <td>2.079259e-04</td>\n",
       "      <td>7.96001</td>\n",
       "      <td>0.0706719</td>\n",
       "      <td>True</td>\n",
       "      <td>{'C': 7.960011267302631, 'gamma': 0.07067192318567007, 'shrinking': True}</td>\n",
       "      <td>0.766990</td>\n",
       "      <td>0.796117</td>\n",
       "      <td>0.771484</td>\n",
       "      <td>0.778210</td>\n",
       "      <td>0.012812</td>\n",
       "      <td>47</td>\n",
       "      <td>0.999026</td>\n",
       "      <td>0.994158</td>\n",
       "      <td>0.996117</td>\n",
       "      <td>0.996434</td>\n",
       "      <td>0.002000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>0.319875</td>\n",
       "      <td>0.010425</td>\n",
       "      <td>0.104162</td>\n",
       "      <td>7.364797e-03</td>\n",
       "      <td>35.4274</td>\n",
       "      <td>0.0543429</td>\n",
       "      <td>False</td>\n",
       "      <td>{'C': 35.427424814754794, 'gamma': 0.0543429191011398, 'shrinking': False}</td>\n",
       "      <td>0.774757</td>\n",
       "      <td>0.815534</td>\n",
       "      <td>0.773438</td>\n",
       "      <td>0.787938</td>\n",
       "      <td>0.019549</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998053</td>\n",
       "      <td>0.998058</td>\n",
       "      <td>0.998704</td>\n",
       "      <td>0.000917</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time   param_C  \\\n",
       "0         0.490553      0.008267         0.130203    7.365527e-03   19.2625   \n",
       "1         0.357690      0.013125         0.098955    7.365527e-03   47.4678   \n",
       "2         0.358646      0.004679         0.114579    7.365639e-03   45.1782   \n",
       "3         0.400697      0.005669         0.114579    7.365358e-03   35.2666   \n",
       "4         0.271918      0.004669         0.097434    5.215195e-03   27.4638   \n",
       "5         0.262663      0.006621         0.088538    7.365583e-03   49.3714   \n",
       "6         0.447708      0.005450         0.109370    7.018853e-07   29.2905   \n",
       "7         0.477364      0.007812         0.119788    7.365808e-03   28.9505   \n",
       "8         0.342583      0.005131         0.109371    2.973602e-07   41.9842   \n",
       "9         0.355870      0.008014         0.093746    3.371748e-07   14.8467   \n",
       "10        0.443700      0.005953         0.109371    0.000000e+00   4.15025   \n",
       "11        0.358232      0.011389         0.109371    4.052337e-07   33.0955   \n",
       "12        0.394910      0.004605         0.119786    7.366539e-03  0.382329   \n",
       "13        0.483953      0.005181         0.124995    4.052337e-07   4.65606   \n",
       "14        0.479941      0.008295         0.109371    8.485379e-07   8.69826   \n",
       "15        0.435567      0.015291         0.128181    2.560313e-03   2.69753   \n",
       "16        0.483643      0.006964         0.119787    7.365583e-03   8.97329   \n",
       "17        0.489988      0.001343         0.125821    1.168311e-03   4.71161   \n",
       "18        0.465456      0.004471         0.114579    7.365246e-03   18.6899   \n",
       "19        0.345717      0.004889         0.088538    7.365134e-03   38.1606   \n",
       "20        0.466490      0.006284         0.114580    7.364459e-03   42.7214   \n",
       "21        0.387061      0.008028         0.119787    7.365696e-03   11.0006   \n",
       "22        0.261218      0.007007         0.093746    1.123916e-07   2.29245   \n",
       "23        0.444733      0.007487         0.109371    2.247832e-07   13.3742   \n",
       "24        0.460929      0.005729         0.119787    7.365527e-03   17.9887   \n",
       "25        0.397009      0.005008         0.118287    6.567020e-03   27.0323   \n",
       "26        0.294354      0.000987         0.093740    8.768706e-06  0.065385   \n",
       "27        0.367684      0.011996         0.093746    1.946680e-07   20.1643   \n",
       "28        0.411121      0.003426         0.124995    2.247832e-07    26.914   \n",
       "29        0.474933      0.006635         0.109371    1.123916e-07   5.63032   \n",
       "..             ...           ...              ...             ...       ...   \n",
       "90        0.346257      0.010683         0.109371    1.123916e-07   7.40204   \n",
       "91        0.436360      0.011811         0.109371    1.123916e-07   41.2496   \n",
       "92        0.456094      0.008951         0.113751    8.015518e-03    26.513   \n",
       "93        0.263259      0.006246         0.088535    7.364235e-03      26.1   \n",
       "94        0.261243      0.007217         0.083330    7.365246e-03   28.7436   \n",
       "95        0.249965      0.012048         0.083330    7.365471e-03   40.4004   \n",
       "96        0.312370      0.001097         0.098954    7.365077e-03    32.353   \n",
       "97        0.236604      0.010438         0.083330    7.365358e-03    2.8418   \n",
       "98        0.232956      0.012335         0.093748    2.657295e-06   5.18722   \n",
       "99        0.401434      0.008301         0.119790    7.367664e-03   31.2269   \n",
       "100       0.395589      0.007939         0.109371    2.247832e-07    12.049   \n",
       "101       0.470859      0.004115         0.114580    7.364684e-03   24.6417   \n",
       "102       0.236667      0.002109         0.088538    7.365358e-03   1.64123   \n",
       "103       0.442383      0.005631         0.104163    7.365302e-03   13.3739   \n",
       "104       0.313114      0.001829         0.093746    3.893359e-07   35.6938   \n",
       "105       0.398743      0.011208         0.114579    7.365302e-03   6.30682   \n",
       "106       0.407702      0.013119         0.130203    7.365021e-03   10.5791   \n",
       "107       0.335754      0.010207         0.109371    1.123916e-07    32.879   \n",
       "108       0.446554      0.004192         0.109737    5.187434e-04   23.6719   \n",
       "109       0.478278      0.003288         0.124995    0.000000e+00    6.9413   \n",
       "110       0.281041      0.008396         0.098955    7.365021e-03   45.3136   \n",
       "111       0.474374      0.002104         0.119787    7.364403e-03    29.827   \n",
       "112       0.466553      0.005318         0.125529    7.553839e-04   26.0832   \n",
       "113       0.468890      0.008287         0.119821    7.389072e-03   8.68249   \n",
       "114       0.280888      0.006503         0.098955    7.366033e-03   35.8174   \n",
       "115       0.450861      0.005477         0.114579    7.365302e-03   37.7087   \n",
       "116       0.419297      0.006615         0.124994    4.495664e-07   9.79117   \n",
       "117       0.251277      0.011860         0.088538    7.364909e-03   32.5323   \n",
       "118       0.448305      0.009034         0.109223    2.079259e-04   7.96001   \n",
       "119       0.319875      0.010425         0.104162    7.364797e-03   35.4274   \n",
       "\n",
       "    param_gamma param_shrinking  \\\n",
       "0      0.154259            True   \n",
       "1     0.0407651            True   \n",
       "2     0.0746224           False   \n",
       "3      0.101341           False   \n",
       "4      0.026813           False   \n",
       "5     0.0220207            True   \n",
       "6     0.0689445            True   \n",
       "7      0.102491            True   \n",
       "8     0.0639297           False   \n",
       "9     0.0350516            True   \n",
       "10    0.0689186            True   \n",
       "11    0.0712146           False   \n",
       "12     0.121264           False   \n",
       "13     0.144236            True   \n",
       "14     0.104208            True   \n",
       "15     0.148885           False   \n",
       "16     0.116828            True   \n",
       "17      0.14614            True   \n",
       "18    0.0875379            True   \n",
       "19    0.0324731            True   \n",
       "20     0.090361            True   \n",
       "21    0.0925419           False   \n",
       "22     0.022649           False   \n",
       "23    0.0662412            True   \n",
       "24    0.0884335            True   \n",
       "25     0.100304           False   \n",
       "26    0.0319357            True   \n",
       "27    0.0371033            True   \n",
       "28     0.117371           False   \n",
       "29      0.10113            True   \n",
       "..          ...             ...   \n",
       "90     0.066673           False   \n",
       "91    0.0604683            True   \n",
       "92    0.0806078            True   \n",
       "93    0.0193134            True   \n",
       "94    0.0181597           False   \n",
       "95    0.0120501            True   \n",
       "96    0.0462698           False   \n",
       "97    0.0109268           False   \n",
       "98    0.0120731            True   \n",
       "99     0.106368           False   \n",
       "100   0.0983427           False   \n",
       "101   0.0931146            True   \n",
       "102   0.0120562            True   \n",
       "103   0.0636064            True   \n",
       "104   0.0462329           False   \n",
       "105    0.107742           False   \n",
       "106    0.124569           False   \n",
       "107    0.059114           False   \n",
       "108   0.0694544            True   \n",
       "109    0.119653            True   \n",
       "110   0.0361607           False   \n",
       "111    0.095629            True   \n",
       "112   0.0969888            True   \n",
       "113   0.0924986            True   \n",
       "114   0.0347452           False   \n",
       "115   0.0768557            True   \n",
       "116    0.139521           False   \n",
       "117   0.0114984           False   \n",
       "118   0.0706719            True   \n",
       "119   0.0543429           False   \n",
       "\n",
       "                                                                           params  \\\n",
       "0       {'C': 19.26248752837037, 'gamma': 0.15425898456052756, 'shrinking': True}   \n",
       "1      {'C': 47.467764705122015, 'gamma': 0.04076509881741229, 'shrinking': True}   \n",
       "2      {'C': 45.17822268576651, 'gamma': 0.07462240280077816, 'shrinking': False}   \n",
       "3     {'C': 35.266567421761586, 'gamma': 0.10134095762731304, 'shrinking': False}   \n",
       "4    {'C': 27.463828618924303, 'gamma': 0.026813031995736276, 'shrinking': False}   \n",
       "5     {'C': 49.371396677766676, 'gamma': 0.022020693132256117, 'shrinking': True}   \n",
       "6      {'C': 29.290475010392882, 'gamma': 0.06894445193558148, 'shrinking': True}   \n",
       "7       {'C': 28.950492540808934, 'gamma': 0.1024906153826446, 'shrinking': True}   \n",
       "8     {'C': 41.984178947732715, 'gamma': 0.06392974884132539, 'shrinking': False}   \n",
       "9      {'C': 14.846698448499513, 'gamma': 0.03505164225045203, 'shrinking': True}   \n",
       "10      {'C': 4.150247492305144, 'gamma': 0.06891857854507473, 'shrinking': True}   \n",
       "11     {'C': 33.09550591871901, 'gamma': 0.07121457954208432, 'shrinking': False}   \n",
       "12   {'C': 0.38232933612978415, 'gamma': 0.12126362122164655, 'shrinking': False}   \n",
       "13      {'C': 4.656057923385682, 'gamma': 0.14423578395322106, 'shrinking': True}   \n",
       "14      {'C': 8.698260890203485, 'gamma': 0.10420839875892418, 'shrinking': True}   \n",
       "15     {'C': 2.697533207714371, 'gamma': 0.14888472962984606, 'shrinking': False}   \n",
       "16      {'C': 8.973288997623152, 'gamma': 0.11682763944017847, 'shrinking': True}   \n",
       "17       {'C': 4.71161019549783, 'gamma': 0.14613998373041326, 'shrinking': True}   \n",
       "18      {'C': 18.689872019819923, 'gamma': 0.0875379249268066, 'shrinking': True}   \n",
       "19       {'C': 38.1605766718631, 'gamma': 0.03247311384933184, 'shrinking': True}   \n",
       "20       {'C': 42.7214141275145, 'gamma': 0.09036100380457267, 'shrinking': True}   \n",
       "21     {'C': 11.00063583368149, 'gamma': 0.09254190604268656, 'shrinking': False}   \n",
       "22    {'C': 2.292452511635402, 'gamma': 0.022648975967004322, 'shrinking': False}   \n",
       "23     {'C': 13.374157403935339, 'gamma': 0.06624124171058018, 'shrinking': True}   \n",
       "24     {'C': 17.988650756701695, 'gamma': 0.08843347002863645, 'shrinking': True}   \n",
       "25    {'C': 27.032310831604626, 'gamma': 0.10030404157242598, 'shrinking': False}   \n",
       "26   {'C': 0.06538502485824547, 'gamma': 0.031935688793944164, 'shrinking': True}   \n",
       "27    {'C': 20.164310563216905, 'gamma': 0.037103263294673824, 'shrinking': True}   \n",
       "28     {'C': 26.91396934414255, 'gamma': 0.11737137340071307, 'shrinking': False}   \n",
       "29      {'C': 5.630324577077462, 'gamma': 0.10113024673770687, 'shrinking': True}   \n",
       "..                                                                            ...   \n",
       "90        {'C': 7.402038266848, 'gamma': 0.06667297102799205, 'shrinking': False}   \n",
       "91      {'C': 41.24959812437073, 'gamma': 0.06046825586739161, 'shrinking': True}   \n",
       "92     {'C': 26.512992915036346, 'gamma': 0.08060777748997125, 'shrinking': True}   \n",
       "93     {'C': 26.100014297576994, 'gamma': 0.01931339897662503, 'shrinking': True}   \n",
       "94    {'C': 28.74359759695357, 'gamma': 0.018159694883001915, 'shrinking': False}   \n",
       "95     {'C': 40.40035795318392, 'gamma': 0.012050115885966146, 'shrinking': True}   \n",
       "96     {'C': 32.35296561800621, 'gamma': 0.04626978131094986, 'shrinking': False}   \n",
       "97   {'C': 2.8418033563420604, 'gamma': 0.010926818745688016, 'shrinking': False}   \n",
       "98     {'C': 5.187219861835652, 'gamma': 0.012073147217292596, 'shrinking': True}   \n",
       "99    {'C': 31.226913546371623, 'gamma': 0.10636773963939428, 'shrinking': False}   \n",
       "100   {'C': 12.048963026484323, 'gamma': 0.09834265606220108, 'shrinking': False}   \n",
       "101     {'C': 24.64168022883977, 'gamma': 0.09311460483872955, 'shrinking': True}   \n",
       "102   {'C': 1.6412297618941374, 'gamma': 0.012056245564175989, 'shrinking': True}   \n",
       "103      {'C': 13.373916691096655, 'gamma': 0.063606397540602, 'shrinking': True}   \n",
       "104     {'C': 35.69381054066936, 'gamma': 0.0462328665583005, 'shrinking': False}   \n",
       "105    {'C': 6.306815740587758, 'gamma': 0.10774160561426925, 'shrinking': False}   \n",
       "106     {'C': 10.57910244128353, 'gamma': 0.1245693546683232, 'shrinking': False}   \n",
       "107  {'C': 32.878984128268506, 'gamma': 0.059114012269919504, 'shrinking': False}   \n",
       "108    {'C': 23.671900054044677, 'gamma': 0.06945444963150091, 'shrinking': True}   \n",
       "109     {'C': 6.941303174125791, 'gamma': 0.11965306437143686, 'shrinking': True}   \n",
       "110     {'C': 45.31356601834488, 'gamma': 0.0361606606243135, 'shrinking': False}   \n",
       "111    {'C': 29.827002236085743, 'gamma': 0.09562895301932473, 'shrinking': True}   \n",
       "112      {'C': 26.08318200276695, 'gamma': 0.0969887771494705, 'shrinking': True}   \n",
       "113     {'C': 8.682492247264607, 'gamma': 0.09249857486925743, 'shrinking': True}   \n",
       "114    {'C': 35.81738243474779, 'gamma': 0.03474518078781474, 'shrinking': False}   \n",
       "115     {'C': 37.70866368316434, 'gamma': 0.07685566779127499, 'shrinking': True}   \n",
       "116    {'C': 9.791171060322286, 'gamma': 0.13952095406748038, 'shrinking': False}   \n",
       "117    {'C': 32.53231206080328, 'gamma': 0.01149843652562267, 'shrinking': False}   \n",
       "118     {'C': 7.960011267302631, 'gamma': 0.07067192318567007, 'shrinking': True}   \n",
       "119    {'C': 35.427424814754794, 'gamma': 0.0543429191011398, 'shrinking': False}   \n",
       "\n",
       "     split0_test_score  split1_test_score  split2_test_score  mean_test_score  \\\n",
       "0             0.739806           0.743689           0.730469         0.738003   \n",
       "1             0.778641           0.803883           0.767578         0.783398   \n",
       "2             0.765049           0.796117           0.765625         0.775616   \n",
       "3             0.753398           0.768932           0.738281         0.753567   \n",
       "4             0.790291           0.801942           0.763672         0.785344   \n",
       "5             0.766990           0.788350           0.759766         0.771725   \n",
       "6             0.776699           0.800000           0.769531         0.782101   \n",
       "7             0.755340           0.765049           0.738281         0.752918   \n",
       "8             0.774757           0.807767           0.767578         0.783398   \n",
       "9             0.786408           0.801942           0.763672         0.784047   \n",
       "10            0.770874           0.786408           0.771484         0.776265   \n",
       "11            0.768932           0.798058           0.769531         0.778859   \n",
       "12            0.693204           0.681553           0.705078         0.693256   \n",
       "13            0.741748           0.743689           0.736328         0.740597   \n",
       "14            0.753398           0.761165           0.738281         0.750973   \n",
       "15            0.735922           0.741748           0.730469         0.736057   \n",
       "16            0.745631           0.759223           0.726562         0.743839   \n",
       "17            0.741748           0.743689           0.736328         0.740597   \n",
       "18            0.765049           0.782524           0.746094         0.764591   \n",
       "19            0.778641           0.803883           0.765625         0.782750   \n",
       "20            0.763107           0.780583           0.748047         0.763943   \n",
       "21            0.759223           0.772816           0.742188         0.758106   \n",
       "22            0.786408           0.800000           0.775391         0.787289   \n",
       "23            0.770874           0.801942           0.771484         0.781453   \n",
       "24            0.765049           0.782524           0.746094         0.764591   \n",
       "25            0.753398           0.768932           0.740234         0.754215   \n",
       "26            0.681553           0.681553           0.683594         0.682231   \n",
       "27            0.794175           0.798058           0.769531         0.787289   \n",
       "28            0.745631           0.759223           0.728516         0.744488   \n",
       "29            0.753398           0.765049           0.740234         0.752918   \n",
       "..                 ...                ...                ...              ...   \n",
       "90            0.765049           0.801942           0.775391         0.780804   \n",
       "91            0.766990           0.811650           0.769531         0.782750   \n",
       "92            0.770874           0.794175           0.759766         0.774968   \n",
       "93            0.768932           0.784466           0.761719         0.771725   \n",
       "94            0.765049           0.782524           0.759766         0.769131   \n",
       "95            0.761165           0.774757           0.751953         0.762646   \n",
       "96            0.774757           0.800000           0.773438         0.782750   \n",
       "97            0.786408           0.776699           0.757812         0.773671   \n",
       "98            0.784466           0.794175           0.773438         0.784047   \n",
       "99            0.759223           0.763107           0.738281         0.753567   \n",
       "100           0.753398           0.770874           0.740234         0.754864   \n",
       "101           0.761165           0.776699           0.742188         0.760052   \n",
       "102           0.770874           0.763107           0.755859         0.763294   \n",
       "103           0.776699           0.803883           0.771484         0.784047   \n",
       "104           0.774757           0.801942           0.773438         0.783398   \n",
       "105           0.757282           0.755340           0.742188         0.751621   \n",
       "106           0.743689           0.759223           0.728516         0.743839   \n",
       "107           0.768932           0.811650           0.771484         0.784047   \n",
       "108           0.772816           0.800000           0.769531         0.780804   \n",
       "109           0.743689           0.757282           0.730469         0.743839   \n",
       "110           0.782524           0.803883           0.769531         0.785344   \n",
       "111           0.761165           0.770874           0.744141         0.758755   \n",
       "112           0.759223           0.770874           0.740234         0.756809   \n",
       "113           0.759223           0.770874           0.746094         0.758755   \n",
       "114           0.786408           0.800000           0.771484         0.785992   \n",
       "115           0.766990           0.794175           0.763672         0.774968   \n",
       "116           0.741748           0.753398           0.734375         0.743191   \n",
       "117           0.763107           0.780583           0.761719         0.768482   \n",
       "118           0.766990           0.796117           0.771484         0.778210   \n",
       "119           0.774757           0.815534           0.773438         0.787938   \n",
       "\n",
       "     std_test_score  rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0          0.005544              114            1.000000            0.998053   \n",
       "1          0.015193               22            1.000000            0.998053   \n",
       "2          0.014519               49            1.000000            0.998053   \n",
       "3          0.012508               79            1.000000            0.998053   \n",
       "4          0.016004                7            0.999026            0.993184   \n",
       "5          0.012136               58            0.999026            0.995131   \n",
       "6          0.013008               33            1.000000            0.998053   \n",
       "7          0.011056               81            1.000000            0.998053   \n",
       "8          0.017503               22            1.000000            0.998053   \n",
       "9          0.015705               15            0.997079            0.991237   \n",
       "10         0.007187               48            0.996105            0.988315   \n",
       "11         0.013598               46            1.000000            0.998053   \n",
       "12         0.009599              119            0.720545            0.703992   \n",
       "13         0.003112              111            1.000000            0.998053   \n",
       "14         0.009494               86            1.000000            0.998053   \n",
       "15         0.004603              117            1.000000            0.993184   \n",
       "16         0.013387               96            1.000000            0.998053   \n",
       "17         0.003112              111            1.000000            0.998053   \n",
       "18         0.014869               63            1.000000            0.998053   \n",
       "19         0.015880               28            0.999026            0.997079   \n",
       "20         0.013289               65            1.000000            0.998053   \n",
       "21         0.012523               74            1.000000            0.998053   \n",
       "22         0.010061                3            0.909445            0.900682   \n",
       "23         0.014511               37            1.000000            0.997079   \n",
       "24         0.014869               63            1.000000            0.998053   \n",
       "25         0.011724               78            1.000000            0.998053   \n",
       "26         0.000961              120            0.682571            0.682571   \n",
       "27         0.012620                3            0.999026            0.995131   \n",
       "28         0.012556               89            1.000000            0.998053   \n",
       "29         0.010131               81            1.000000            0.995131   \n",
       "..              ...              ...                 ...                 ...   \n",
       "90         0.015552               40            0.999026            0.992210   \n",
       "91         0.020492               28            1.000000            0.998053   \n",
       "92         0.014337               50            1.000000            0.998053   \n",
       "93         0.009490               58            0.996105            0.990263   \n",
       "94         0.009726               60            0.996105            0.990263   \n",
       "95         0.009364               67            0.992210            0.986368   \n",
       "96         0.012227               28            1.000000            0.997079   \n",
       "97         0.011864               55            0.867575            0.856865   \n",
       "98         0.008467               15            0.907498            0.902629   \n",
       "99         0.010893               79            1.000000            0.998053   \n",
       "100        0.012545               77            1.000000            0.998053   \n",
       "101        0.014104               70            1.000000            0.998053   \n",
       "102        0.006128               66            0.826680            0.828627   \n",
       "103        0.014207               15            1.000000            0.997079   \n",
       "104        0.013142               22            1.000000            0.998053   \n",
       "105        0.006698               85            1.000000            0.997079   \n",
       "106        0.012531               96            1.000000            0.998053   \n",
       "107        0.019575               15            1.000000            0.998053   \n",
       "108        0.013659               40            1.000000            0.998053   \n",
       "109        0.010941               96            1.000000            0.998053   \n",
       "110        0.014159                7            1.000000            0.997079   \n",
       "111        0.011041               71            1.000000            0.998053   \n",
       "112        0.012619               76            1.000000            0.998053   \n",
       "113        0.010117               71            1.000000            0.997079   \n",
       "114        0.011639                5            0.999026            0.997079   \n",
       "115        0.013669               50            1.000000            0.998053   \n",
       "116        0.007829              100            1.000000            0.998053   \n",
       "117        0.008587               61            0.986368            0.984421   \n",
       "118        0.012812               47            0.999026            0.994158   \n",
       "119        0.019549                2            1.000000            0.998053   \n",
       "\n",
       "     split2_train_score  mean_train_score  std_train_score  \n",
       "0              0.998058          0.998704         0.000917  \n",
       "1              0.998058          0.998704         0.000917  \n",
       "2              0.998058          0.998704         0.000917  \n",
       "3              0.998058          0.998704         0.000917  \n",
       "4              0.997087          0.996433         0.002430  \n",
       "5              0.998058          0.997405         0.001656  \n",
       "6              0.998058          0.998704         0.000917  \n",
       "7              0.998058          0.998704         0.000917  \n",
       "8              0.998058          0.998704         0.000917  \n",
       "9              0.996117          0.994811         0.002558  \n",
       "10             0.994175          0.992865         0.003312  \n",
       "11             0.998058          0.998704         0.000917  \n",
       "12             0.719417          0.714652         0.007551  \n",
       "13             0.998058          0.998704         0.000917  \n",
       "14             0.998058          0.998704         0.000917  \n",
       "15             0.994175          0.995786         0.003007  \n",
       "16             0.998058          0.998704         0.000917  \n",
       "17             0.998058          0.998704         0.000917  \n",
       "18             0.998058          0.998704         0.000917  \n",
       "19             0.998058          0.998054         0.000795  \n",
       "20             0.998058          0.998704         0.000917  \n",
       "21             0.998058          0.998704         0.000917  \n",
       "22             0.905825          0.905317         0.003596  \n",
       "23             0.998058          0.998379         0.001214  \n",
       "24             0.998058          0.998704         0.000917  \n",
       "25             0.998058          0.998704         0.000917  \n",
       "26             0.681553          0.682232         0.000480  \n",
       "27             0.998058          0.997405         0.001656  \n",
       "28             0.998058          0.998704         0.000917  \n",
       "29             0.997087          0.997406         0.002000  \n",
       "..                  ...               ...              ...  \n",
       "90             0.996117          0.995784         0.002793  \n",
       "91             0.998058          0.998704         0.000917  \n",
       "92             0.998058          0.998704         0.000917  \n",
       "93             0.996117          0.994162         0.002757  \n",
       "94             0.996117          0.994162         0.002757  \n",
       "95             0.994175          0.990918         0.003316  \n",
       "96             0.998058          0.998379         0.001214  \n",
       "97             0.863107          0.862516         0.004393  \n",
       "98             0.912621          0.907583         0.004080  \n",
       "99             0.998058          0.998704         0.000917  \n",
       "100            0.998058          0.998704         0.000917  \n",
       "101            0.998058          0.998704         0.000917  \n",
       "102            0.829126          0.828144         0.001056  \n",
       "103            0.998058          0.998379         0.001214  \n",
       "104            0.998058          0.998704         0.000917  \n",
       "105            0.998058          0.998379         0.001214  \n",
       "106            0.998058          0.998704         0.000917  \n",
       "107            0.998058          0.998704         0.000917  \n",
       "108            0.998058          0.998704         0.000917  \n",
       "109            0.998058          0.998704         0.000917  \n",
       "110            0.998058          0.998379         0.001214  \n",
       "111            0.998058          0.998704         0.000917  \n",
       "112            0.998058          0.998704         0.000917  \n",
       "113            0.998058          0.998379         0.001214  \n",
       "114            0.998058          0.998054         0.000795  \n",
       "115            0.998058          0.998704         0.000917  \n",
       "116            0.998058          0.998704         0.000917  \n",
       "117            0.988350          0.986379         0.001604  \n",
       "118            0.996117          0.996434         0.002000  \n",
       "119            0.998058          0.998704         0.000917  \n",
       "\n",
       "[120 rows x 19 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(svmRSCV.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8081395348837209"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svmRSCV.best_estimator_.score(vectTexts_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
