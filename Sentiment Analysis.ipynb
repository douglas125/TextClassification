{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis\n",
    "\n",
    "Read the Foursquare annotated comments in Brazilian Portuguese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('max_colwidth',150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texto</th>\n",
       "      <th>rotulo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A comida é deliciosa, mas pedi limonada suiça e me disseram que hoje estavam todos muito ocupados e que ninguém conseguiria me atender....melhor i...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A partir desta sexta feira dia 11 começam a abrir para jantar mas corre pois é só até as 22 hrs e no domingo dia das mães, estarão aberto durante ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Joint burguer e brewdog</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Agora de segunda a sexta o Habanero vai abrir no almoço com pratos mexicanos e tradicionais!</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Experimente o drink \"Dona Diabla\". Muito bom!</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Nova senha do Wifi: 1129508219</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Wi-fi 1129508219</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Adoramos a pizza carbonara e a paulistana. Não surpreendeu tanto, mas vale a pena por resgatar o tradicionalismo. Dica @Gourmet_For</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>O diferencial desse Burger King é que você mesmo serve o refrigerante, e a vontade!</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Unico defeito estacionamento pago!</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>24h é 24h.</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Excelente Burger King: bom atendimento, ambiente agradável e refil para refrigerante. Evite o inconveniente estacionamento pago estacionando ao re...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>o atendimento aqui é simplesmente um lixo</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>O Drive-Truh mais lento da cidade!!</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Cheio de bêbados depois das 2 da manhã :D</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Recinto sujo, sem manutenção. Não há segurança pra conter a briga que ocorreu agora há pouco. O refrigerante está aguado, sem gosto, horrível. O l...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                    texto  \\\n",
       "0   A comida é deliciosa, mas pedi limonada suiça e me disseram que hoje estavam todos muito ocupados e que ninguém conseguiria me atender....melhor i...   \n",
       "1   A partir desta sexta feira dia 11 começam a abrir para jantar mas corre pois é só até as 22 hrs e no domingo dia das mães, estarão aberto durante ...   \n",
       "2                                                                                                                                 Joint burguer e brewdog   \n",
       "3                                                            Agora de segunda a sexta o Habanero vai abrir no almoço com pratos mexicanos e tradicionais!   \n",
       "4                                                                                                           Experimente o drink \"Dona Diabla\". Muito bom!   \n",
       "5                                                                                                                          Nova senha do Wifi: 1129508219   \n",
       "6                                                                                                                                        Wi-fi 1129508219   \n",
       "7                     Adoramos a pizza carbonara e a paulistana. Não surpreendeu tanto, mas vale a pena por resgatar o tradicionalismo. Dica @Gourmet_For   \n",
       "8                                                                     O diferencial desse Burger King é que você mesmo serve o refrigerante, e a vontade!   \n",
       "9                                                                                                                      Unico defeito estacionamento pago!   \n",
       "10                                                                                                                                             24h é 24h.   \n",
       "11  Excelente Burger King: bom atendimento, ambiente agradável e refil para refrigerante. Evite o inconveniente estacionamento pago estacionando ao re...   \n",
       "12                                                                                                              o atendimento aqui é simplesmente um lixo   \n",
       "13                                                                                                                    O Drive-Truh mais lento da cidade!!   \n",
       "14                                                                                                              Cheio de bêbados depois das 2 da manhã :D   \n",
       "15  Recinto sujo, sem manutenção. Não há segurança pra conter a briga que ocorreu agora há pouco. O refrigerante está aguado, sem gosto, horrível. O l...   \n",
       "\n",
       "    rotulo  \n",
       "0     -1.0  \n",
       "1      0.0  \n",
       "2      0.0  \n",
       "3      0.0  \n",
       "4      1.0  \n",
       "5      0.0  \n",
       "6      0.0  \n",
       "7      1.0  \n",
       "8      1.0  \n",
       "9     -1.0  \n",
       "10     0.0  \n",
       "11     1.0  \n",
       "12    -1.0  \n",
       "13    -1.0  \n",
       "14    -1.0  \n",
       "15    -1.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('docs/tips_scenario1_train.csv')\n",
    "df.head(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def splitWithPunctuation(text):\n",
    "    return re.findall(r\"[\\w']+|[.,!?;:\\\"]\", text)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mas', 'que', ':', '\"', 'legal', '\"']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitWithPunctuation('mas que: \"legal\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1714, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline: Bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df['texto'].astype(str).tolist()\n",
    "categs = df['rotulo'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(texts, categs, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "countVec = CountVectorizer()\n",
    "vectTexts_train = countVec.fit_transform(X_train)\n",
    "vectTexts_test = countVec.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1542x4781 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 25423 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectTexts_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "mnb.fit(vectTexts_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9137483787289234"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb.score(vectTexts_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7790697674418605"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb.score(vectTexts_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embedding Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Embeddings import WordEmbeddingBR, splitWithPunctuation\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading NILC word embeddings. More available at http://nilc.icmc.usp.br/embeddings\n",
      "Downloading glove50 from http://143.107.183.175:22980/download.php?file=embeddings/glove/glove_s50.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "178KKB [1:15:44, 39.2KB/s]                                                                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading cbow50_wang2vec from http://143.107.183.175:22980/download.php?file=embeddings/wang2vec/cbow_s50.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "179KKB [50:24, 59.3KB/s]                                                                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading cbow50_fasttext from http://143.107.183.175:22980/download.php?file=embeddings/fasttext/cbow_s50.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▍                                                    | 1.29K/155K [00:25<44:31, 57.4KB/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-79c5ebc22701>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mWordEmbeddingBR\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdownloadNILCEmbeddings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mWordEmbeddingBR\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetAvailableEmbeddings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\py\\TextClassification\\Embeddings.py\u001b[0m in \u001b[0;36mdownloadNILCEmbeddings\u001b[1;34m()\u001b[0m\n\u001b[0;32m     73\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdestFile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Downloading {} from {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNILCfiles\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m                 \u001b[0m_downloadFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNILCfiles\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdestFile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'{} exists. Skipping.'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\py\\TextClassification\\Embeddings.py\u001b[0m in \u001b[0;36m_downloadFile\u001b[1;34m(url, filename)\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[0mwrote\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miter_content\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblock_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal_size\u001b[0m\u001b[1;33m//\u001b[0m\u001b[0mblock_size\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0munit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'KB'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munit_scale\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m             \u001b[0mwrote\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwrote\u001b[0m  \u001b[1;33m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m             \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tqdm\\_tqdm.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    831\u001b[0m \"\"\", fp_write=getattr(self.fp, 'write', sys.stderr.write))\n\u001b[0;32m    832\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 833\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    834\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    835\u001b[0m                 \u001b[1;31m# Update and print the progressbar.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\requests\\models.py\u001b[0m in \u001b[0;36mgenerate\u001b[1;34m()\u001b[0m\n\u001b[0;32m    743\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'stream'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    744\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 745\u001b[1;33m                     \u001b[1;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    746\u001b[0m                         \u001b[1;32myield\u001b[0m \u001b[0mchunk\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    747\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mProtocolError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\urllib3\\response.py\u001b[0m in \u001b[0;36mstream\u001b[1;34m(self, amt, decode_content)\u001b[0m\n\u001b[0;32m    434\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    435\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_fp_closed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 436\u001b[1;33m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mamt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecode_content\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    437\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\urllib3\\response.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[0;32m    382\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m                 \u001b[0mcache_content\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 384\u001b[1;33m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    385\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mamt\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Platform-specific: Buggy versions of Python.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m                     \u001b[1;31m# Close the connection when no data is returned\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    447\u001b[0m             \u001b[1;31m# Amount is given, implement using readinto\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m             \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 449\u001b[1;33m             \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    450\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    491\u001b[0m         \u001b[1;31m# connection, and the user is reading more bytes than will be provided\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    492\u001b[0m         \u001b[1;31m# (for example, reading in 1k chunks)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 493\u001b[1;33m         \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    494\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m             \u001b[1;31m# Ideally, we would raise IncompleteRead if the content-length\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    584\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▍                                                  | 1.29K/155K [00:40<1:19:10, 32.3KB/s]"
     ]
    }
   ],
   "source": [
    "WordEmbeddingBR.downloadNILCEmbeddings()\n",
    "WordEmbeddingBR.getAvailableEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading embedding file: cbow50_wang2vec.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "934967it [00:53, 17362.67it/s]\n"
     ]
    }
   ],
   "source": [
    "wee = WordEmbeddingBR('cbow50_wang2vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = max([len(x) for x in X_train])\n",
    "def getSentenceVector(x, emb):\n",
    "    wordArray = splitWithPunctuation(x)\n",
    "    ans = np.zeros( (maxlen, emb.embDim) )\n",
    "    for i,w in enumerate(wordArray):\n",
    "        ans[i] = emb.encodeWord(w.lower())\n",
    "        ans[i] /= (np.linalg.norm(ans[i])+1e-4)\n",
    "        \n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Muito caro pelo tamanho e sabor. Fomos em dois e gastamos R$60,00. Para fast food de tamanho normal, foi muito.'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-5.05464027e-02,  2.78965577e-02, -5.00163159e-03,\n",
       "        -1.22586421e-01,  1.40743375e-01, -2.89156209e-01,\n",
       "        -9.89202798e-02, -7.40342671e-02, -1.33117794e-01,\n",
       "        -1.21884777e-01,  2.06737795e-02,  5.87740136e-02,\n",
       "         2.26668426e-02, -2.09829375e-01,  3.32079798e-01,\n",
       "         1.62030253e-02,  7.72076725e-02,  3.35773012e-02,\n",
       "         2.33533860e-01,  4.39359321e-02, -4.30212260e-02,\n",
       "         5.66354830e-02,  2.75821028e-01, -7.38374116e-02,\n",
       "         7.16115215e-02,  1.02926170e-01, -7.39445357e-02,\n",
       "         6.39970088e-02,  2.45025793e-01, -9.81186273e-02,\n",
       "         9.45985507e-02,  8.40323915e-02, -1.05096324e-02,\n",
       "         6.17323800e-02,  2.47888104e-01, -3.83512445e-03,\n",
       "         8.51099579e-02,  6.55252082e-02,  4.06108531e-01,\n",
       "        -1.97363047e-01, -1.65714771e-01,  1.85374626e-01,\n",
       "        -1.17492686e-01,  1.13006911e-01,  1.08819976e-02,\n",
       "        -7.86623476e-02, -1.27782931e-01,  1.15749448e-01,\n",
       "         4.12016962e-02,  5.72331647e-02],\n",
       "       [-2.48460687e-01, -3.25266708e-01,  2.65903340e-02,\n",
       "        -2.46754519e-01, -1.59670248e-01, -1.58305314e-01,\n",
       "        -1.54423502e-01, -3.35871193e-02, -6.06461805e-02,\n",
       "         5.37832637e-02,  1.28835120e-01, -3.27959077e-03,\n",
       "        -1.19697938e-01, -2.23226287e-01,  6.13995189e-03,\n",
       "         8.35455687e-02,  4.44807154e-02,  3.23849276e-02,\n",
       "         3.71794074e-01, -7.32268197e-02, -7.81930785e-02,\n",
       "         4.97342103e-02, -2.03019643e-01, -7.57725711e-03,\n",
       "        -2.01409096e-01,  1.24348838e-01,  8.25709910e-03,\n",
       "         2.58506074e-01, -4.24329398e-02, -3.98193167e-02,\n",
       "         8.91950444e-02, -5.45261026e-03, -1.08145499e-01,\n",
       "        -3.54275299e-02,  9.49918879e-02,  1.83616960e-01,\n",
       "         1.26629102e-01, -2.51069435e-01,  1.25836015e-01,\n",
       "         6.75090973e-02,  1.10646253e-01,  6.27734522e-02,\n",
       "        -1.13731978e-02,  5.34517798e-02, -1.17444298e-02,\n",
       "        -5.59026608e-02, -1.26546606e-01, -1.02619393e-01,\n",
       "        -1.98994588e-01,  1.62511485e-01],\n",
       "       [-1.36011679e-01, -1.41054828e-01,  8.72888395e-02,\n",
       "        -3.74233771e-02, -6.07556522e-02,  4.30925324e-02,\n",
       "         5.26192761e-02, -2.06851244e-04, -1.40541960e-01,\n",
       "         3.92271404e-01,  5.53352636e-02, -1.04720572e-02,\n",
       "         8.59267564e-02, -1.59558302e-01, -5.23330239e-03,\n",
       "         3.02717083e-01,  1.84576739e-01,  1.51145556e-01,\n",
       "         5.47975185e-02,  2.08435854e-01, -1.40518105e-01,\n",
       "        -4.57730792e-03,  1.57727992e-01,  9.39520394e-03,\n",
       "        -3.73068316e-02,  1.13796469e-01, -5.55850526e-02,\n",
       "         1.16634113e-01,  1.14786424e-01,  2.77034133e-02,\n",
       "         1.02001518e-01,  1.27887911e-01,  1.26994396e-01,\n",
       "         2.06095402e-01, -3.85758827e-03, -2.18581447e-01,\n",
       "         3.57804943e-02,  8.31405690e-02,  1.01852939e-01,\n",
       "        -1.59270005e-01,  1.22709815e-01,  2.45814589e-01,\n",
       "        -1.59698020e-01,  3.51224552e-02,  9.45749786e-02,\n",
       "        -2.42177143e-01,  3.43945569e-03, -1.88945491e-01,\n",
       "        -1.11853362e-01,  2.33865267e-01],\n",
       "       [-2.21647784e-01, -1.54377828e-01,  2.23933798e-01,\n",
       "        -1.83702320e-01,  1.48007350e-01,  4.65791196e-02,\n",
       "        -1.59826880e-01, -1.31455104e-01,  3.87586346e-02,\n",
       "         3.03448686e-02,  2.28133703e-01, -5.42499100e-02,\n",
       "        -3.60349543e-02,  1.77536087e-01,  3.21182843e-01,\n",
       "        -3.51625817e-02,  1.72490450e-01, -1.65112283e-01,\n",
       "         1.49952111e-01,  2.22774299e-02, -1.56545862e-01,\n",
       "        -1.01302217e-01, -6.70132763e-02, -2.40284337e-01,\n",
       "        -1.01930173e-01, -2.03698388e-01, -1.70691155e-01,\n",
       "         5.02018131e-02,  1.97013298e-02, -3.02674841e-02,\n",
       "         4.84004037e-02, -8.65721003e-02, -5.42989624e-02,\n",
       "        -1.66979659e-01,  1.94530229e-01, -4.14345311e-02,\n",
       "        -1.45174571e-01, -5.42723219e-02,  8.46696259e-02,\n",
       "         1.02100165e-01, -5.81195573e-02,  4.69093780e-02,\n",
       "        -4.29788379e-02,  5.53633163e-02,  3.46947649e-01,\n",
       "         9.03115049e-02,  2.11258810e-01, -9.84136186e-03,\n",
       "         3.58146411e-02,  1.13276515e-01],\n",
       "       [-3.80982085e-02, -2.02741102e-01, -1.31272826e-01,\n",
       "         8.20189102e-02, -2.03289283e-01,  1.46378243e-01,\n",
       "        -1.88074765e-02,  2.54750645e-01,  3.87862787e-02,\n",
       "        -9.12248617e-02,  1.59872586e-01, -4.86649059e-02,\n",
       "         8.21835651e-02, -1.43985392e-01,  2.45438271e-01,\n",
       "         4.09689607e-02,  1.27114954e-01,  8.66747629e-02,\n",
       "         1.67119411e-01, -7.91655605e-02, -2.60783977e-01,\n",
       "        -1.10454015e-01,  1.50098374e-01,  1.83884765e-01,\n",
       "        -3.14892536e-02,  1.08798095e-01,  5.97108429e-02,\n",
       "         2.45782975e-01,  3.15337640e-01, -2.50155032e-02,\n",
       "        -1.81254971e-01, -7.67144776e-02, -1.58268873e-01,\n",
       "         3.43445443e-01,  4.26295660e-02, -8.75890664e-02,\n",
       "        -2.90830157e-02, -1.91160371e-02, -4.84078835e-02,\n",
       "        -8.19660332e-02, -6.57602387e-02,  2.96004071e-02,\n",
       "         5.29392411e-02,  9.75212399e-02,  2.20728651e-01,\n",
       "        -5.18783546e-02, -8.75622932e-02,  5.98313221e-02,\n",
       "         7.45291183e-02, -1.40253213e-01],\n",
       "       [-1.95556714e-01, -1.46413094e-01,  1.65806605e-01,\n",
       "         3.20187012e-02,  5.20690285e-02, -2.62260733e-01,\n",
       "        -1.08701347e-01, -2.04105552e-01,  9.27625591e-02,\n",
       "        -3.45230058e-02,  1.35915749e-01, -2.21937230e-01,\n",
       "        -5.46819198e-02, -2.60980394e-01,  1.74106866e-01,\n",
       "        -2.51107706e-02,  1.89573851e-01, -1.37998949e-01,\n",
       "         1.67965475e-01, -9.01610183e-03,  1.93178400e-02,\n",
       "        -2.50033189e-02, -3.01980767e-02, -3.21923264e-01,\n",
       "         2.04687456e-01, -6.16208752e-02, -7.63216993e-02,\n",
       "         2.62119608e-01, -9.94192647e-03,  4.57918088e-03,\n",
       "         5.35884857e-02,  7.47243018e-04, -4.81016411e-02,\n",
       "        -1.07847788e-01,  3.23603899e-01, -6.70040518e-02,\n",
       "         1.13400844e-01,  1.17435199e-01, -2.66642793e-02,\n",
       "         1.85296216e-01,  9.72967162e-02,  1.15221468e-01,\n",
       "         3.60481382e-02,  2.97516226e-02,  2.43616358e-01,\n",
       "        -4.57388397e-02,  7.86406119e-02,  1.06798242e-01,\n",
       "         2.19761334e-02,  7.65532500e-02],\n",
       "       [-1.27322126e-01, -1.97335063e-01, -1.64654860e-01,\n",
       "         5.27609173e-02, -2.35155479e-01,  1.99869502e-01,\n",
       "        -6.14973586e-02,  2.07911802e-01, -2.17063219e-02,\n",
       "         2.07323291e-02,  1.08455474e-01, -4.68435679e-02,\n",
       "        -2.65927479e-03,  3.00833462e-02,  6.32073334e-02,\n",
       "         8.05320594e-02,  1.83759524e-01,  5.64058454e-02,\n",
       "         1.04257702e-01, -2.79618252e-02, -2.14785997e-01,\n",
       "         3.57510242e-02,  8.84954797e-02,  1.27865367e-01,\n",
       "         1.51517617e-03,  1.59201872e-01,  8.70571255e-02,\n",
       "         1.00504400e-01,  3.62558543e-01, -8.43848184e-02,\n",
       "        -3.04708856e-02, -1.16272795e-01, -2.47784462e-01,\n",
       "         1.82833544e-01,  9.57565276e-02, -4.91475411e-02,\n",
       "        -1.12160076e-02, -1.75436000e-01, -1.19272967e-02,\n",
       "        -2.10606058e-01, -1.70125682e-01,  2.05072819e-01,\n",
       "        -3.83211306e-02,  1.06445070e-01,  2.98210540e-01,\n",
       "        -2.29526212e-02, -1.80755236e-01, -1.94832862e-02,\n",
       "         2.04784051e-01, -4.46253335e-03],\n",
       "       [ 1.52370642e-01, -5.45172425e-02,  5.24317877e-02,\n",
       "        -2.12055410e-01,  1.95047629e-02, -1.30951566e-01,\n",
       "        -1.01169808e-01,  1.45452689e-02,  8.00289136e-02,\n",
       "        -1.03090168e-01,  9.69003248e-02,  1.52182869e-01,\n",
       "        -2.33370167e-02, -1.82273046e-01, -4.14206345e-02,\n",
       "         2.33016393e-01,  4.88248005e-02,  1.01352440e-01,\n",
       "        -4.22678789e-02,  1.35734475e-02, -4.20840371e-03,\n",
       "         1.21160481e-01, -5.87516501e-02, -1.24111927e-01,\n",
       "        -7.66199796e-02,  2.12634753e-01, -8.28406643e-02,\n",
       "        -2.35339511e-01,  2.89659608e-02, -7.72767300e-02,\n",
       "        -1.01743104e-01,  1.00087318e-01, -3.48013942e-01,\n",
       "         1.92394623e-01, -8.02750438e-02,  2.17638998e-01,\n",
       "        -1.05692073e-01,  4.42992093e-02,  4.18823857e-01,\n",
       "        -2.37276804e-01,  7.45705069e-02,  2.21053072e-01,\n",
       "         2.39825794e-02, -6.11784822e-02,  1.05562960e-01,\n",
       "        -5.82612039e-02,  3.93533219e-02, -2.07599061e-02,\n",
       "        -1.57035626e-01, -1.15312620e-01],\n",
       "       [-1.51131490e-02,  4.92760240e-02, -1.24736242e-01,\n",
       "         3.65948480e-02, -1.24210069e-02,  1.59352346e-01,\n",
       "         1.40272470e-01,  9.22292098e-02, -2.20031071e-01,\n",
       "        -1.14556094e-01,  1.01668241e-01,  6.39038482e-02,\n",
       "        -4.62138096e-02, -8.85109803e-02,  1.60169326e-01,\n",
       "         3.19844088e-01,  2.89232642e-01,  1.49157123e-02,\n",
       "        -1.63897768e-01,  8.70136708e-02,  6.32930587e-02,\n",
       "         8.45816977e-03,  2.33374584e-01, -3.59125729e-02,\n",
       "         1.81367027e-01, -9.85768491e-02, -6.70866643e-02,\n",
       "         2.01027057e-01,  6.24809422e-02,  1.01796624e-01,\n",
       "         2.00101146e-01, -2.88996788e-02, -2.89395066e-01,\n",
       "        -1.35934698e-01, -5.73539092e-02, -1.06529756e-01,\n",
       "         1.40710624e-01, -4.04609120e-02, -1.19146741e-01,\n",
       "        -2.02758761e-01, -1.26981964e-01,  1.03421830e-01,\n",
       "        -9.44715269e-02,  1.70013443e-01,  2.74345135e-01,\n",
       "         1.50324236e-02, -3.09854081e-02, -1.28474896e-02,\n",
       "        -1.20295861e-01,  2.06351526e-01],\n",
       "       [ 2.37493722e-01, -1.77764210e-01, -7.22147304e-03,\n",
       "        -8.76707180e-02,  1.39055886e-01,  2.60825551e-03,\n",
       "        -6.03877202e-02, -5.86369786e-02, -7.67937702e-02,\n",
       "         1.06414674e-01,  1.17905284e-02,  2.08456527e-01,\n",
       "        -6.23730972e-02, -1.55807169e-01, -5.85663191e-02,\n",
       "        -1.08791751e-01,  2.09635848e-02, -6.54629123e-02,\n",
       "        -4.72227886e-03,  8.26120387e-02,  1.32713432e-01,\n",
       "        -1.19325769e-01,  1.40946410e-01, -3.22560793e-01,\n",
       "        -2.04648213e-01,  8.88822972e-02,  4.64516789e-02,\n",
       "         2.27847171e-01, -1.51777660e-01,  9.05623793e-02,\n",
       "         1.48179020e-01,  8.44150068e-03, -6.39095563e-02,\n",
       "         4.14157335e-01, -5.52153713e-02,  4.95253651e-02,\n",
       "        -5.73800851e-02, -2.78901315e-02,  1.08332080e-01,\n",
       "        -3.25791159e-01, -1.66483659e-01,  2.23641013e-02,\n",
       "        -1.20547333e-02,  1.49525390e-02,  1.73857971e-01,\n",
       "         1.75376766e-01, -8.53643012e-02, -6.13324064e-02,\n",
       "        -1.82300624e-01,  1.10193803e-01]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getSentenceVector(X_train[2], wee)[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.13147829, -0.15114349, -0.08199338, ..., -0.17250816,\n",
       "        -0.00402809, -0.11158497],\n",
       "       [ 0.09640924,  0.04780224,  0.0055655 , ...,  0.07664581,\n",
       "         0.07899589,  0.08604658],\n",
       "       [-0.23149888, -0.06592918,  0.06388329, ..., -0.07717097,\n",
       "         0.29113467, -0.15354034],\n",
       "       ...,\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectTexts_train = [getSentenceVector(x, wee).reshape((-1,)) for x in X_train]\n",
    "vectTexts_test = [getSentenceVector(x, wee).reshape((-1,)) for x in X_test]\n",
    "getSentenceVector(X_train[0], wee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1        1436.2329           25.22m\n",
      "         2        1427.9516           25.29m\n",
      "         3        1419.7201           25.37m\n",
      "         4        1411.7423           25.33m\n",
      "         5        1403.7663           25.33m\n",
      "         6        1395.9774           25.32m\n",
      "         7        1388.3512           25.26m\n",
      "         8        1380.7659           25.40m\n",
      "         9        1373.4924           26.28m\n",
      "        10        1366.1588           26.48m\n",
      "        20        1295.3412           28.30m\n",
      "        30        1228.3983           27.99m\n",
      "        40        1170.1145           26.97m\n",
      "        50        1117.3483           26.29m\n",
      "        60        1069.6253           25.72m\n",
      "        70        1026.0009           25.20m\n",
      "        80         987.7744           24.82m\n",
      "        90         951.8734           24.52m\n",
      "       100         918.2048           24.46m\n",
      "       200         700.3390           20.65m\n",
      "       300         573.0794           16.70m\n",
      "       400         483.7820           13.20m\n",
      "       500         417.9905            9.86m\n",
      "       600         366.6526            6.56m\n",
      "       700         325.8843           36.66m\n"
     ]
    }
   ],
   "source": [
    "#try some of scikit learn classifiers\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "gbc = GradientBoostingClassifier(verbose=1, learning_rate=0.01, n_estimators=800, max_depth=4)\n",
    "gbc.fit(vectTexts_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train score: {} Test score: {}'.format(gbc.score(vectTexts_train, y_train),gbc.score(vectTexts_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         911.6240            4.97s\n",
      "         2         868.0945            5.63s\n",
      "         3         830.5351            6.06s\n",
      "         4         797.2125            5.87s\n",
      "         5         768.6529            5.90s\n",
      "         6         742.6890            6.02s\n",
      "         7         721.1076            5.85s\n",
      "         8         699.8268            5.76s\n",
      "         9         681.4205            5.76s\n",
      "        10         662.7929            5.67s\n",
      "        20         543.6652            4.74s\n",
      "        30         464.4371            4.22s\n",
      "        40         404.8558            3.91s\n",
      "        50         359.7200            3.84s\n",
      "        60         322.4471            3.53s\n",
      "        70         290.7074            3.25s\n",
      "        80         262.9695            3.01s\n",
      "        90         235.9893            2.70s\n",
      "       100         213.4610            2.43s\n",
      "       200          91.1978            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         912.1014            6.26s\n",
      "         2         870.6646            5.68s\n",
      "         3         834.7010            5.80s\n",
      "         4         802.1413            5.77s\n",
      "         5         774.1548            5.86s\n",
      "         6         749.2447            5.73s\n",
      "         7         727.0479            5.66s\n",
      "         8         706.2973            5.67s\n",
      "         9         687.3436            5.54s\n",
      "        10         670.3964            5.63s\n",
      "        20         550.0531            4.83s\n",
      "        30         471.0479            4.28s\n",
      "        40         415.8290            3.97s\n",
      "        50         370.3052            3.68s\n",
      "        60         333.3926            3.37s\n",
      "        70         299.3120            3.10s\n",
      "        80         272.3953            2.82s\n",
      "        90         248.3483            2.56s\n",
      "       100         222.9344            2.33s\n",
      "       200          98.2157            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         911.3387            5.46s\n",
      "         2         865.8295            5.53s\n",
      "         3         826.2691            5.67s\n",
      "         4         791.8012            5.48s\n",
      "         5         761.2409            5.41s\n",
      "         6         734.5670            5.45s\n",
      "         7         710.7416            5.44s\n",
      "         8         689.4242            5.46s\n",
      "         9         669.4121            5.38s\n",
      "        10         649.5216            5.50s\n",
      "        20         514.2484            4.69s\n",
      "        30         431.7223            4.17s\n",
      "        40         379.5413            3.83s\n",
      "        50         336.8145            3.52s\n",
      "        60         301.1625            3.23s\n",
      "        70         273.4312            3.02s\n",
      "        80         247.6890            2.75s\n",
      "        90         227.0576            2.52s\n",
      "       100         206.9176            2.29s\n",
      "       200          89.9607            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         961.1552            8.84s\n",
      "         2         960.3869            9.63s\n",
      "         3         959.6201            9.21s\n",
      "         4         958.8550            9.00s\n",
      "         5         958.0913            9.01s\n",
      "         6         957.3369            9.28s\n",
      "         7         956.5763            9.36s\n",
      "         8         955.8173            9.50s\n",
      "         9         955.0597            9.48s\n",
      "        10         954.3037            9.53s\n",
      "        20         946.9215            9.31s\n",
      "        30         939.7038            8.03s\n",
      "        40         932.5584            7.31s\n",
      "        50         925.5250            6.63s\n",
      "        60         918.6246            6.05s\n",
      "        70         911.8893            5.52s\n",
      "        80         905.2177            5.06s\n",
      "        90         898.5364            4.59s\n",
      "       100         891.8355            4.16s\n",
      "       200         829.3784            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         961.1471            8.54s\n",
      "         2         960.3696            8.50s\n",
      "         3         959.5937            8.72s\n",
      "         4         958.8193            8.71s\n",
      "         5         958.0464            9.01s\n",
      "         6         957.2751            9.05s\n",
      "         7         956.5052            8.96s\n",
      "         8         955.7369            9.10s\n",
      "         9         954.9712            9.03s\n",
      "        10         954.2058            9.11s\n",
      "        20         946.6310            7.73s\n",
      "        30         939.2002            7.01s\n",
      "        40         932.0565            6.52s\n",
      "        50         925.0282            6.00s\n",
      "        60         918.1372            5.55s\n",
      "        70         911.3751            5.12s\n",
      "        80         904.7633            4.70s\n",
      "        90         898.2609            4.29s\n",
      "       100         891.8416            3.91s\n",
      "       200         832.4726            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         964.8241           11.22s\n",
      "         2         963.9469           10.38s\n",
      "         3         963.0715           10.49s\n",
      "         4         962.1980           10.27s\n",
      "         5         961.3265           10.12s\n",
      "         6         960.4565            9.99s\n",
      "         7         959.5885            9.78s\n",
      "         8         958.7218            9.68s\n",
      "         9         957.8572            9.54s\n",
      "        10         956.9940            9.43s\n",
      "        20         948.4552            8.06s\n",
      "        30         940.0800            7.24s\n",
      "        40         931.8599            6.62s\n",
      "        50         923.8008            6.14s\n",
      "        60         915.9030            5.72s\n",
      "        70         908.1714            5.27s\n",
      "        80         900.5517            4.84s\n",
      "        90         893.0544            4.41s\n",
      "       100         885.7096            4.00s\n",
      "       200         818.1557            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         961.1552            0.36s\n",
      "         2         960.3869            0.33s\n",
      "         3         959.6201            0.30s\n",
      "         4         958.8550            0.26s\n",
      "         5         958.0913            0.22s\n",
      "         6         957.3369            0.17s\n",
      "         7         956.5763            0.13s\n",
      "         8         955.8173            0.09s\n",
      "         9         955.0597            0.05s\n",
      "        10         954.3037            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         961.1471            0.41s\n",
      "         2         960.3696            0.35s\n",
      "         3         959.5937            0.31s\n",
      "         4         958.8193            0.28s\n",
      "         5         958.0464            0.23s\n",
      "         6         957.2751            0.19s\n",
      "         7         956.5052            0.15s\n",
      "         8         955.7369            0.10s\n",
      "         9         954.9712            0.05s\n",
      "        10         954.2058            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         964.8241            0.45s\n",
      "         2         963.9469            0.41s\n",
      "         3         963.0715            0.34s\n",
      "         4         962.1980            0.31s\n",
      "         5         961.3265            0.26s\n",
      "         6         960.4565            0.21s\n",
      "         7         959.5885            0.16s\n",
      "         8         958.7218            0.10s\n",
      "         9         957.8572            0.05s\n",
      "        10         956.9940            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         961.2794            2.01s\n",
      "         2         960.6352            1.76s\n",
      "         3         959.9922            1.75s\n",
      "         4         959.3505            1.72s\n",
      "         5         958.7086            1.71s\n",
      "         6         958.0694            1.67s\n",
      "         7         957.4316            1.59s\n",
      "         8         956.7951            1.60s\n",
      "         9         956.1583            1.55s\n",
      "        10         955.5243            1.52s\n",
      "        20         949.2608            1.05s\n",
      "        30         943.1097            0.68s\n",
      "        40         937.0764            0.33s\n",
      "        50         931.1529            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         961.2830            1.93s\n",
      "         2         960.6423            1.71s\n",
      "         3         960.0028            1.85s\n",
      "         4         959.3645            1.77s\n",
      "         5         958.7274            1.73s\n",
      "         6         958.0916            1.68s\n",
      "         7         957.4570            1.63s\n",
      "         8         956.8236            1.61s\n",
      "         9         956.1915            1.56s\n",
      "        10         955.5605            1.53s\n",
      "        20         949.3172            1.03s\n",
      "        30         943.2407            0.66s\n",
      "        40         937.2984            0.32s\n",
      "        50         931.4663            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         964.9947            1.81s\n",
      "         2         964.2877            1.89s\n",
      "         3         963.5820            1.75s\n",
      "         4         962.8777            1.73s\n",
      "         5         962.1747            1.73s\n",
      "         6         961.4731            1.70s\n",
      "         7         960.7728            1.66s\n",
      "         8         960.0738            1.64s\n",
      "         9         959.3762            1.58s\n",
      "        10         958.6798            1.57s\n",
      "        20         951.7884            1.06s\n",
      "        30         945.0176            0.67s\n",
      "        40         938.3665            0.33s\n",
      "        50         931.8419            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         961.1552            2.08s\n",
      "         2         960.3869            2.10s\n",
      "         3         959.6201            2.06s\n",
      "         4         958.8550            1.99s\n",
      "         5         958.0913            1.98s\n",
      "         6         957.3369            1.95s\n",
      "         7         956.5763            1.94s\n",
      "         8         955.8173            1.90s\n",
      "         9         955.0597            1.87s\n",
      "        10         954.3037            1.85s\n",
      "        20         946.9215            1.29s\n",
      "        30         939.7038            0.83s\n",
      "        40         932.5584            0.41s\n",
      "        50         925.5250            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         961.1471            1.98s\n",
      "         2         960.3696            2.13s\n",
      "         3         959.5937            2.09s\n",
      "         4         958.8193            2.07s\n",
      "         5         958.0464            2.07s\n",
      "         6         957.2751            2.01s\n",
      "         7         956.5052            1.97s\n",
      "         8         955.7369            1.93s\n",
      "         9         954.9712            1.89s\n",
      "        10         954.2058            1.84s\n",
      "        20         946.6310            1.25s\n",
      "        30         939.2002            0.81s\n",
      "        40         932.0565            0.40s\n",
      "        50         925.0282            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         964.8241            2.69s\n",
      "         2         963.9469            2.59s\n",
      "         3         963.0715            2.47s\n",
      "         4         962.1980            2.33s\n",
      "         5         961.3265            2.27s\n",
      "         6         960.4565            2.29s\n",
      "         7         959.5885            2.19s\n",
      "         8         958.7218            2.11s\n",
      "         9         957.8572            2.10s\n",
      "        10         956.9940            2.05s\n",
      "        20         948.4552            1.35s\n",
      "        30         940.0800            0.86s\n",
      "        40         931.8599            0.42s\n",
      "        50         923.8008            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         956.5908            5.07s\n",
      "         2         951.3595            5.53s\n",
      "         3         946.2285            5.73s\n",
      "         4         941.1940            5.53s\n",
      "         5         936.2444            5.49s\n",
      "         6         931.2333            5.62s\n",
      "         7         926.4685            5.56s\n",
      "         8         921.6398            5.74s\n",
      "         9         916.8947            5.69s\n",
      "        10         912.2808            5.69s\n",
      "        20         869.8568            4.76s\n",
      "        30         832.6939            4.22s\n",
      "        40         799.8981            3.89s\n",
      "        50         771.1159            3.59s\n",
      "        60         745.6144            3.30s\n",
      "        70         722.9088            3.06s\n",
      "        80         702.4660            2.80s\n",
      "        90         684.1165            2.55s\n",
      "       100         667.0324            2.31s\n",
      "       200         544.4199            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         956.6179            4.97s\n",
      "         2         951.4119            4.94s\n",
      "         3         946.3112            5.28s\n",
      "         4         941.2971            5.31s\n",
      "         5         936.3762            5.74s\n",
      "         6         931.5512            5.71s\n",
      "         7         926.8022            5.56s\n",
      "         8         922.1778            5.53s\n",
      "         9         917.6420            5.53s\n",
      "        10         913.1134            5.54s\n",
      "        20         871.7499            4.83s\n",
      "        30         835.6367            4.26s\n",
      "        40         804.7803            3.95s\n",
      "        50         777.5863            3.64s\n",
      "        60         752.3521            3.33s\n",
      "        70         729.9531            3.07s\n",
      "        80         709.4291            2.80s\n",
      "        90         690.5371            2.56s\n",
      "       100         673.1536            2.32s\n",
      "       200         553.4519            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         959.9412            5.56s\n",
      "         2         954.2871            5.39s\n",
      "         3         948.7378            5.80s\n",
      "         4         943.2756            5.65s\n",
      "         5         937.9129            5.61s\n",
      "         6         932.6485            5.57s\n",
      "         7         927.4816            5.49s\n",
      "         8         922.4076            5.58s\n",
      "         9         917.4729            5.58s\n",
      "        10         912.5743            5.59s\n",
      "        20         867.9073            4.67s\n",
      "        30         829.2139            4.16s\n",
      "        40         795.6715            3.79s\n",
      "        50         765.9034            3.52s\n",
      "        60         739.5754            3.24s\n",
      "        70         715.8800            2.98s\n",
      "        80         694.2672            2.75s\n",
      "        90         674.3163            2.51s\n",
      "       100         655.6269            2.28s\n",
      "       200         519.5930            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         889.8738            8.94s\n",
      "         2         826.4671            9.58s\n",
      "         3         774.6331           10.00s\n",
      "         4         720.9016            9.88s\n",
      "         5         674.6948            9.93s\n",
      "         6         633.5832            9.71s\n",
      "         7         599.6123            9.80s\n",
      "         8         568.2784            9.88s\n",
      "         9         540.5218            9.63s\n",
      "        10         514.6224            9.56s\n",
      "        20         328.1199            8.18s\n",
      "        30         223.3176            7.27s\n",
      "        40         158.1975            6.67s\n",
      "        50         114.9329            6.14s\n",
      "        60          86.2334            5.67s\n",
      "        70          66.2011            5.20s\n",
      "        80          51.5742            4.76s\n",
      "        90          39.7477            4.34s\n",
      "       100          30.9176            3.93s\n",
      "       200           4.4095            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         887.9191            9.43s\n",
      "         2         827.8419            9.54s\n",
      "         3         773.6574           10.16s\n",
      "         4         726.9251           10.34s\n",
      "         5         685.6357           10.39s\n",
      "         6         647.2112           10.36s\n",
      "         7         612.3154           10.15s\n",
      "         8         579.6204           10.17s\n",
      "         9         549.2962           10.14s\n",
      "        10         522.9105            9.97s\n",
      "        20         327.5483            8.33s\n",
      "        30         221.8836            7.41s\n",
      "        40         161.4127            6.80s\n",
      "        50         119.8689            6.25s\n",
      "        60          91.0806            5.75s\n",
      "        70          70.1445            5.26s\n",
      "        80          55.2659            4.84s\n",
      "        90          43.4654            4.40s\n",
      "       100          35.2963            3.98s\n",
      "       200           5.7783            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         883.6191            8.94s\n",
      "         2         816.3730            9.68s\n",
      "         3         755.8781            9.50s\n",
      "         4         705.3879            9.54s\n",
      "         5         659.8980            9.50s\n",
      "         6         618.0132            9.46s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         7         582.0981            9.44s\n",
      "         8         547.6361            9.45s\n",
      "         9         516.5319            9.47s\n",
      "        10         484.9291            9.42s\n",
      "        20         293.5168            8.17s\n",
      "        30         197.9318            7.39s\n",
      "        40         136.9017            6.80s\n",
      "        50         100.0028            6.27s\n",
      "        60          74.0695            5.74s\n",
      "        70          56.3086            5.26s\n",
      "        80          43.5444            4.82s\n",
      "        90          34.4314            4.40s\n",
      "       100          27.7283            3.97s\n",
      "       200           6.0209            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         961.2794            0.32s\n",
      "         2         960.6352            0.29s\n",
      "         3         959.9922            0.26s\n",
      "         4         959.3505            0.22s\n",
      "         5         958.7086            0.19s\n",
      "         6         958.0694            0.15s\n",
      "         7         957.4316            0.11s\n",
      "         8         956.7951            0.07s\n",
      "         9         956.1583            0.04s\n",
      "        10         955.5243            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         961.2830            0.31s\n",
      "         2         960.6423            0.32s\n",
      "         3         960.0028            0.27s\n",
      "         4         959.3645            0.24s\n",
      "         5         958.7274            0.20s\n",
      "         6         958.0916            0.17s\n",
      "         7         957.4570            0.13s\n",
      "         8         956.8236            0.09s\n",
      "         9         956.1915            0.04s\n",
      "        10         955.5605            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         964.9947            0.34s\n",
      "         2         964.2877            0.31s\n",
      "         3         963.5820            0.26s\n",
      "         4         962.8777            0.23s\n",
      "         5         962.1747            0.19s\n",
      "         6         961.4731            0.16s\n",
      "         7         960.7728            0.11s\n",
      "         8         960.0738            0.08s\n",
      "         9         959.3762            0.04s\n",
      "        10         958.6798            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         901.4579            7.75s\n",
      "         2         847.5345            7.31s\n",
      "         3         801.9457            7.28s\n",
      "         4         763.3406            7.56s\n",
      "         5         727.5919            7.43s\n",
      "         6         694.3284            7.42s\n",
      "         7         665.0378            7.46s\n",
      "         8         638.8759            7.44s\n",
      "         9         613.2872            7.29s\n",
      "        10         591.9112            7.23s\n",
      "        20         429.3189            6.13s\n",
      "        30         335.8106            5.62s\n",
      "        40         273.7892            5.13s\n",
      "        50         227.2166            4.72s\n",
      "        60         188.4180            4.40s\n",
      "        70         160.6335            4.11s\n",
      "        80         135.7805            3.76s\n",
      "        90         115.4352            3.41s\n",
      "       100          99.6387            3.07s\n",
      "       200          24.4668            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         901.5401            6.26s\n",
      "         2         852.2242            6.77s\n",
      "         3         808.9540            7.14s\n",
      "         4         771.5040            7.31s\n",
      "         5         735.3508            7.26s\n",
      "         6         704.4910            7.33s\n",
      "         7         673.4438            7.20s\n",
      "         8         647.4557            7.15s\n",
      "         9         623.3779            7.22s\n",
      "        10         600.2866            7.26s\n",
      "        20         437.8136            6.18s\n",
      "        30         345.0761            5.57s\n",
      "        40         275.7568            5.15s\n",
      "        50         227.1153            4.79s\n",
      "        60         190.7270            4.39s\n",
      "        70         160.0063            4.02s\n",
      "        80         134.5981            3.69s\n",
      "        90         116.9281            3.36s\n",
      "       100         101.7910            3.04s\n",
      "       200          26.2757            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         899.3410            7.55s\n",
      "         2         843.2361            8.65s\n",
      "         3         795.5941            8.06s\n",
      "         4         754.9369            7.87s\n",
      "         5         717.1660            7.88s\n",
      "         6         683.7273            7.78s\n",
      "         7         652.2127            7.79s\n",
      "         8         623.4060            7.95s\n",
      "         9         597.0922            7.75s\n",
      "        10         573.7031            7.80s\n",
      "        20         403.3156            6.58s\n",
      "        30         307.9806            5.78s\n",
      "        40         245.0551            5.27s\n",
      "        50         198.5072            4.84s\n",
      "        60         160.6375            4.45s\n",
      "        70         135.5173            4.06s\n",
      "        80         113.5749            3.69s\n",
      "        90          97.9035            3.39s\n",
      "       100          83.8197            3.06s\n",
      "       200          21.1847            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         954.2709            0.40s\n",
      "         2         946.8847            0.38s\n",
      "         3         939.6140            0.34s\n",
      "         4         932.4142            0.29s\n",
      "         5         925.4111            0.25s\n",
      "         6         918.5315            0.20s\n",
      "         7         911.7044            0.15s\n",
      "         8         905.0454            0.10s\n",
      "         9         898.3406            0.05s\n",
      "        10         891.7750            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         954.1897            0.35s\n",
      "         2         946.6052            0.34s\n",
      "         3         939.1364            0.34s\n",
      "         4         932.0134            0.29s\n",
      "         5         924.9424            0.24s\n",
      "         6         917.9883            0.19s\n",
      "         7         911.2283            0.14s\n",
      "         8         904.6282            0.10s\n",
      "         9         898.1010            0.05s\n",
      "        10         891.6579            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1         956.9659            0.39s\n",
      "         2         948.3994            0.37s\n",
      "         3         940.0013            0.32s\n",
      "         4         931.7604            0.30s\n",
      "         5         923.6700            0.25s\n",
      "         6         915.8451            0.19s\n",
      "         7         908.0044            0.15s\n",
      "         8         900.4461            0.10s\n",
      "         9         892.7824            0.05s\n",
      "        10         885.5152            0.00s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:  1.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1        1372.1220            6.95s\n",
      "         2        1310.2252            7.56s\n",
      "         3        1258.1945            7.70s\n",
      "         4        1214.3457            7.85s\n",
      "         5        1172.9817            7.80s\n",
      "         6        1137.6678            7.81s\n",
      "         7        1105.3929            7.75s\n",
      "         8        1077.6997            8.01s\n",
      "         9        1050.0682            7.95s\n",
      "        10        1025.6831            7.78s\n",
      "        20         862.7868            6.54s\n",
      "        30         758.8188            5.86s\n",
      "        40         686.2422            5.38s\n",
      "        50         625.1313            4.95s\n",
      "        60         576.0591            4.54s\n",
      "        70         526.6949            4.19s\n",
      "        80         487.6930            3.83s\n",
      "        90         452.2790            3.50s\n",
      "       100         423.9086            3.16s\n",
      "       200         217.7912            0.00s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=None, error_score='raise',\n",
       "          estimator=GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=2,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=200,\n",
       "              presort='auto', random_state=None, subsample=1.0, verbose=1,\n",
       "              warm_start=False),\n",
       "          fit_params=None, iid=True, n_iter=10, n_jobs=1,\n",
       "          param_distributions={'learning_rate': [0.1, 0.01, 0.001], 'n_estimators': [10, 50, 100, 200], 'max_depth': [3, 4, 5]},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=1)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbParams = { #'verbose' : [1],\n",
    "             'learning_rate':[0.1,0.01,0.001],  \n",
    "             'n_estimators' :[10, 50, 100, 200], \n",
    "             'max_depth'    :[3,4,5]}\n",
    "gbRSCV = RandomizedSearchCV(gbc, gbParams, verbose=1) #, n_jobs=-1)\n",
    "gbRSCV.fit(vectTexts_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dougl_000\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\dougl_000\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\dougl_000\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\dougl_000\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\dougl_000\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.373492</td>\n",
       "      <td>0.091101</td>\n",
       "      <td>0.011978</td>\n",
       "      <td>0.000705</td>\n",
       "      <td>200</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'n_estimators': 200, 'max_depth': 3, 'learning_rate': 0.1}</td>\n",
       "      <td>0.728155</td>\n",
       "      <td>0.741748</td>\n",
       "      <td>0.730469</td>\n",
       "      <td>0.733463</td>\n",
       "      <td>0.005942</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999026</td>\n",
       "      <td>0.998053</td>\n",
       "      <td>0.997087</td>\n",
       "      <td>0.998055</td>\n",
       "      <td>0.000792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.772204</td>\n",
       "      <td>0.248362</td>\n",
       "      <td>0.017135</td>\n",
       "      <td>0.000622</td>\n",
       "      <td>200</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.001}</td>\n",
       "      <td>0.689320</td>\n",
       "      <td>0.695146</td>\n",
       "      <td>0.689453</td>\n",
       "      <td>0.691310</td>\n",
       "      <td>0.002717</td>\n",
       "      <td>5</td>\n",
       "      <td>0.718598</td>\n",
       "      <td>0.706913</td>\n",
       "      <td>0.710680</td>\n",
       "      <td>0.712064</td>\n",
       "      <td>0.004870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.506870</td>\n",
       "      <td>0.017460</td>\n",
       "      <td>0.004325</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'n_estimators': 10, 'max_depth': 5, 'learning_rate': 0.001}</td>\n",
       "      <td>0.681553</td>\n",
       "      <td>0.681553</td>\n",
       "      <td>0.683594</td>\n",
       "      <td>0.682231</td>\n",
       "      <td>0.000961</td>\n",
       "      <td>6</td>\n",
       "      <td>0.682571</td>\n",
       "      <td>0.682571</td>\n",
       "      <td>0.681553</td>\n",
       "      <td>0.682232</td>\n",
       "      <td>0.000480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.604947</td>\n",
       "      <td>0.018219</td>\n",
       "      <td>0.005989</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'n_estimators': 50, 'max_depth': 4, 'learning_rate': 0.001}</td>\n",
       "      <td>0.681553</td>\n",
       "      <td>0.681553</td>\n",
       "      <td>0.683594</td>\n",
       "      <td>0.682231</td>\n",
       "      <td>0.000961</td>\n",
       "      <td>6</td>\n",
       "      <td>0.682571</td>\n",
       "      <td>0.682571</td>\n",
       "      <td>0.681553</td>\n",
       "      <td>0.682232</td>\n",
       "      <td>0.000480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.030638</td>\n",
       "      <td>0.043805</td>\n",
       "      <td>0.006654</td>\n",
       "      <td>0.000624</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'n_estimators': 50, 'max_depth': 5, 'learning_rate': 0.001}</td>\n",
       "      <td>0.681553</td>\n",
       "      <td>0.681553</td>\n",
       "      <td>0.683594</td>\n",
       "      <td>0.682231</td>\n",
       "      <td>0.000961</td>\n",
       "      <td>6</td>\n",
       "      <td>0.682571</td>\n",
       "      <td>0.682571</td>\n",
       "      <td>0.681553</td>\n",
       "      <td>0.682232</td>\n",
       "      <td>0.000480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.314938</td>\n",
       "      <td>0.017325</td>\n",
       "      <td>0.011146</td>\n",
       "      <td>0.000236</td>\n",
       "      <td>200</td>\n",
       "      <td>3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'n_estimators': 200, 'max_depth': 3, 'learning_rate': 0.01}</td>\n",
       "      <td>0.702913</td>\n",
       "      <td>0.720388</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.714008</td>\n",
       "      <td>0.007885</td>\n",
       "      <td>4</td>\n",
       "      <td>0.817916</td>\n",
       "      <td>0.806232</td>\n",
       "      <td>0.822330</td>\n",
       "      <td>0.815493</td>\n",
       "      <td>0.006792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.450524</td>\n",
       "      <td>0.096367</td>\n",
       "      <td>0.016470</td>\n",
       "      <td>0.000814</td>\n",
       "      <td>200</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.1}</td>\n",
       "      <td>0.722330</td>\n",
       "      <td>0.745631</td>\n",
       "      <td>0.707031</td>\n",
       "      <td>0.725032</td>\n",
       "      <td>0.015866</td>\n",
       "      <td>2</td>\n",
       "      <td>0.999026</td>\n",
       "      <td>0.998053</td>\n",
       "      <td>0.997087</td>\n",
       "      <td>0.998055</td>\n",
       "      <td>0.000792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.409721</td>\n",
       "      <td>0.022981</td>\n",
       "      <td>0.003827</td>\n",
       "      <td>0.000471</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'n_estimators': 10, 'max_depth': 4, 'learning_rate': 0.001}</td>\n",
       "      <td>0.681553</td>\n",
       "      <td>0.681553</td>\n",
       "      <td>0.683594</td>\n",
       "      <td>0.682231</td>\n",
       "      <td>0.000961</td>\n",
       "      <td>6</td>\n",
       "      <td>0.682571</td>\n",
       "      <td>0.682571</td>\n",
       "      <td>0.681553</td>\n",
       "      <td>0.682232</td>\n",
       "      <td>0.000480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5.698329</td>\n",
       "      <td>0.013964</td>\n",
       "      <td>0.013808</td>\n",
       "      <td>0.000848</td>\n",
       "      <td>200</td>\n",
       "      <td>4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'n_estimators': 200, 'max_depth': 4, 'learning_rate': 0.1}</td>\n",
       "      <td>0.732039</td>\n",
       "      <td>0.735922</td>\n",
       "      <td>0.705078</td>\n",
       "      <td>0.724384</td>\n",
       "      <td>0.013704</td>\n",
       "      <td>3</td>\n",
       "      <td>0.999026</td>\n",
       "      <td>0.998053</td>\n",
       "      <td>0.997087</td>\n",
       "      <td>0.998055</td>\n",
       "      <td>0.000792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.492895</td>\n",
       "      <td>0.007830</td>\n",
       "      <td>0.004325</td>\n",
       "      <td>0.000236</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'n_estimators': 10, 'max_depth': 5, 'learning_rate': 0.01}</td>\n",
       "      <td>0.681553</td>\n",
       "      <td>0.681553</td>\n",
       "      <td>0.683594</td>\n",
       "      <td>0.682231</td>\n",
       "      <td>0.000961</td>\n",
       "      <td>6</td>\n",
       "      <td>0.682571</td>\n",
       "      <td>0.682571</td>\n",
       "      <td>0.681553</td>\n",
       "      <td>0.682232</td>\n",
       "      <td>0.000480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       4.373492      0.091101         0.011978        0.000705   \n",
       "1       7.772204      0.248362         0.017135        0.000622   \n",
       "2       0.506870      0.017460         0.004325        0.000235   \n",
       "3       1.604947      0.018219         0.005989        0.000001   \n",
       "4       2.030638      0.043805         0.006654        0.000624   \n",
       "5       4.314938      0.017325         0.011146        0.000236   \n",
       "6       7.450524      0.096367         0.016470        0.000814   \n",
       "7       0.409721      0.022981         0.003827        0.000471   \n",
       "8       5.698329      0.013964         0.013808        0.000848   \n",
       "9       0.492895      0.007830         0.004325        0.000236   \n",
       "\n",
       "  param_n_estimators param_max_depth param_learning_rate  \\\n",
       "0                200               3                 0.1   \n",
       "1                200               5               0.001   \n",
       "2                 10               5               0.001   \n",
       "3                 50               4               0.001   \n",
       "4                 50               5               0.001   \n",
       "5                200               3                0.01   \n",
       "6                200               5                 0.1   \n",
       "7                 10               4               0.001   \n",
       "8                200               4                 0.1   \n",
       "9                 10               5                0.01   \n",
       "\n",
       "                                                          params  \\\n",
       "0    {'n_estimators': 200, 'max_depth': 3, 'learning_rate': 0.1}   \n",
       "1  {'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.001}   \n",
       "2   {'n_estimators': 10, 'max_depth': 5, 'learning_rate': 0.001}   \n",
       "3   {'n_estimators': 50, 'max_depth': 4, 'learning_rate': 0.001}   \n",
       "4   {'n_estimators': 50, 'max_depth': 5, 'learning_rate': 0.001}   \n",
       "5   {'n_estimators': 200, 'max_depth': 3, 'learning_rate': 0.01}   \n",
       "6    {'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.1}   \n",
       "7   {'n_estimators': 10, 'max_depth': 4, 'learning_rate': 0.001}   \n",
       "8    {'n_estimators': 200, 'max_depth': 4, 'learning_rate': 0.1}   \n",
       "9    {'n_estimators': 10, 'max_depth': 5, 'learning_rate': 0.01}   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  mean_test_score  \\\n",
       "0           0.728155           0.741748           0.730469         0.733463   \n",
       "1           0.689320           0.695146           0.689453         0.691310   \n",
       "2           0.681553           0.681553           0.683594         0.682231   \n",
       "3           0.681553           0.681553           0.683594         0.682231   \n",
       "4           0.681553           0.681553           0.683594         0.682231   \n",
       "5           0.702913           0.720388           0.718750         0.714008   \n",
       "6           0.722330           0.745631           0.707031         0.725032   \n",
       "7           0.681553           0.681553           0.683594         0.682231   \n",
       "8           0.732039           0.735922           0.705078         0.724384   \n",
       "9           0.681553           0.681553           0.683594         0.682231   \n",
       "\n",
       "   std_test_score  rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0        0.005942                1            0.999026            0.998053   \n",
       "1        0.002717                5            0.718598            0.706913   \n",
       "2        0.000961                6            0.682571            0.682571   \n",
       "3        0.000961                6            0.682571            0.682571   \n",
       "4        0.000961                6            0.682571            0.682571   \n",
       "5        0.007885                4            0.817916            0.806232   \n",
       "6        0.015866                2            0.999026            0.998053   \n",
       "7        0.000961                6            0.682571            0.682571   \n",
       "8        0.013704                3            0.999026            0.998053   \n",
       "9        0.000961                6            0.682571            0.682571   \n",
       "\n",
       "   split2_train_score  mean_train_score  std_train_score  \n",
       "0            0.997087          0.998055         0.000792  \n",
       "1            0.710680          0.712064         0.004870  \n",
       "2            0.681553          0.682232         0.000480  \n",
       "3            0.681553          0.682232         0.000480  \n",
       "4            0.681553          0.682232         0.000480  \n",
       "5            0.822330          0.815493         0.006792  \n",
       "6            0.997087          0.998055         0.000792  \n",
       "7            0.681553          0.682232         0.000480  \n",
       "8            0.997087          0.998055         0.000792  \n",
       "9            0.681553          0.682232         0.000480  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(gbRSCV.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.180629, -0.044899, -0.145163, -0.018974,  0.237544,  0.452695,\n",
       "        0.004599, -0.091597, -0.993889,  0.360783, -0.386382, -0.512438,\n",
       "       -0.658062,  0.420846,  0.162521,  0.553969,  0.099122,  0.755036,\n",
       "       -0.471112,  0.830366,  0.08927 , -0.260255,  0.572333, -0.748436,\n",
       "       -0.28951 ,  0.373733, -0.111502,  0.255532, -0.529217,  0.01092 ,\n",
       "       -0.328379,  0.311962, -0.546522,  0.058784, -0.089845,  0.265421,\n",
       "        0.26021 ,  0.060581,  0.492156, -0.294599,  0.00214 , -0.079839,\n",
       "        0.056477,  0.535249, -0.26015 ,  0.226907, -1.349362,  0.774546,\n",
       "        0.156021, -0.314995])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = wee.encodeWord('tóquio')-wee.encodeWord('japão')+wee.encodeWord('alemanha')\n",
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'berlim': 0.8206403394718784},\n",
       " {'zurique': 0.8176687002454563},\n",
       " {'frankfurt': 0.7990995590380496},\n",
       " {'munique': 0.7966431526280903},\n",
       " {'tóquio': 0.7872814224416539},\n",
       " {'bratislava': 0.7839682571121654},\n",
       " {'budapeste': 0.7817987924868405},\n",
       " {'viena': 0.7796727611854269},\n",
       " {'londres': 0.7750696819697582},\n",
       " {'cracóvia': 0.7741654426676957}]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wee.wordFromEmbedding(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
