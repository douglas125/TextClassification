{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named Entity Recognition (NER) using Optical Character Recognition (OCR) Data (Draft)\n",
    "\n",
    "\n",
    "\n",
    "OCR data provides (somewhat) structured information about words and their positions in a digitized document.\n",
    "\n",
    "This is a collection of ideas to extract features and classify the entities. So, let's say we want to extract info to help suggest Named Entities from an invoice OCR data:\n",
    "\n",
    "- (none)\n",
    "- VAT number\n",
    "- Company name\n",
    "- Company address\n",
    "- Total value\n",
    "\n",
    "Sample input:\n",
    "\n",
    "- words\n",
    "- word position (X, Y) in range [0,1] as coordinates of the image\n",
    "\n",
    "Desired output:\n",
    "\n",
    "For each word, we would like to predict category.\n",
    "\n",
    "## Classic approach\n",
    "\n",
    "A classic approach, for small number of data points, is to hand engineer some features for each word.\n",
    "\n",
    "First perform stemming and lemmatization (and maybe set to lowercase): https://nlp.stanford.edu/IR-book/html/htmledition/stemming-and-lemmatization-1.html\n",
    "\n",
    "Then, add some hand-engineered features (creativity and time consumption comes here):\n",
    "\n",
    "- One-hot encoding of the word;\n",
    "- Binary: Does it belong to the list ['eur', 'â‚¬', 'euro', 'euros'] ?\n",
    "- Binary: Does it belong to the list ['total', 'tot', 'totale', 'tutto'] ?\n",
    "- Binary: Is this word one of the 10% closer to the right of the page?\n",
    "- Binary: Is this word one of the 10% closer to the bottom of the page?\n",
    "- Numeric: How many digits does this word have? (or what % of the characters are digits)\n",
    "- etc.\n",
    "\n",
    "On top of that, add as extra features the features extracted for the N closest neighbors (left-right, maybe up and down).\n",
    "\n",
    "Obtain x_train, y_train vectors where x_train are features for each word (which includes info from neighbors) and corresponding NER labels.\n",
    "\n",
    "\n",
    "## Iterating the solution\n",
    "\n",
    "Once an initial estimate for NER is obtained, these can themselves be added to the feature set to try to improve the estimate. So, model 1 (say, linear regression) is trained using x_train, y_train and then model 2 (say SVM) uses x_train+(linear reg output), y_train.\n",
    "\n",
    "Scikit-learn RandomSearchCV https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html is the best friend to find best parameters and combinations that work best (search on Linear models, SVMs, boosted trees).\n",
    "\n",
    "\n",
    "## A note on generating the dataset\n",
    "\n",
    "If all you have are OCR outputs and desired labels, locating a string that does not match exactly can be approximated using https://en.wikipedia.org/wiki/Levenshtein_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Neural Approach\n",
    "\n",
    "If there is enough data (this is always a big if, of course), it is reasonable to try to learn features from data. Following the same rationale as before, each word has its own features (and of course there is no problem including the hand-engineered features in a neural model as well). The X and Y coordinates of the word should be included along with the hand-engineered features.\n",
    "\n",
    "One possibility is to use attention to try to fetch data that helps classifying the current word. One decision to be made is whether to use word or character level embedding.\n",
    "\n",
    "For simplicity, this neural model will assume word embeddings after stemming/lemmatization, keeping the top N more frequent words in the dictionary (replacing the others with the UNK token).\n",
    "\n",
    "This is a very first approach/suggestion that needs to be improved when real problems are to be solved.\n",
    "\n",
    "## Inputs\n",
    "\n",
    "For each document, the neural net has the following inputs:\n",
    "\n",
    "- Word indexes in dictionary (ints)\n",
    "- Hand-engineered features for each word\n",
    "\n",
    "Note that shape is `(batch_size, sequence_length)` for words (one index for each in the sequence) and `(batch_size, sequence_length, nFeats)` for features (nFeats features per word in the sequence).\n",
    "\n",
    "## Outputs\n",
    "\n",
    "Note that, for each word, the output is a softmax over the number of classes. Shape is `(batch_size, sequence_length, nClasses)`\n",
    "\n",
    "## Model\n",
    "\n",
    "Note that the model is purely attentional. Its arguments are:\n",
    "\n",
    "- nClasses: number of named entities to predict\n",
    "- nFeats: number of hand-engineered features plus the X,Y coordinates\n",
    "- projection_dim: projection dimension to use when computing attention (to learn proper metrics)\n",
    "- interactions: in the classic case the output of one model could be input to another. In a Neural Net, since there is gradient propagation, it is possible to simply nest the interactions. This is the number of neural models to use.\n",
    "- dict_size: number of words kept in dictionary (including the `<UNK>` token)\n",
    "- word_emb_dim: dimension of the embeddings\n",
    "- n_attention_heads: fetch relevant information from how many other words?\n",
    "\n",
    "Note: no regularization has been added. This will depend on the real problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______________________________________________________________________________________________________________\n",
      "Layer (type)                        Output Shape            Param #      Connected to                         \n",
      "==============================================================================================================\n",
      "input_1 (InputLayer)                (None, None)            0                                                 \n",
      "______________________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)             (None, None, 16)        4096         input_1[0][0]                        \n",
      "______________________________________________________________________________________________________________\n",
      "input_2 (InputLayer)                (None, None, 6)         0                                                 \n",
      "______________________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)         (None, None, 22)        0            embedding_1[0][0]                    \n",
      "                                                                         input_2[0][0]                        \n",
      "______________________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistributed (None, None, 64)        1472         concatenate_1[0][0]                  \n",
      "______________________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistributed (None, None, 64)        4160         time_distributed_1[0][0]             \n",
      "______________________________________________________________________________________________________________\n",
      "time_distributed_3 (TimeDistributed (None, None, 64)        4160         time_distributed_1[0][0]             \n",
      "______________________________________________________________________________________________________________\n",
      "time_distributed_4 (TimeDistributed (None, None, 64)        4160         time_distributed_1[0][0]             \n",
      "______________________________________________________________________________________________________________\n",
      "time_distributed_5 (TimeDistributed (None, None, 64)        4160         time_distributed_1[0][0]             \n",
      "______________________________________________________________________________________________________________\n",
      "dot_1 (Dot)                         (None, None, None)      0            time_distributed_1[0][0]             \n",
      "                                                                         time_distributed_2[0][0]             \n",
      "______________________________________________________________________________________________________________\n",
      "dot_3 (Dot)                         (None, None, None)      0            time_distributed_1[0][0]             \n",
      "                                                                         time_distributed_3[0][0]             \n",
      "______________________________________________________________________________________________________________\n",
      "dot_5 (Dot)                         (None, None, None)      0            time_distributed_1[0][0]             \n",
      "                                                                         time_distributed_4[0][0]             \n",
      "______________________________________________________________________________________________________________\n",
      "dot_7 (Dot)                         (None, None, None)      0            time_distributed_1[0][0]             \n",
      "                                                                         time_distributed_5[0][0]             \n",
      "______________________________________________________________________________________________________________\n",
      "softmax_1 (Softmax)                 (None, None, None)      0            dot_1[0][0]                          \n",
      "______________________________________________________________________________________________________________\n",
      "softmax_2 (Softmax)                 (None, None, None)      0            dot_3[0][0]                          \n",
      "______________________________________________________________________________________________________________\n",
      "softmax_3 (Softmax)                 (None, None, None)      0            dot_5[0][0]                          \n",
      "______________________________________________________________________________________________________________\n",
      "softmax_4 (Softmax)                 (None, None, None)      0            dot_7[0][0]                          \n",
      "______________________________________________________________________________________________________________\n",
      "dot_2 (Dot)                         (None, None, 64)        0            softmax_1[0][0]                      \n",
      "                                                                         time_distributed_1[0][0]             \n",
      "______________________________________________________________________________________________________________\n",
      "dot_4 (Dot)                         (None, None, 64)        0            softmax_2[0][0]                      \n",
      "                                                                         time_distributed_1[0][0]             \n",
      "______________________________________________________________________________________________________________\n",
      "dot_6 (Dot)                         (None, None, 64)        0            softmax_3[0][0]                      \n",
      "                                                                         time_distributed_1[0][0]             \n",
      "______________________________________________________________________________________________________________\n",
      "dot_8 (Dot)                         (None, None, 64)        0            softmax_4[0][0]                      \n",
      "                                                                         time_distributed_1[0][0]             \n",
      "______________________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)         (None, None, 278)       0            concatenate_1[0][0]                  \n",
      "                                                                         dot_2[0][0]                          \n",
      "                                                                         dot_4[0][0]                          \n",
      "                                                                         dot_6[0][0]                          \n",
      "                                                                         dot_8[0][0]                          \n",
      "______________________________________________________________________________________________________________\n",
      "time_distributed_6 (TimeDistributed (None, None, 64)        17856        concatenate_2[0][0]                  \n",
      "______________________________________________________________________________________________________________\n",
      "time_distributed_7 (TimeDistributed (None, None, 64)        4160         time_distributed_6[0][0]             \n",
      "______________________________________________________________________________________________________________\n",
      "time_distributed_8 (TimeDistributed (None, None, 64)        4160         time_distributed_6[0][0]             \n",
      "______________________________________________________________________________________________________________\n",
      "time_distributed_9 (TimeDistributed (None, None, 64)        4160         time_distributed_6[0][0]             \n",
      "______________________________________________________________________________________________________________\n",
      "time_distributed_10 (TimeDistribute (None, None, 64)        4160         time_distributed_6[0][0]             \n",
      "______________________________________________________________________________________________________________\n",
      "dot_9 (Dot)                         (None, None, None)      0            time_distributed_6[0][0]             \n",
      "                                                                         time_distributed_7[0][0]             \n",
      "______________________________________________________________________________________________________________\n",
      "dot_11 (Dot)                        (None, None, None)      0            time_distributed_6[0][0]             \n",
      "                                                                         time_distributed_8[0][0]             \n",
      "______________________________________________________________________________________________________________\n",
      "dot_13 (Dot)                        (None, None, None)      0            time_distributed_6[0][0]             \n",
      "                                                                         time_distributed_9[0][0]             \n",
      "______________________________________________________________________________________________________________\n",
      "dot_15 (Dot)                        (None, None, None)      0            time_distributed_6[0][0]             \n",
      "                                                                         time_distributed_10[0][0]            \n",
      "______________________________________________________________________________________________________________\n",
      "softmax_5 (Softmax)                 (None, None, None)      0            dot_9[0][0]                          \n",
      "______________________________________________________________________________________________________________\n",
      "softmax_6 (Softmax)                 (None, None, None)      0            dot_11[0][0]                         \n",
      "______________________________________________________________________________________________________________\n",
      "softmax_7 (Softmax)                 (None, None, None)      0            dot_13[0][0]                         \n",
      "______________________________________________________________________________________________________________\n",
      "softmax_8 (Softmax)                 (None, None, None)      0            dot_15[0][0]                         \n",
      "______________________________________________________________________________________________________________\n",
      "dot_10 (Dot)                        (None, None, 64)        0            softmax_5[0][0]                      \n",
      "                                                                         time_distributed_6[0][0]             \n",
      "______________________________________________________________________________________________________________\n",
      "dot_12 (Dot)                        (None, None, 64)        0            softmax_6[0][0]                      \n",
      "                                                                         time_distributed_6[0][0]             \n",
      "______________________________________________________________________________________________________________\n",
      "dot_14 (Dot)                        (None, None, 64)        0            softmax_7[0][0]                      \n",
      "                                                                         time_distributed_6[0][0]             \n",
      "______________________________________________________________________________________________________________\n",
      "dot_16 (Dot)                        (None, None, 64)        0            softmax_8[0][0]                      \n",
      "                                                                         time_distributed_6[0][0]             \n",
      "______________________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)         (None, None, 534)       0            concatenate_2[0][0]                  \n",
      "                                                                         dot_10[0][0]                         \n",
      "                                                                         dot_12[0][0]                         \n",
      "                                                                         dot_14[0][0]                         \n",
      "                                                                         dot_16[0][0]                         \n",
      "______________________________________________________________________________________________________________\n",
      "time_distributed_11 (TimeDistribute (None, None, 64)        34240        concatenate_3[0][0]                  \n",
      "______________________________________________________________________________________________________________\n",
      "time_distributed_12 (TimeDistribute (None, None, 64)        4160         time_distributed_11[0][0]            \n",
      "______________________________________________________________________________________________________________\n",
      "time_distributed_13 (TimeDistribute (None, None, 64)        4160         time_distributed_11[0][0]            \n",
      "______________________________________________________________________________________________________________\n",
      "time_distributed_14 (TimeDistribute (None, None, 64)        4160         time_distributed_11[0][0]            \n",
      "______________________________________________________________________________________________________________\n",
      "time_distributed_15 (TimeDistribute (None, None, 64)        4160         time_distributed_11[0][0]            \n",
      "______________________________________________________________________________________________________________\n",
      "dot_17 (Dot)                        (None, None, None)      0            time_distributed_11[0][0]            \n",
      "                                                                         time_distributed_12[0][0]            \n",
      "______________________________________________________________________________________________________________\n",
      "dot_19 (Dot)                        (None, None, None)      0            time_distributed_11[0][0]            \n",
      "                                                                         time_distributed_13[0][0]            \n",
      "______________________________________________________________________________________________________________\n",
      "dot_21 (Dot)                        (None, None, None)      0            time_distributed_11[0][0]            \n",
      "                                                                         time_distributed_14[0][0]            \n",
      "______________________________________________________________________________________________________________\n",
      "dot_23 (Dot)                        (None, None, None)      0            time_distributed_11[0][0]            \n",
      "                                                                         time_distributed_15[0][0]            \n",
      "______________________________________________________________________________________________________________\n",
      "softmax_9 (Softmax)                 (None, None, None)      0            dot_17[0][0]                         \n",
      "______________________________________________________________________________________________________________\n",
      "softmax_10 (Softmax)                (None, None, None)      0            dot_19[0][0]                         \n",
      "______________________________________________________________________________________________________________\n",
      "softmax_11 (Softmax)                (None, None, None)      0            dot_21[0][0]                         \n",
      "______________________________________________________________________________________________________________\n",
      "softmax_12 (Softmax)                (None, None, None)      0            dot_23[0][0]                         \n",
      "______________________________________________________________________________________________________________\n",
      "dot_18 (Dot)                        (None, None, 64)        0            softmax_9[0][0]                      \n",
      "                                                                         time_distributed_11[0][0]            \n",
      "______________________________________________________________________________________________________________\n",
      "dot_20 (Dot)                        (None, None, 64)        0            softmax_10[0][0]                     \n",
      "                                                                         time_distributed_11[0][0]            \n",
      "______________________________________________________________________________________________________________\n",
      "dot_22 (Dot)                        (None, None, 64)        0            softmax_11[0][0]                     \n",
      "                                                                         time_distributed_11[0][0]            \n",
      "______________________________________________________________________________________________________________\n",
      "dot_24 (Dot)                        (None, None, 64)        0            softmax_12[0][0]                     \n",
      "                                                                         time_distributed_11[0][0]            \n",
      "______________________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)         (None, None, 790)       0            concatenate_3[0][0]                  \n",
      "                                                                         dot_18[0][0]                         \n",
      "                                                                         dot_20[0][0]                         \n",
      "                                                                         dot_22[0][0]                         \n",
      "                                                                         dot_24[0][0]                         \n",
      "______________________________________________________________________________________________________________\n",
      "time_distributed_16 (TimeDistribute (None, None, 64)        50624        concatenate_4[0][0]                  \n",
      "______________________________________________________________________________________________________________\n",
      "time_distributed_17 (TimeDistribute (None, None, 64)        4160         time_distributed_16[0][0]            \n",
      "______________________________________________________________________________________________________________\n",
      "time_distributed_18 (TimeDistribute (None, None, 5)         325          time_distributed_17[0][0]            \n",
      "==============================================================================================================\n",
      "Total params: 162,693\n",
      "Trainable params: 162,693\n",
      "Non-trainable params: 0\n",
      "______________________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import Model\n",
    "from keras import layers as L\n",
    "\n",
    "def build_OCR_NER_model(nClasses = 5, nFeats = 6, projection_dim = 64, interactions=3, \n",
    "                        dict_size=256, word_emb_dim = 16, n_attention_heads=4):\n",
    "    inpWords = L.Input( (None, ) ) #these are the indexes of the words in the dictionary, including <UNK>\n",
    "    inpFeats = L.Input( (None, nFeats) ) #X and Y coordinates are among these\n",
    "    \n",
    "    #first we learn word embeddings. Usual rule of thumb: srqt(len(dictionary))\n",
    "    emb_words = L.Embedding(dict_size, word_emb_dim)(inpWords)\n",
    "    \n",
    "    #combine the features\n",
    "    x = L.Concatenate()([emb_words,inpFeats])\n",
    "    \n",
    "    for interac in range(interactions):\n",
    "        feat_list = [x] #we include the original features here hoping to learn their interactions as well\n",
    "        \n",
    "        #what is important from other words? attention could be used to fetch this information\n",
    "        x = L.TimeDistributed(L.Dense( projection_dim ))(x)\n",
    "        for k in range(n_attention_heads):\n",
    "            proj = L.TimeDistributed(L.Dense( projection_dim ))(x) #query projection\n",
    "            attw = L.Dot([2,2])([x,proj])\n",
    "            attw = L.Softmax()(attw)\n",
    "            weighted_avg = L.Dot([2,1])([attw, x])\n",
    "            feat_list.append(weighted_avg)\n",
    "        x = L.Concatenate()(feat_list)\n",
    "    \n",
    "    #now do classification with a simple FF net\n",
    "    x = L.TimeDistributed(L.Dense( projection_dim, activation='relu'))(x)\n",
    "    x = L.TimeDistributed(L.Dense( projection_dim, activation='relu'))(x)\n",
    "    x = L.TimeDistributed(L.Dense( nClasses, activation='softmax'))(x)\n",
    "    \n",
    "    m = Model(inputs = [inpWords, inpFeats], outputs=x)\n",
    "    \n",
    "    return m\n",
    "\n",
    "model = build_OCR_NER_model()\n",
    "model.summary(line_length=110)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
